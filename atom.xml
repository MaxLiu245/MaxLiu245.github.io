<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Max Liu&#39;s Blog</title>
  
  <subtitle>Earlier birds eat more worms</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://maxliu245.github.io/"/>
  <updated>2021-03-21T02:36:54.573Z</updated>
  <id>http://maxliu245.github.io/</id>
  
  <author>
    <name>Max Liu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【论文阅读42】神经流形ODE——进一步可构建CNF的流形版本MCNF</title>
    <link href="http://maxliu245.github.io/2021/03/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB42%E3%80%91%E7%A5%9E%E7%BB%8F%E6%B5%81%E5%BD%A2ODE%E2%80%94%E2%80%94%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%8F%AF%E6%9E%84%E5%BB%BACNF%E7%9A%84%E6%B5%81%E5%BD%A2%E7%89%88%E6%9C%ACMCNF/"/>
    <id>http://maxliu245.github.io/2021/03/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB42%E3%80%91%E7%A5%9E%E7%BB%8F%E6%B5%81%E5%BD%A2ODE%E2%80%94%E2%80%94%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%8F%AF%E6%9E%84%E5%BB%BACNF%E7%9A%84%E6%B5%81%E5%BD%A2%E7%89%88%E6%9C%ACMCNF/</id>
    <published>2021-03-18T18:11:47.000Z</published>
    <updated>2021-03-21T02:36:54.573Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文的标题<em>Neural Manifold Ordinary Differential Equations</em>着实是吸引了我（自己记为<u>MODE</u>）</p><p>摘要里也说这算是NODE的流形版</p><p>那就看看和之前看的<a href="http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/">深度微分同胚归一化流DDNF</a>有啥区别，估摸着大概是DDNF是直接假设隐变量在流形上积分，这个MODE还有把隐变量逆回原始数据空间的操作</p><p>ps：这份笔记写急了，写得很烂。。。不喜请勿食用</p></blockquote><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><div style="width:60%;margin:auto"><img src="/2021/03/19/【论文阅读42】神经流形ODE——进一步可构建CNF的流形版本MCNF/1.png" title="MODE"></div><p>这篇文章是<a href="https://papers.nips.cc/paper/2020" target="_blank" rel="noopener">NeurIPS 2020</a>上的，作者主要来自康奈尔和脸书，其中最后一个作者<a href="https://www.cs.cornell.edu/~cdesa/" target="_blank" rel="noopener">Christopher De Sa</a>是康奈尔大学的，看看人家的<a href="https://www.cs.cornell.edu/~cdesa/" target="_blank" rel="noopener">研究</a>，就离谱。。。</p><p>本文提出的框架叫<strong>神经流形ODE</strong>，简称MODE；进一步结合NF提出MCNF，<strong>流形连续归一化流</strong></p><script type="math/tex; mode=display">MODE= \varphi_k\circ ODE_k\circ (\varphi_k^{-1}\circ \varphi_{k-1})\circ \cdots\circ (\varphi_2^{-1}\circ \varphi_{1})\circ ODE_1 \circ \varphi_1^{-1} \tag{1}</script><p>文献地址：</p><ul><li><a href="https://papers.nips.cc/paper/2020" target="_blank" rel="noopener">NeurIPS 2020</a>：<a href="https://papers.nips.cc/paper/2020/hash/cbf8710b43df3f2c1553e649403426df-Abstract.html" target="_blank" rel="noopener">https://papers.nips.cc/paper/2020/hash/cbf8710b43df3f2c1553e649403426df-Abstract.html</a></li><li>ArXiv：<a href="https://arxiv.org/abs/2006.10254" target="_blank" rel="noopener">https://arxiv.org/abs/2006.10254</a></li><li>原文的审稿记录：<a href="https://papers.nips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-AuthorFeedback.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-AuthorFeedback.pdf</a></li><li>代码：<a href="https://github.com/CUAI/Neural-Manifold-Ordinary-Differential-Equations" target="_blank" rel="noopener">https://github.com/CUAI/Neural-Manifold-Ordinary-Differential-Equations</a></li></ul><h2 id="背景方法"><a href="#背景方法" class="headerlink" title="背景方法"></a>背景方法</h2><p>由于本文针对的<font color="#000FFF">问题</font>是数据中几何结构的建模，所以自然的想法就是隐变量分布在流形上。由此，基本的背景方法是<u>生成模型</u>，偏<u>流</u>的建模或者和<u>流形</u>的联系，有一定可解释性</p><p>具体的背景方法请见原文的第$(2)$章，related work</p><blockquote><p>CNF似乎也是NODE，把隐变量建模，连续变化？查一下确认一下</p></blockquote><h2 id="动机-Idea"><a href="#动机-Idea" class="headerlink" title="动机/Idea"></a>动机/Idea</h2><p>本文的<font color="#000FFF">动机</font>是，生成模型要与流形结合使之有更直观的解释性。但是在<strong>推广到非欧几何</strong>后会有诸多限制，比如可能手动设计网络，对网络施加保持非欧几何性质的限制，这样也会<strong>难以推广</strong>到任意流形</p><blockquote><p>我觉得文章说“<code>难以推广到任意流形</code>”是指若推广到任意流形，则整个映射是微分同胚，意味着数据的几何结构是一样的，而这不现实！</p></blockquote><p><font color="#000FFF">Idea</font>是把NODE进行流形推广，只用（<font color="#000FFF">疑问</font>：真的只用这个？）考虑<strong>局部流形</strong>限制，然后“推广”到整个流形上（<font color="#000FFF">疑问</font>：那这个局部其实是很强的条件，这里所谓的推广应该只是指积分的过程，整个映射未必还保持微分同胚了）</p><p><font color="#000FFF">Idea</font>继续发散，归一化流NF大概是用一系列成串的可逆可微映射拟合一个复杂，且tractable的后验分布。NF中这个整体的分布变换是微分同胚，要求是forward映射的Jacobi好算，逆好算，采样好采。但正因为引入NF，要求两个分布其实是同胚，几何上等价，隐空间中必须保持拓扑性质，这其实对于大多数数据不成立。所以由此退而求其次，本文只取<strong>有限维</strong>光滑流形的假设，不必要是同胚，导出的模型叫做<font color="#000FFF">MCNF</font>，流形连续归一化流</p><p>上述idea弄出来以后，可以理解为MODE的特例，即微分结构（chart）不取指数映射，取id</p><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>本文针对的问题是数据几何建模，结合流模型、NODE的思想</p><h2 id="模型MODE"><a href="#模型MODE" class="headerlink" title="模型MODE"></a>模型MODE</h2><p>基本的<strong>MODE</strong>很简单，<strong>DE设置到流形上即可</strong>，那么一阶导数其实就是切向量场</p><blockquote><p>思路和之前写的<a href="http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/">深度微分同胚归一化流DDNF</a>基本一致！然而投稿差异。。</p></blockquote><p>此ODE前向和后向的计算<strong>不太一样</strong>，前者需要在流形上显示计算，后者单在欧氏空间中计算！</p><p>其中前向的gt（ground truth）一般用数值求解器（solver），过去就有两种方案：投影转化到欧氏空间中求解再投影回去；和隐式方法。在流形上会涉及真正流形上的计算，和李群、指数映射什么的有关。本文表示前者在全局流形意义下点的表示上有所缺陷，后者更简单通用一点，但是本文MODE不就是前者❓这个和我黎曼几何大作业翻译的文章是一致的❗</p><p>后向也不简单，涉及伴随方法、伴随梯度计算，我猜要用G导数和近似。似乎只要取$\mathbb{R}^{2n}$，那么由Whitney Embedding Theorem，$n$维流形$\mathcal{M}$上的曲线就可以嵌入此流形的周围空间（ambient space）。看了附录，本文定理$(4.1)$的证明挺简单的，只用了伴随的定义。这个定理只是<strong>帮助计算</strong>向后传播的梯度的</p><div style="width:60%;margin:auto"><img src="/2021/03/19/【论文阅读42】神经流形ODE——进一步可构建CNF的流形版本MCNF/2.png" title="最终的近似计算：可以选择多次流形-欧氏空间之间的变换"></div><p>那么上述是MODE的思路，计算上就麻烦了，涉及欧氏空间到流形切空间的<strong>指数映射</strong>与伴随方法的<strong>G导数</strong>计算。为此使用了所谓的dynamic chart method方法<strong>近似</strong>优化，还是<font color="#FF0000">近似</font>！详情见优化部分</p><hr><p>进一步MODE的一个应用是CNF的流形形式，称为<strong>MCNF</strong>。这个推广很自然，想想CNF的结构，把隐空间变一下变到流形上就是了，这样看来CNF算是MODE的特例</p><blockquote><p>道理与MODE一样，同胚通过把欧氏空间的局部动力性质积分，然后通过微分结构（本文用的说法是chart，和那个map一致）映射到流形上。CNF就转化到流形空间中了</p></blockquote><h2 id="训练-优化"><a href="#训练-优化" class="headerlink" title="训练/优化"></a>训练/优化</h2><p>MODE的思路只是一个框架，是本文general的<strong>神经流形ODE</strong></p><p>具体计算使用了dynamic chart method，是一个欧氏空间-流形切空间之间变换的近似过程。用到MODE优化中，算是黎曼梯度下降的<strong>替代品</strong>。那么这个方法的一个关键是chart变换的选择，自然的选择是指数映射，局部流形切空间和欧氏空间就联系起来了，但是文章的指数映射<strong><font color="#FF0000">为什么取成</font></strong></p><script type="math/tex; mode=display">z_{t+1}=exp(-\eta \nabla_{z_t} f) \tag{2}</script><p>我不是很明白它的具体选取方式，可能需要自己去查代码</p><p>文章这个方法的一大优点是提供了两个理论保证，此外还有别的：</p><ul><li><strong>理论保证</strong>：定理$(5.1)$是流形ODE局部解的存在性；定理$(5.2)$是收敛性，有限次chart转换就可以了</li><li>对于特定的非欧几何，这个dynamic chart method似乎可以更快，和近似的解析形式有关</li><li>avoid catastrophic gradient instability，这个没看，<strong>没看懂</strong></li></ul><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li><p>流的思想使之适用于密度估计（density estimation）和流相关（downstream tasks）的问题</p></li><li><p>与CNF的对比，是其流形形式manifold analogue</p></li><li><p>与NODE的对比，其流形形式✅，且NODE的拓展，它基本上也可以用啊</p></li><li><p>broader impact，准确建模数据拓扑？确实有意义</p></li></ul><p>缺点略，就是觉得和那个CVPRW2018思路一致，但它就加了个微分结构和一些理论</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验不多，只有一个密度估计和一个变分推断的比较。总的来说，MODE比比较的方法都<strong>显著地好</strong></p><p>但是实验不是太能看得明白，扫了一眼附录，觉得<strong>非常几何</strong>，这个虽然我喜欢，但是确实看不大明白，毕竟没研究过双曲空间、球面的具体性质</p><h2 id="读审稿意见"><a href="#读审稿意见" class="headerlink" title="读审稿意见"></a>读审稿意见</h2><p>感觉出来本文的作者有不少生物、物理上的认识，对方程、流形非常熟悉</p><p>里面也有一些我的疑问，比如chart的选择，作者回应，这是<strong>作为先验显式规定</strong>好的</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Aaron Lou, Derek Lim, Isay Katsman, Leo Huang, Qingxuan Jiang, Ser Nam Lim, and Christopher M De Sa. Neural manifold ordinary differential equations. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 17548–17558. Curran Associates, Inc., 2020.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;NEURIPS2020_cbf8710b,</span><br><span class="line">author = &#123;Lou, Aaron and Lim, Derek and Katsman, Isay and Huang, Leo and Jiang, Qingxuan and Lim, Ser Nam and De Sa, Christopher M&#125;,</span><br><span class="line">booktitle = &#123;Advances in Neural Information Processing Systems&#125;,</span><br><span class="line">editor = &#123;H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin&#125;,</span><br><span class="line">pages = &#123;17548--17558&#125;,</span><br><span class="line">publisher = &#123;Curran Associates, Inc.&#125;,</span><br><span class="line">title = &#123;Neural Manifold Ordinary Differential Equations&#125;,</span><br><span class="line">url = &#123;https://proceedings.neurips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-Paper.pdf&#125;,</span><br><span class="line">volume = &#123;33&#125;,</span><br><span class="line">year = &#123;2020&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文的标题&lt;em&gt;Neural Manifold Ordinary Differential Equations&lt;/em&gt;着实是吸引了我（自己记为&lt;u&gt;MODE&lt;/u&gt;）&lt;/p&gt;
&lt;p&gt;摘要里也说这算是NODE的流形版&lt;/p&gt;
&lt;p&gt;那就看看和之前看的&lt;a href=&quot;http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/&quot;&gt;深度微分同胚归一化流DDNF&lt;/a&gt;有啥区别，估摸着大概是DDNF是直接假设隐变量在流形上积分，这个MODE还有把隐变量逆回原始数据空间的操作&lt;/p&gt;
&lt;p&gt;ps：这份笔记写急了，写得很烂。。。不喜请勿食用&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Manifold" scheme="http://maxliu245.github.io/tags/Manifold/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读41】动态神经网络综述</title>
    <link href="http://maxliu245.github.io/2021/03/18/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB41%E3%80%91%E5%8A%A8%E6%80%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%BC%E8%BF%B0/"/>
    <id>http://maxliu245.github.io/2021/03/18/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB41%E3%80%91%E5%8A%A8%E6%80%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%BC%E8%BF%B0/</id>
    <published>2021-03-18T05:37:17.000Z</published>
    <updated>2021-03-19T00:35:00.852Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>这次略读了综述<em>Dynamic Neural Networks: A Survey</em></p><p>阅读的<u>动机是觉得这个和动力系统有关系</u>，不过读完了没什么感觉，大的感悟是玄学，小的感悟是和元学习、NAS、ODE、流什么的其实都有点关系，觉得框架不太优美，多而杂</p><p>ps：其实没有读完，正文只读了前四大章，到优化训练前面。后面参考他人的博客了解了概览</p><p>ps2：这次写作引入了缩放图片的<a href="http://xring.info/2018/hexo-pic-size.html" target="_blank" rel="noopener">方法</a>，且兼容中文图片标题</p></blockquote><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><div style="width:60%;margin:auto"><img src="/2021/03/18/【论文略读41】动态神经网络综述/1.png" title="Dynamic Neural Networks: A Survey"></div><p><a href="https://arxiv.org/abs/2102.04906" target="_blank" rel="noopener">本文</a>是动态神经网络的一个综述，引言之后就按动态网络分类，分三类介绍，然后讲优化训练技巧，最后讲应用和未来方向。正文15页，作者都是清华的，主力似乎是<a href="http://www.gaohuang.net/" target="_blank" rel="noopener">黄高</a>老师。我自己读到了正文前四大章，到优化/训练的前面。本来想着这个动态网络和NODE有点关系，但是读了一大半发现目前关系不大，下次读文章还是要<u>搞清楚我的初始目标</u>是什么，不然要花好多时间。后面的内容<strong>有人已经总结好了</strong>（<del>虽然自己读的确实详细一点</del>），请参考下列博客：</p><ul><li><p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAA9hMKA_HwTPZFwHS1O-PYqDQUiH8qpEJuNpqGuMb9KUg/" target="_blank" rel="noopener">AI科技评论</a>的文章<a href="https://www.toutiao.com/i6939102678295249439" target="_blank" rel="noopener">「深度」清华黄高等人新作：动态神经网络首篇综述</a></p></li><li><p><a href="https://www.zhihu.com/org/bei-jing-zhi-yuan-ren-gong-zhi-neng-yan-jiu-yuan" target="_blank" rel="noopener">北京智源人工智能研究院</a>(<a href="https://www.zhihu.com/question/48510028)的文章[【深度】动态神经网络综述](https://zhuanlan.zhihu.com/p/354507714)，这个和第一个差不多" target="_blank" rel="noopener">https://www.zhihu.com/question/48510028)的文章[【深度】动态神经网络综述](https://zhuanlan.zhihu.com/p/354507714)，这个和第一个差不多</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/149303296" target="_blank" rel="noopener">Dynamic Neural Networks（上）</a>，这个供参考，其实我没读</p></li></ul><h2 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h2><p>动态网络的<font color="#000FFF">背景</font>方法是静态网络，后者有固定的权重、计算图和网络结构；</p><p>研究它的<font color="#000FFF">动机</font>是与静态网络对比，超越其诸多限制；</p><p>要解决的<font color="#000FFF">问题</font>可以分特定任务考虑，也可以说是针对静态网络的缺点（静态限制了表达能力，计算效率，以及某种意义下的可解释性）；</p><p>动态网络的表示方法可以<font color="#000FFF">分</font>为3大<font color="#000FFF">类</font>，具体是<strong>instance-wise，spatial-wise，temporal-wise</strong>。大致就是网络🉑根据每个输入的样本、或样本中的位置（如图像上像素位置）、或时间（主要是TS或视频数据）自适应变化。另外，动态也可以指在测试的时候动态，即自适应推断，测试样本来的时候，可能有级联（非串联）或者并行（不严格是并联）的结构；</p><p>其训练<font color="#000FFF">优化</font>方法也很重要，因为相比静态，动态的训练更难；</p><p>动态网络的<font color="#000FFF">优点</font>，主要是对比静态网络：</p><ul><li>可解释性up，这个解释的角度清奇啊，动态网络可能打通深度模型和人脑机制之间的gap？理由是脑处理信息是动态的，比如接收不同信息后脑的激活区域不同。这个idea是启发式的，所以其实可解释性不强</li><li>计算效率up，比如分配计算，激活部分结构</li><li>表示能力up，参数空间动态变化，更大了</li><li>自适应性🉑，动态平衡准确率和计算效率</li><li>兼容性🉑，与现有方法，技巧基本上兼容</li><li>一般性/泛化性🉑，动态的比静态的更general，应用也都可以用</li></ul><p><font color="#000FFF">缺点</font>，显然的一个缺点是理论证明不充分，只有一小部分启发式的道理，所以玄学感强；</p><p>其未来<font color="#000FFF">研究方向</font>有，继续设计网络结构、优化技巧；寻找应用；补充现在缺乏的理论证明，etc</p><h2 id="方法分类（看图即可）"><a href="#方法分类（看图即可）" class="headerlink" title="方法分类（看图即可）"></a>方法分类（看图即可）</h2><p>这一部分是把综述里列举的动态网络分类一一列出来，和网上的其它博客差不多。写在这里是因为自己看过一遍，就列一遍<u>仅供自己</u>日后回忆</p><p>文章的图$(1)$其实很🉑，看了可以加深对本文的认识，不错，我基本上看懂了。下面是具体的分类：</p><div style="width:95%;margin:auto"><img src="/2021/03/18/【论文略读41】动态神经网络综述/2.png" title="综述分类"></div><ul><li><p>第一大类【instance-wise】</p><p>总的来说，它指根据输入样本，不改变参数时调整使用的计算图（即模型结构）；或者不改变计算图时自适应模型参数（会增大计算消耗但确实性能有所提升）</p><ul><li><p>【动态结构】，主要是推断/测试的时候</p><ul><li><p>【调整网络深度】，具体方法包括</p><ol><li><p>【提前中止网络】，道理是简单样本确实不需要太多计算，难的样本才需要深度特征</p><p>例一是网络级联，参考原文图$(3a)$，不是串联！像树一样分好多模型，选择其中的部分模型；</p><p>例二是在中间层设置分类器，某一层之后如果显著确定类别就可以提前终止了；</p><p>例三是多尺度的提前中止，这个多尺度指的是浅层和深度特征的选择，主要是DenseNet，Dense连接之类的方法，权衡选择浅层或深度特征</p></li><li><p>【跳过某些中间层】，其实有点像提前中止的灵活版，skip的操作可用ResNet那样的连接完成</p><p>例一，halting score，是个分数（标量），具体怎么算没看。感觉是要网络前进过程种这个量会累计，当超过一定的阈值之后网络才会跳到下一层，否则循环上一层；</p><p>例二，门函数（gating functions），输入还是上一层的输出，输出是0或1，原文$(4)$式很清楚。特点是即插即用（plug-and-play）模块，如原文图$(4)$，确实是像开关一样即插即用；</p><p>例三是策略网络，就是单独用一个网络来当门函数，输入取原始的输入，它怎么就能是policy暂时不太明白</p></li></ol></li><li><p>【调整中间层宽度】，具体方法🈶</p><ol><li><p>FC层【动态宽度】，思想是有的神经元表示的特征不太重要，就不必被激活</p></li><li><p>【专家混合（MoE）】，这个和上面的网络级联有点像，但是不会说一个专家网络🆗了其它的网络就不计算了。MoE都计算，只是会为每个专家的输出赋权，权重与样本数据有关，可以通过单独的函数或者输出稀疏系数的hard门函数</p></li><li><p>CNN中的【动态channel剪枝】，这个的idea是对不同样本，有的channel可能用不上，所以可以跳过一些channel（不是真剪了）</p><p>例一，Multi-stage architectures along the channel dimension没看懂；</p><p>例二、三分别是基于门函数和特征激活的动态剪枝。我对剪枝不感兴趣，也看不太明白，不看了</p></li></ol></li><li><p>用超网络【选择计算图路径】，这个主要是讨论怎么确定选择路径的策略，以及超网络的结构。注意之前提早中止也相当于是一种路径选择。具体的实例不感兴趣，怎么觉得和剪枝很像，越看越不明白，怎么看都像NAS，再看就是玄学。和ODE关系不大，不看了！</p></li></ul></li><li><p>【动态参数】，首先还是在样本-wise的框架下，所以这个动态参数是指对每个输入样本，网络的结构不要变，参数有所变化</p><ul><li><p>CNN中的【卷积核参数化】，原文标题weights调整应该就是这个意思，根据输入调整训练参数，这样做的好处是消耗一定的计算资源提高性能。具体细节以前没有关注过，感觉分两种：</p><p>一种是只改卷积核参数，比如用多个核加权近似；</p><p>还有一种是卷积核大小自适应，具体不太了解，应该和感受域大小有关</p></li><li><p>【权重预测】，这个比上一条更暴力，根据输入样本直接预测/生成网络中的滤波器/参数。一般的做法是直接上超网络，输出就是滤波器/卷积算子；另外，特定任务的信息也可以拿来训练生成这些参数</p></li><li><p>【动态特征】，这类方法的动机是利用上述动态参数进行测试/推断的时候，其实生产的特征也是动态的，其中会暗含一些不清楚是什么的新特征；而现在可以更直接地得到这样的动态特征。文章总结了三种方法来获取动态特征：</p><ol><li>利用attention直接对多channel加权；</li><li>利用attention直接对输入的不同位置进行自适应加权；</li><li>直接对激活函数动态加权，方式似乎是在激活函数中引入了调整参数</li></ol></li></ul></li></ul></li></ul><ul><li><p>第二大类【spatial-wise】</p><p>动机合理，vision task中，不是图像中所有区域都很重要，位置信息有冗余；且使用不同分辨率的图像效果也不同。由此动机，空间-wise分三类，<strong>像素自适应、区域自适应和分变量自适应</strong></p><ul><li><p>【像素自适应】，这个自适应又分动态结构、动态参数</p><ol><li><p>【动态结构】，例子是稀疏卷积，指的是只对图像上部分区域进行卷积，这些像素位置可以通过采样位置进行卷积或者先学习mask再卷积</p></li><li><p>【动态参数】</p><p>例一是每个像素位置生成不同的卷积核；</p><p>例二是每一层生成不同的卷积核，这样改变了每一层处理的感受野；</p><p>例三是动态特征，动态参数生成的是动态特征，因此跳过卷积核直接自适应加权像素位置</p></li></ol></li><li><p>【区域自适应】，对图像上不同区域区分，也是要区分图像上空间位置中的冗余信息。可以稀疏采样区域，或者用attention机制、RNN等网络递归学习每一层关注哪个区域</p></li><li><p>【分辨率自适应】这个同区域自适应，也是要区分空间位置中的冗余信息。但是它不是直接按位置来分，而是按照多尺度下，不同分辨率来自适应</p><ol><li>例一是，每一层都自适应选择分辨率尺度；</li><li>例二是，网络的结构级联分层，通过选择上下采样判断下一步使用哪个尺度的模型</li></ol></li></ul></li><li><p>第三大类【时间-wise】</p><p>针对有顺序的数据，如文本、音视频、TS。这个<strong>和流的关系最大</strong></p><ul><li>【文本处理任务】，静态方法的话，可以训练好一个RNN，持续预测后续词句。基于上游每层输出对下游网络影响不同的动机，可以改造成动态网络（很自然的想法就是DenseNet）<ul><li>RNN中中间状态动态更新：例一，不重要的信息可以直接跳层；例二叫做粗略更新，一般会调整隐层的深度或者宽度；例三，高尺度/层的RNN模块判断使用哪些低尺度模型传来的中间状态</li><li>NLP类任务也可以选择跳层/提前中止，或者甚至跳过文本中的部分片段</li></ul></li><li>【视频流任务】，视频流按帧成为TS数据。一种挺无语的处理方式是直接把每一帧编码成所谓特征向量，再当成一般的输入<ul><li>RNN类方法，和前面涉及RNN更新中间状态的方式基本一致</li><li>关键帧选取方法，即不用RNN训练处理判断每一帧。可以直接采样或者attention机制去选择关键帧</li></ul></li></ul></li><li><p>【训练优化策略】</p><p>后面的基本上只看了别人的博客。显然，如果只是动态参数，那么一样的梯度下降就可以；难的是各种结构上的变化怎么弄，即discrete decision making怎么优化，见仁见智了</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这次略读了综述&lt;em&gt;Dynamic Neural Networks: A Survey&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;阅读的&lt;u&gt;动机是觉得这个和动力系统有关系&lt;/u&gt;，不过读完了没什么感觉，大的感悟是玄学，小的感悟是和元学习、NAS、ODE、流什么的其实都有点关系，觉得框架不太优美，多而杂&lt;/p&gt;
&lt;p&gt;ps：其实没有读完，正文只读了前四大章，到优化训练前面。后面参考他人的博客了解了概览&lt;/p&gt;
&lt;p&gt;ps2：这次写作引入了缩放图片的&lt;a href=&quot;http://xring.info/2018/hexo-pic-size.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;方法&lt;/a&gt;，且兼容中文图片标题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读40】DnCNNs——经典去噪方法</title>
    <link href="http://maxliu245.github.io/2021/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB40%E3%80%91DnCNNs%E2%80%94%E2%80%94%E7%BB%8F%E5%85%B8%E5%8E%BB%E5%99%AA%E6%96%B9%E6%B3%95/"/>
    <id>http://maxliu245.github.io/2021/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB40%E3%80%91DnCNNs%E2%80%94%E2%80%94%E7%BB%8F%E5%85%B8%E5%8E%BB%E5%99%AA%E6%96%B9%E6%B3%95/</id>
    <published>2021-03-15T11:39:48.000Z</published>
    <updated>2021-03-15T13:09:30.279Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>顺着<a href="http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/">【论文略读39】与38相关文章</a>中的第二篇，即<a href="https://www.zhihu.com/people/chen-yun-jin-5" target="_blank" rel="noopener">陈运锦</a>老师的TNRD，找到了这篇文章</p></blockquote><a id="more"></a><h3 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h3> <img src="/2021/03/15/【论文略读40】DnCNNs——经典去噪方法/DnCNNs.png" title="DnCNNs"><p>该文名为Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising，是17年的<strong>TIP</strong>。所提模型是前向的denoising convolutional neural networks，即<font color="#000FFF">DnCNNs</font></p><p>作者是鼎鼎大名的<strong><a href="https://cszn.github.io/" target="_blank" rel="noopener">张凯</a></strong>、陈运锦老师、左老师、孟老师、港理工的<a href="https://www4.comp.polyu.edu.hk/~cslzhang/" target="_blank" rel="noopener">张磊</a>老师</p><ul><li>文献地址：<a href="https://ieeexplore.ieee.org/abstract/document/7839189" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/7839189</a> 或 <a href="https://arxiv.org/abs/1608.03981" target="_blank" rel="noopener">https://arxiv.org/abs/1608.03981</a></li><li>一作张凯提供的代码：<a href="https://github.com/cszn/DnCNN" target="_blank" rel="noopener">https://github.com/cszn/DnCNN</a></li><li>截至2021/03/15，该文在谷歌学术上引用量2868，TNRD的引用量为678，真的迪奥</li><li>根据参考文献中列出的博客来看，这篇文章可谓是图像去噪中的<strong>经典</strong>牛文了</li></ul><blockquote><p>注：由于先入为主，先看了几篇相关博客，讲得应该都没啥问题。所以就没有再在文章上花太多时间了，只是把实验外的部分读了一遍，没有再去思考什么，谨记于此</p></blockquote><h3 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h3><p>本文提出<strong>模型</strong>DnCNNs，针对图像去噪（本文是高斯噪声）<strong>问题</strong>，采用的<strong>网络</strong>是端到端学习带噪图和gt之间残差的CNN，其中不仅引入了<strong>学习残差</strong>的策略，还使用了<strong>BN</strong>（ batch normalization）策略。这样做的<strong>动机</strong>有以往模型的缺点（见图$(2)$下面）、CNN的良好性质、两种改进策略结合的优势、TNRD的启发，等等</p> <img src="/2021/03/15/【论文略读40】DnCNNs——经典去噪方法/DnCNNs-1.png" title="简单理不糙的强效结构"><p>本文除了用大量的实验验证了DnCNNs的性能，还有额外的对比实验，验证了<strong>残差学习和BN结合相互促进</strong>（或者说辅助）的优势，见原文图$(2)$：</p> <img src="/2021/03/15/【论文略读40】DnCNNs——经典去噪方法/DnCNNs-2.png" title="验证残差学习和BN结合相互促进"><p>它的<strong>优点</strong>为何？文章反复强调了以往方法的弱点，包括加深网络后<strong>训练难</strong>度加大、往往<strong>只能针对特定</strong>程度的特定噪声等。<strong>前者</strong>被残差学习加速训练➕BN缓解internal covariate shift（指训练过程中分布变化导致激活后梯度停滞，BN则通过激活前归一化使分布难偏移）以加速收敛给淦了；<strong>后者</strong>被DnCNNs的拓展模型gank了，借鉴TNRD的思想，对模型进行拓展，可以训练单个DnCNNs，同时解决Gaussian denoising，single image super-resolution和JPEG image deblocking三种问题</p><p>本文还有一些<strong>技巧</strong>，比如感受野和网络深度的选择，与TNRD的比较等，略</p><p>最后，本文的作者们表示，更genral的去更general噪的方法是研究的目标，目前来看，unfolding、plug-and-play（即插即用）模块设计等都是研究的方向</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising. IEEE Transactions on Image Processing, 26(7):3142–3155, 2017.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@article&#123;RN37,</span><br><span class="line">   author = &#123;Zhang, K. and Zuo, W. and Chen, Y. and Meng, D. and Zhang, L.&#125;,</span><br><span class="line">   title = &#123;Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising&#125;,</span><br><span class="line">   journal = &#123;IEEE Transactions on Image Processing&#125;,</span><br><span class="line">   volume = &#123;26&#125;,</span><br><span class="line">   number = &#123;7&#125;,</span><br><span class="line">   pages = &#123;3142-3155&#125;,</span><br><span class="line">   ISSN = &#123;1941-0042&#125;,</span><br><span class="line">   DOI = &#123;10.1109/TIP.2017.2662206&#125;,</span><br><span class="line">   year = &#123;2017&#125;,</span><br><span class="line">   type = &#123;Journal Article&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要参考的博客：</p><ol><li>有重要思考的博客：<a href="https://blog.csdn.net/ewen_lee/article/details/106851978" target="_blank" rel="noopener">【图像去噪】DnCNN论文详解（Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising）…</a></li><li>总结精辟的博客：<a href="https://blog.csdn.net/weixin_41923961/article/details/80382529" target="_blank" rel="noopener">DnCNN论文阅读笔记【MATLAB】</a></li><li>纯翻译：<a href="https://blog.csdn.net/u013049912/article/details/86609356" target="_blank" rel="noopener">Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising</a></li><li>讲了一点DnCNNs后续发展：<a href="https://zhuanlan.zhihu.com/p/94382390" target="_blank" rel="noopener">基于卷积神经网络的图像去噪</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;顺着&lt;a href=&quot;http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/&quot;&gt;【论文略读39】与38相关文章&lt;/a&gt;中的第二篇，即&lt;a href=&quot;https://www.zhihu.com/people/chen-yun-jin-5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈运锦&lt;/a&gt;老师的TNRD，找到了这篇文章&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Denoising" scheme="http://maxliu245.github.io/tags/Denoising/"/>
    
      <category term="CNN" scheme="http://maxliu245.github.io/tags/CNN/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读39】与38相关文章</title>
    <link href="http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/"/>
    <id>http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/</id>
    <published>2021-03-09T02:04:19.000Z</published>
    <updated>2021-03-14T16:09:14.374Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>截至2021/03/08，谷歌学术上引用林老师<em>Learning PDEs for Image Restoration via Optimal Control</em>的有46篇，打算抽上几篇看看，目前只看了3篇（有笔记的）</p><p>ps1：发现林老师此文引用量不高可能是因为没复现代码？</p><p>ps2：这次写作的时候发现，如果断网，本地localhost预览博客可能会出现公式无法渲染的问题</p></blockquote><a id="more"></a>  <h2 id="Adaptive-Partial-Differential-Equation-Learning-for-Visual-Saliency-Detection"><a href="#Adaptive-Partial-Differential-Equation-Learning-for-Visual-Saliency-Detection" class="headerlink" title="Adaptive Partial Differential Equation Learning for Visual Saliency Detection"></a>Adaptive Partial Differential Equation Learning for Visual Saliency Detection</h2><h3 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h3><p>这篇文章是刘日升林宙辰老师的CVPR2014的文章，百度显示至2021/03/09引用量131。标题表明本文提出的<strong>模型是自适应学习PDE</strong>，模型叫做Linear Elliptic System with Dirichlet boundary （<strong>LESD</strong>），<strong>目标是视觉显著性检测</strong></p><blockquote><p>注1：这个视觉显著性指的是图像中的重要区域，参考这个<a href="https://max.book118.com/html/2017/0607/112170172.shtm" target="_blank" rel="noopener">PPT</a>，比较清楚</p><p>注2：显著性后续似乎有别人的很顺眼的工作：参考<a href="http://dpfan.net/SOCBenchmark/" target="_blank" rel="noopener">Salient Objects in Clutter: Bringing Salient Object Detection to the Foreground</a></p><p>注3：读了本文之后觉得它似乎是尝试<strong>用传统CV方法解决近年来CV问题</strong>。。。好像<strong>没用神经网络</strong>耶</p></blockquote><p>文献地址参考：<a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Liu_Adaptive_Partial_Differential_2014_CVPR_paper.html" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_cvpr_2014/html/Liu_Adaptive_Partial_Differential_2014_CVPR_paper.html</a></p><h3 id="背景方法与动机"><a href="#背景方法与动机" class="headerlink" title="背景方法与动机"></a>背景方法与动机</h3><p>本文的target是显著性检测，分为<strong>bottom-up和top-down</strong>方法，前者是<strong>数据驱动</strong>，具体又有纹理特征判断、对比度判断等；后者是<strong>模型驱动</strong>，直接监督或者通过显著图（map）监督，等</p><p>本文的动机：</p><ul><li><p>这个target的问题不简单，要把人的感知（显著区域）和高级（复杂）的先验弄进PDE</p></li><li><p>林宙辰老师之前ECCV2010的工作有个缺点，对图像的刻画适合传统CV（参考GT的CV课程），对近年来的CV高级任务不合适</p><blockquote><p>ps：读了本文之后觉得它似乎是尝试用传统CV方法解决近年来CV问题。。。</p></blockquote></li></ul><h3 id="模型LESD与实验"><a href="#模型LESD与实验" class="headerlink" title="模型LESD与实验"></a>模型LESD与实验</h3><p>本文提出的模型叫Linear Elliptic System with Dirichlet boundary （LESD），是自适应学习PDE，此PDE的特点是<strong>假设</strong>了<strong>显著性扩散</strong>，<strong>学习的目标</strong>是LESD的<strong>公式形式和边界条件</strong>。具体扩散的<strong>假设是核心</strong>！</p><p>模拟了人的注意力机制，先注意到图像的一个极其显著的区域，即人注意到的初始区域，记为$\mathcal{S}$，称为<strong>显著性种子</strong>，然后用PDE模拟注意力转移（扩散）的过程。</p><p>下面开始建模，向量或者位置用粗体字母表示。设整个图片区域为$V$，可以由像素点$\mathbf{p}$或者像素块$\mathbf{p}$（超像素）组成；定义实值的<strong>注意力score函数</strong>，记为$f(\mathbf{p})\overset{def}{=}s_\mathbf{p}$，支集定义在$\mathcal{S}$上。那么在Dirichelet边界条件（$V$内$\mathcal{S}$外$f=0$）下，显著性（注意力）扩散的PDE方程为</p><script type="math/tex; mode=display">\displaystyle \dfrac{\partial f(\mathbb{p},t)}{\partial t}=F(f,\nabla f),\ f(\mathbf{g})=0,\ f(\mathbf{p})=s_{\mathbf{p}},\ \mathbf{p}\in \mathcal{S}. \tag{1}</script><p>其中$\mathbf{g}$是$V$之外的点，分数为0。$F$就是一个待定函数</p><p>这个score函数$f$对时间的偏导$F$定义为线性扩散项，$div(K_{\mathbf{p}}\nabla  f(\mathbf{p}))$，$K_{\mathbf{p}}$是一个非均匀度量张量，用于控制$\mathbf{p}$处的局部扩散率。人的感知怎么导入方程？用正则项，用$\mathbf{p}$的得分和引导图$g(\mathbf{p})$（此$g$是实值函数，非彼$\mathbf{g}$）的差异度量。。。即</p><script type="math/tex; mode=display">F(f,\nabla f)=div(K_{\mathbf{p}}\nabla  f(\mathbf{p}))+\lambda (f(\mathbf{p})-g(\mathbf{p})). \tag{2}</script><p>其中度量$K_{\mathbf{p}}$和引导图$g$是干什么的？前者和$f$的形式参考原文$(2.3)$节，后者参考原文$(3.2)$节。。。看的有点累，到处找概念。<strong>大概就是</strong>本文把图像看成超像素集合，构建了点集意义（即没有概率意义）上的<strong>无向图</strong>，在注意力区域内$\mathbf{p}$和其多个邻域内的点有连接，连接之间的度量代表扩散的程度，因此$K_{\mathbf{p}}$真的是个度量矩阵，矩阵则有高斯核决定；然后由$K_{\mathbf{p}}$和$g(\mathbf{p})$联合定义了$f(\mathbf{p})$，形式我觉得不重要不写了；最后引导图$g$比较麻烦，本文自己定义出了一个点属于前景的概率$f_f(\mathbf{p})$，乘上本文的参考文献$[34]$中提出的color prior map$f_c$和center prior map$f_l$，最后归一化得到所谓的引导图。我对它的意义不是很理解，只知道是把先验信息弄成像文中图$(3,4)$底部那样的图（取值为$[0,1]$），然后在PDE的约束下去优化得到注意力（显著性）区域</p><p>上面所述就是本文的LESD框架，接着假定注意力<strong>得分函数随时间不变</strong>！为什么？因为我们需要就是给定一张图片后，显著性固定，不随时间$t$变化🆗。由此令$(1)$式中的$F=0$，就是LESD的final形式。现在看这个方程的话，显著性信息就体现在$g$所在区域和$\mathcal{S}$区域的划分上，它们体现了人的感知先验和初始注意力区域的选择</p><p>最最后再说一下LESD模型的可行性：文章给出了定理$1$，它保证，在LESD的假设下，score函数$f$是单调次模函数，次模的概念可参考<a href="https://www.zhihu.com/question/34720027" target="_blank" rel="noopener">知乎问题</a>，但是具体定义为什么保证可行性我先<strong>不管了</strong>。。。</p><p>实验的话，实验部分不管了，我喜欢的是它展示了一些更改先验感知信息$g$，更改初始区域$\mathcal{S}$的例子，分别见图$(3,4)$。另外展示了实际数据实验的预测准确率等</p> <img src="/2021/03/09/【论文略读39】与38相关文章/1-1.png" title="先验信息引入、更改初始注意区域的实例"><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点</p><ul><li><p>动机不错，考虑更复杂的任务，ECCV2010的PDE形式不太合适了</p></li><li><p>模型LESD新颖，又是<strong>图</strong>的建立又是传统CV，还是很interesting的</p></li><li><p>文章表示LESD的公式中包含了bottom-up和top-down的先验信息。yysy确实既有模型驱动也有数据驱动</p></li><li><p>文章表示对LESD既有数值，也<strong>有理论</strong>分析</p></li><li>和之前ECCV2010小小<strong>对比</strong>了下，Discussion部分提了几句，二者target任务不同，本文的任务难一些；二者都是PDE学习，PDE的形式不同；训练的方式不同，10年的是稀疏回归，本文更像是<strong>古典CV</strong>，从文中算法$1$可以看出来，构造点的连接，然后优化也是离散的，<strong>没有涉及网络结构</strong>（应该没有）</li></ul><p>缺点的话，看不出来啥缺点，可以自圆其说（虽然我不太懂），无情的刷文机器。。</p><h3 id="自己的问题（待解决）"><a href="#自己的问题（待解决）" class="headerlink" title="自己的问题（待解决）"></a>自己的问题（待解决）</h3><p>文中提了一句PDE处理图像问题的<strong>合理性</strong>：the multiscale representation of images are indeed solutions of heat equation with different time parameters，我喵喵喵？迷迷糊糊明白一点，但是这个理论需要专门去了解么？</p><h2 id="Trainable-Nonlinear-Reaction-Diffusion-A-Flexible-Framework-for-Fast-and-Effective-Image-Restoration"><a href="#Trainable-Nonlinear-Reaction-Diffusion-A-Flexible-Framework-for-Fast-and-Effective-Image-Restoration" class="headerlink" title="Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration"></a>Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration</h2><p>这文章吓到我了，被干吐了。。</p><h3 id="文献信息-1"><a href="#文献信息-1" class="headerlink" title="文献信息"></a>文献信息</h3><p>本文是16年的TPAMI，一作<a href="https://www.zhihu.com/people/chen-yun-jin-5" target="_blank" rel="noopener">陈运锦</a>老师，从各方面的资料这个文章还是很猛的</p><ul><li>文献地址：<a href="https://ieeexplore.ieee.org/abstract/document/7527621" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/7527621</a></li><li>一作自己的评论：<a href="https://www.zhihu.com/question/62599196/answer/233376903" target="_blank" rel="noopener">https://www.zhihu.com/question/62599196/answer/233376903</a></li><li><a href="https://blog.csdn.net/qq_25196865" target="_blank" rel="noopener">_JoeZoe</a>关于<strong>TNRD</strong>模型的博客：<a href="https://blog.csdn.net/qq_25196865/article/details/78894051" target="_blank" rel="noopener">https://blog.csdn.net/qq_25196865/article/details/78894051</a></li><li>引用了此文的一个专利：<a href="http://www.xjishu.com/zhuanli/55/201810750492.html" target="_blank" rel="noopener">一种基于深度学习的自适应图像去噪方法与流程</a></li><li>代码实在是找不着，可能在<a href="https://github.com/leolee5633/Part-III-project" target="_blank" rel="noopener">这里</a>。。</li><li>TNRD的一个拓展<a href="https://epubs.siam.org/doi/abs/10.1137/16M1093707" target="_blank" rel="noopener">Image Denoising via Multiscale Nonlinear Diffusion Models</a>，大概就是在下面网络结构图里，第一次卷积前和第二次卷积后分别加一次下、上采样</li></ul><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><blockquote><p>这部分写得细但是乱，<strong>不利</strong>于展示！</p></blockquote><p>背景是图像恢复/修复问题，图像恢复方法的两个评价对象，修复质量和计算效率。本文在其中的PDE方法上进行改进，下面回顾一下本文主要参考的PDE方法：</p><p>刚开始的PM扩散方程</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dfrac{\partial u}{\partial t} &= div(g(|\nabla u|)\nabla u) \\ u|_{t=0} &= f \end{aligned} \right., \tag{3}</script><p>其中$f$是初始待恢复图像，$g$称为边缘停止（edge-stopping）函数或<strong>扩散函数</strong>，经典的是$\displaystyle g(z)=\dfrac{1}{1+z^2}$。PM扩散方程的特点是非线性各向异性扩散，可以保持和增强图像边缘，我也不知道为什么，但必和这个$div$的形式有关</p><p>从PDE的角度去改进，可以改进/选择的有扩散函数、方程的最优停止时间和合适的反作用力（反应扩散方程中的概念），由此，一般的形式如下，即加了正则$\kappa (u)$、系数$a$和各种不变量或者算子$\mathcal{O}(u)$，这个形式和先前林宙辰老师的文章一致：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dfrac{\partial u}{\partial t} &= \kappa (u) + a(t)^T\mathcal{O}(u) \\ u|_{t=0} &= f \end{aligned} \right.. \tag{4}</script><p>从传统CV处理图像的方式看，把图像展成列向量$u\in\mathbb{R}^N$，那么</p><script type="math/tex; mode=display">\displaystyle \nabla u\approx \dfrac{u_{t+1}-u_t}{\Delta t}=-\sum_{i=\{x,y\}}\nabla_i^T\Lambda(u_t)\nabla_iu_t\overset{\cdot}{=}-\sum_{i=\{x,y\}}\nabla_i^T\phi(\nabla_iu_t). \tag{5}</script><p>其中$\Lambda(u_t)=diag\left(g\left(\sqrt{(\nabla_xu_t)_p^2+(\nabla_yu_t)_p^2}\right)\right)_{p=1,\cdots,N}$是$N\times N$的对角阵，$g$是扩散函数，$\nabla_x$和$\nabla_y\in \mathbb{R}^{N\times N}$是$x,y$两个方向上的梯度的差分近似，这里算子为$N\times N$维，作用在$u_t\in\mathbb{R}^N$上很奇怪，<strong><font color="#FF0000">这一点我没看懂</font></strong>（<strong>懂了</strong>，见下一段），先跳过。另外定义的$\phi(z)=zg(z)$就是影响函数，也成为flux函数，似乎这个对角阵$\Lambda(u_t)$的元素是和$\nabla u_t$的分量一一对应的，<strong><font color="#FF0000">这一点我也没看懂</font></strong>，先跳过</p><p>上面是基本的反应扩散方程模型，扩散的过程对应求能量泛函（也可以说是惩罚项）$\displaystyle \mathcal{R}=\sum_{i\in\{x,y\}}\sum_{p=1}^N\rho((k_i<em>u)_p)$的极小，但是<strong><font color="#FF0000">为什么是惩罚项是这样的呢</font></strong>？其中函数$\rho$就是惩罚项，如$\rho(z)=\log(1+z^2)$，不知道这里$\rho^\prime (z)=\phi (z)$有没有什么意义。另外注意这里$\nabla_xu$是<em>*矩阵和向量的积</em></em>，对应线性滤波$k_x=[-1,1]$的作用，确实，从差分的角度看这样是合理的，同理$\nabla_y$对应线性滤波$k_y=[-1,1]^T$的作用</p><h3 id="TNRD小结"><a href="#TNRD小结" class="headerlink" title="TNRD小结"></a>TNRD小结</h3><p>本文针对图像恢复问题，提出<strong>模型</strong>TNRD，即标题里的Trainable Nonlinear Reaction Diffusion。它的模型<strong>核心/idea</strong>是在反应扩散方程中使用了时变的线性滤波器和影响函数（influence function）；<strong>动机</strong>是尽管最近（16年前）的PDE方法在许多图像处理任务中表现出良好的性能，但它们仍然不能为经典的图像恢复任务产生最先进的质量；<strong>优化</strong>方法是数据驱动，直接最小化损失函数。进行的<strong>实验</strong>有三个， 高斯图像去噪、单图超分辨、和JPEG deblocking，具体实验很多先不看了</p><p>TNRD模型的细节还是比较多的，所以还是决定小结一下</p><p>整体的general TNRD模型如<a href="https://blog.csdn.net/qq_25196865/article/details/78894051" target="_blank" rel="noopener">博客</a>所述，其实就是：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \min_{\Theta} &= \sum_{s=1}^S \frac{1}{2}||u_T^s-u_{gt}^s||_2^2 \\ s.t. &\left\{ \begin{aligned} u_0^s &= I_0^s\\ u_t^s &= Prox_{\mathcal{G}}\left(u_{t-1}^s-\left(\sum_{i=1}^{N_k}(K_i^t)^T\phi_i^t(K_i^tu_{t-1}^s)+\psi^t(u_{t-1}^s,f^s)\right)\right) \\ t &= 1,\cdots,T\end{aligned} \right. \end{aligned} \right.. \tag{5}</script> <img src="/2021/03/09/【论文略读39】与38相关文章/2-1.png" title="TNRD的网络结构解释"><p>优化目标中的$u_{gt}$指ground truth图像，$u_{T}$是方程最后一个stage（第$T$个，一共也是$T$个stage）的输出，$s$指有这么多样本，训练集一共$S$张图像，目标也可以使用其它的loss，应该是的🤔；$(5)$式中的条件是general的TNRD，$I_0^s$指第$s$个样本对应的初始带噪图像，是输入的初值</p><p>然后要分析最长的那个式子，它也是最复杂的，还是建议参考文章的图$(1)$来理解，如上图。对第$t-1$个stage的第$s$个样本$u_{t-1}^s$的操作如上图蓝色方框所示，对应关系直接给出来，也省得我写一堆字了。其中要<strong>注意</strong>，网络结构中，第二个卷积（即对应线性滤波）和第一个卷积有关联，注意看第二个卷积头上有一$\bar{}$，表示是把第一个卷积<strong>旋转</strong>了$180^\circ$！最后最外层的$Prox_{\mathcal{G}}$叫proximal mapping operation，具体公式参考原文图$(1)$下面的公式，它套在最外面是为了让里面的式子可求导，所以用这个所谓的近似映射，怎么近似的就不管啦</p><font color="#0000FF">最后提一下设置这样形式的反应扩散方程的道理，首先要强调的一点是**这种结构是从传统算法推导出来的**，思路就是从上文的背景模型一步步推出方程，然后里面的反应项（force项）和扩散项就这样设计了。。。我觉得还是从$\nabla u$的离散近似出发，设置成线性滤波的形式，后面的force项则引入影响函数，这样设计出来的，真是的思路还是要参考以前的文献了，此处估计日后不怎么看了</font><blockquote><p>作者原话，来自知乎：</p><p>这种网络结构是从传统算法推导出来的，不是刻意设计的，然后恰好就和<em>EDSR</em>的<em>residual block</em>的结构相似啦。那是不是意味着<em>EDSR</em>的<em>residual block</em>的结构选择成目前这个样子，效果就好，有一些深层次的原因呢？需要paper的筒子们刻意挖一挖嘛。</p></blockquote><p>另外有个trick是网络中的非线性激活函数由基函数拟合出，文中是63个高斯径向基函数线性组合，这样组合出来的非线性函数的形状可以比较任意，我<font color="#0000FF">寻思着这会增加计算复杂度</font>（不像是提前决定好的啊）啊</p><p>至于训练方法什么的，再见，叭看！</p><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p>它的优点有：</p><ul><li>是个灵活的可学习框架，是有线性滤波和影响函数的非线性反应扩散模型</li><li>调整结构可以适用于多种图像恢复中的任务（如提到的3个实验）</li><li>模型保持了非线性扩散模型的结构简单性，并且只需要少量的扩散步骤，因此高效</li><li>似乎是因为结构简单性，可在GPU上高速训练</li><li>文章表示较好地平衡了计算效率和去噪质量的关系（难道是实验的观察结论）</li></ul><p>缺点：</p><ul><li><p>是基于先验知识的分析模型，在获取图像全部特征结构时受到限制，以及在整个训练阶段需要手动的微调参数，此外这些方法训练出的模型都是针对已知具体的噪声级，无法实现未知噪声级图像的盲去噪</p><blockquote><p>这些话是引自一个专利的，参考<a href="http://www.xjishu.com/zhuanli/55/201810750492.html" target="_blank" rel="noopener">一种基于深度学习的自适应图像去噪方法与流程</a></p></blockquote></li><li><p>文章自己表示，本文TNRD只适合监督，这似乎不算什么缺点。。</p></li><li><p>另外我有不少问题，不见得是缺点吧，<strong>见上文的彩色字体部分</strong></p></li></ul><h2 id="Toward-designing-intelligent-PDEs-for-computer-vision-An-optimal-control-approach"><a href="#Toward-designing-intelligent-PDEs-for-computer-vision-An-optimal-control-approach" class="headerlink" title="Toward designing intelligent PDEs for computer vision: An optimal control approach"></a>Toward designing intelligent PDEs for computer vision: An optimal control approach</h2><h3 id="文献信息-2"><a href="#文献信息-2" class="headerlink" title="文献信息"></a>文献信息</h3><p>这篇文章是刘日升、林宙辰老师等于11年提交，12年接收，发在Image and Vision Computing这个刊上的</p><p>文献地址：<a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885612001746" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/S0262885612001746</a></p><p> 观标题，是用PDE解图像处理问题，这次准备了一个自己去找的框架，不知道是不是又是字典稀疏回归，且待分解~是的，要学习的<strong>与时间$t$相关</strong>的系数，而且字典大得一批。。</p><img src="/2021/03/09/【论文略读39】与38相关文章/3-1.png" title="本文稀疏回归使用的字典"><h3 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h3><p>这个文章年限摆在那里，<strong>方法</strong>还是一个以PDE为条件的优化问题。考虑自动从数据中学习限制条件PDE，<strong>动机</strong>是视觉任务的intuition和手动设计PDE不优美，另外考虑把适合多数视觉任务的不变性当成基本的不变量扔进方程。PDE仍然是要学习<strong>不变量</strong>的<strong>系数</strong>，其中最高考虑的是2阶的不变量，这个阶指的是导数的阶，主要包括<strong>平移和旋转不变性</strong>。优化的目标是正常的loss，输出用ground truth监督</p><h3 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h3><p>这个自动学习PDE的框架有个特点，考虑了<strong>两组</strong>PDE方程，一个方程用来控制输出图像$u$的变化（evolution）过程；另一个作为所谓的indicator函数$v$，它学习图像的全局特征，<strong>辅助监督</strong>第一个方程。它的形式如下所示：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} &\dfrac{\partial u}{\partial t} = F_u(u,v,\mathbf{a}),\ (x,y,t)\in Q, \\ &u(x,y,t) = 0,\ (x,y,t)\in \Gamma, \\ &u|_{t=0} = f_u,\ (x,y)\in \Omega. \\ &\dfrac{\partial v}{\partial t} = F_v(v,u,\mathbf{b}),\ (x,y,t)\in Q, \\ &v(x,y,t) = 0,\ (x,y,t)\in \Gamma, \\ &v|_{t=0} = f_v,\ (x,y)\in \Omega.\end{aligned} \right.. \tag{6}</script><p>如上，直接的观察结论是$u$和$v$的演化都用$F$表示，但是内容可能不同。不过本文中，都还是各种不变量的线性组合</p><p>由动机，手动设计PDE，不仅可能只适用少数问题，还很麻烦。因此只说，<strong>平移不变性和旋转不变性</strong>是大多数vision task的<strong>共性</strong>，若要保持这些性质，PDE方程的形式需要是平移、旋转这样的算子下不变的（有点像群在集合上作用那味儿），也是这些不变量的函数，依据是文章引用的<em>微分不变量理论</em>。。。</p><p>文章声明最高考虑的是2阶的不变量，其理由主要在于更高阶的不变量会有数值问题，以及字典太大导致计算复杂，还有当模型<strong>拓展为针对三通道图像</strong>时字典更是加大</p><p>PDE方程就是这样，没啥。对于优化，优化的目标函数（能量泛函）也很正常，是gt的监督以及两组系数$\mathbf{a,b}$的正则。优化的方法仍然是伴随方法，推导G导数，然后近似迭代</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>优点：</p><ol><li>相比原始的10年文章，这个框架引入的不变量更多，还包括一些耦合的不变量，因此框架适用于更多vision task，包括边缘检测、去噪、修复，etc</li><li>这个证了不变量具有的平移和旋转不变性（没看）</li></ol><p>所以说这个文章算是10年那个文章的<strong>直接推广</strong>，PDE在形式上增广了，加了些不变性理论，加了些实验</p><p>最后，注意下几个小知识点：</p><ol><li>文中提到一个有意思的思路叫<em>Multi-layer PDE systems</em>，每层PDE的形式相同，即最多二阶的不变量的线性组合。但每一层的参数值和初值不同，具体采用贪婪策略学习多层结构，即每一层确定后，用上一层的输出作为下一层的输入。每一层的预期输出都是gt！那么由于每一层都在逼近gt，这样做可能能<strong>连续地提高近似的精度</strong></li><li>突然意识到，这些基于PDE的方法和<strong>水平集</strong>拓展方法的设计思想没什么区别啊！</li></ol><h2 id="其它暂未阅读的文献"><a href="#其它暂未阅读的文献" class="headerlink" title="其它暂未阅读的文献"></a>其它暂未阅读的文献</h2><ul><li>董彬老师组18年PMLR的<a href="http://proceedings.mlr.press/v80/lu18d.html" target="_blank" rel="noopener">Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations</a></li><li>剑桥的奇怪杂志Acta Numerica上的<a href="https://www.cambridge.org/core/journals/acta-numerica/article/solving-inverse-problems-using-datadriven-models/CE5B3725869AEAF46E04874115B0AB15?__cf_chl_jschl_tk__=58c78f0b80836ffecb5c616c191f72229855d968-1615168268-0-AbGsCfjDCGWPcOgqc6G8cxdlSM63cp31QBNUZo6CojNnGl9t9bVPq7a7Go3_OCjrA7kNQW4KlxVvgcy4y3QBD1VGcBltZpX1hyW_goa8Ttr4ckII-npANh-NDlEbTnJXHurph-0Sqvinh3WLs9k0fGVP7pdp6IOIMJg1c-5m9nHwSkwPtjcd4-7gFB7qTBUwZl-LyIHYip6-5bhNE4FOFeus1eZ50MZVoJZslP3Wgx9pm_-uXaGRJqtsZr37cEpjKD9riKLSl9VJI-HeTWrJ0gtfMKdrwoJwA233iklZ_KGsmkJDpY71Ud3ngVIlwoVdFlFIxX6DtX6t9_-vRNhxbyZF-KU5FpOIsknLlVw_rZ52u7j9BBA4AVatjl3KFD_IYrjJ2ij5iL3cRk-ILUWKAF7CXwY_p2_6bgPXIfnFt0NqGemTbND91TildOhUg6YVvCkhhFItAhYZyLOYVeobbbwHpxOapeRM85OMYRPeE9agati9v2VN8zHF_lBSdFTjKc3LxBZPhW3uBID7qmmPRTolcbubz0XVL6CnFzIqs-R-" target="_blank" rel="noopener">Solving inverse problems using data-driven models</a>，不打算看了，174页，像是综述+写书</li><li>老师一作在CVPR2015上的<a href="https://openaccess.thecvf.com/content_cvpr_2015/html/Chen_On_Learning_Optimized_2015_CVPR_paper.html" target="_blank" rel="noopener">On Learning Optimized Reaction Diffusion Processes for Effective Image Restoration</a></li><li>Neural Computing and Applications 2018上的<a href="https://link.springer.com/article/10.1007/s00521-016-2623-y" target="_blank" rel="noopener">Learning sparse partial differential equations for vector-valued images</a></li><li>ICASSP 2019上的<a href="https://ieeexplore.ieee.org/abstract/document/8682944" target="_blank" rel="noopener">Learning Compact Partial Differential Equations for Color Images with Efficiency</a></li><li>刘日升老师的Valse课件<a href="http://valser.org/webinar/slide/slides/20141022/LPDE_RishengLiu.pdf" target="_blank" rel="noopener">Learning-Based PDE: A New Perspective for PDE Methods in Computer Vision</a></li><li>西交孙剑老师的Review，中国工业与应用数学学会，received on 22 April 2020；accepted on 16 June 2020，<a href="https://doc.global-sci.org/uploads/Issue/CSIAM-AM/v1n3/13_365.pdf?1603081030" target="_blank" rel="noopener">Model Meets Deep Learning in Image Inverse Problems</a></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Risheng Liu, Junjie Cao, Zhouchen Lin, and Shiguang Shan. Adaptive partial differential equation learning for visual saliency detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2014.</p><p>[2] Y. Chen and T. Pock. Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(6):1256–1272, 2017.</p><p>[3] Risheng Liu, Zhouchen Lin, Wei Zhang, Kewei Tang, and Zhixun Su. Toward designing intelligent pdes for computer vision: An optimal control approach. Image and Vision Computing, 31(1):43–56, 2013.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;截至2021/03/08，谷歌学术上引用林老师&lt;em&gt;Learning PDEs for Image Restoration via Optimal Control&lt;/em&gt;的有46篇，打算抽上几篇看看，目前只看了3篇（有笔记的）&lt;/p&gt;
&lt;p&gt;ps1：发现林老师此文引用量不高可能是因为没复现代码？&lt;/p&gt;
&lt;p&gt;ps2：这次写作的时候发现，如果断网，本地localhost预览博客可能会出现公式无法渲染的问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读38】重读Learning PDEs for Image Restoration via Optimal Control</title>
    <link href="http://maxliu245.github.io/2021/03/07/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB38%E3%80%91%E9%87%8D%E8%AF%BBLearning-PDEs-for-Image-Restoration-via-Optimal-Control/"/>
    <id>http://maxliu245.github.io/2021/03/07/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB38%E3%80%91%E9%87%8D%E8%AF%BBLearning-PDEs-for-Image-Restoration-via-Optimal-Control/</id>
    <published>2021-03-07T14:44:12.000Z</published>
    <updated>2021-03-07T15:36:44.569Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>近日重读<em>Learning PDEs for Image Restoration via Optimal Control</em>，确认下本文的目标和做法</p><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2> <img src="/2021/03/07/【论文阅读38】重读Learning-PDEs-for-Image-Restoration-via-Optimal-Control/1.png" title="林老师的文章"><p>本文<em>Learning PDEs for Image Restoration via Optimal Control</em>是林宙辰老师等人在ECCV2010的文章，引用量没有查，应该不低，毕竟很经典</p><p>文献参考链接地址：</p><ul><li><p><a href="http://www.cvpapers.com/eccv2010.html" target="_blank" rel="noopener">http://www.cvpapers.com/eccv2010.html</a></p></li><li><p>官方博客：<a href="https://zero-lab-pku.github.io/publication/limingjie/eccv10_learning_pdes_for_imge_restoration_via_optimal_control/" target="_blank" rel="noopener">https://zero-lab-pku.github.io/publication/limingjie/eccv10_learning_pdes_for_imge_restoration_via_optimal_control/</a></p></li><li>陆一平的推荐：<a href="https://zhuanlan.zhihu.com/p/51514687" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51514687</a></li></ul><h2 id="文献内容"><a href="#文献内容" class="headerlink" title="文献内容"></a>文献内容</h2><p>本文学习PDE的基本目标（和我想得差不多），为图像相关任务自动设计合理的PDE</p><p>背景方法有2类，<strong>变分方法</strong>和<strong>直接设计</strong>PDE。变分方法的思路是用能量泛函学习图像的先验知识，一般是正则或其它先验模型；直接设计很暴力麻烦，对PDE中算子类型有所要求。两者应该（我的解读）都要保证图像的<strong>全局几何性质</strong>，对应PDE中的<strong>正则先验模型</strong>；然后保持一些变换下的<strong>不变性</strong>，对应各种<strong>微分不变量</strong>的线性组合</p><p>由此，本文的模型，称为<strong>可学习PDE</strong>（L-PDE），基本的形式如文中$(1)$式：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dfrac{\partial u}{\partial t} &= L(u,a) = \kappa(u)+F(u,a),\ (x,y,t)\in Q \\ u &= 0,\ (x,y,t)\in \Gamma \\ u|_{t=0} &= f,\ (x,y)\in \Omega \end{aligned} \right. \tag{1}</script><p><strong>本文要学习的目标</strong>和我想的是一样的，是正常PDE<strong>右边的方程</strong>，本文把它的形式设置为如上所示的正则先验项和数据驱动的几何不变量项。PDE的边界条件就是图像边界像素（假定填充为0）。式子中前者用的似乎是（我没看过）经典的TV-正则；后者其实很简单，如文中表$(2)$，几何不变量设置了5个，原始图像、输出图像、光滑程度等等。知道是这样做的即可，表格列在这里，细节不多</p> <img src="/2021/03/07/【论文阅读38】重读Learning-PDEs-for-Image-Restoration-via-Optimal-Control/2.png" title="图像在简单变换下的不变量"><p>学习过程就是学习几何不变量的系数，有个目标函数，优化方法是<strong>伴随方法+对能量泛函求G导数</strong>。。。当场🈚了，这部分<strong>还没研究透</strong>。。。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p><ul><li><p>L-PDE的形式可以概括本文之前的很多PDE模型</p></li><li><p>框架不错，模型假设和思路清晰</p></li></ul><p>缺点：</p><ul><li><p>个人疑问这几个几何不变量够么？？</p></li><li><p>代码当时未公布，<a href="https://zero-lab-pku.github.io/publication/limingjie/eccv10_learning_pdes_for_imge_restoration_via_optimal_control/" target="_blank" rel="noopener">官方博客</a>没给，现在似乎也搜不到。。</p></li></ul><h2 id="和PDE-Net共通之处"><a href="#和PDE-Net共通之处" class="headerlink" title="和PDE-Net共通之处"></a>和PDE-Net共通之处</h2><p>本来想和PDE-Net，结果发现以前的博客没有更。。。所以草草记录一下，手头上只有这个笔记：</p><p>PDE-Net 的motivation是pde轨线的拟合预测以及微分算子的估计，为此先估计导数再拟合轨线；2.0 的改进是修改了拟合轨线的网络，使用的是各阶导数组成的多项式的形式</p><p>这样看应该都是在学习PDE右边的式子</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日重读&lt;em&gt;Learning PDEs for Image Restoration via Optimal Control&lt;/em&gt;，确认下本文的目标和做法&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读37】Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</title>
    <link href="http://maxliu245.github.io/2021/03/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB37%E3%80%91Very-Deep-VAEs-Generalize-Autoregressive-Models-and-Can-Outperform-Them-on-Images/"/>
    <id>http://maxliu245.github.io/2021/03/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB37%E3%80%91Very-Deep-VAEs-Generalize-Autoregressive-Models-and-Can-Outperform-Them-on-Images/</id>
    <published>2021-03-03T01:04:03.000Z</published>
    <updated>2021-03-03T01:19:44.533Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>阅读文献<em>Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</em></p><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><p>标题<em>Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</em>，发表于ICLR2021的<strong>spotlight</strong></p><p>文献链接</p><ul><li><a href="https://openreview.net/forum?id=RLRXCV6DbEJ" target="_blank" rel="noopener">https://openreview.net/forum?id=RLRXCV6DbEJ</a> （审稿意见先不看了）</li><li><a href="https://arxiv.org/abs/2011.10650" target="_blank" rel="noopener">https://arxiv.org/abs/2011.10650</a></li><li><a href="https://github.com/yaminibansal/vdvae" target="_blank" rel="noopener">https://github.com/yaminibansal/vdvae</a></li><li><a href="https://github.com/openai/vdvae" target="_blank" rel="noopener">https://github.com/openai/vdvae</a></li></ul><h2 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h2><p>本文基于下列动机/idea：</p><ol><li><p>自回归的归纳偏置不好，暴力找变量相关性；而VAE生成过程更明朗，二者关联性存在</p></li><li><p>由1，VAE可以弄成自回归模型，深度的可进一步完成其它生成模型</p><p>这里面有个idea是自回归模型约等于分层VAE+强先验，由此VAE弄成自回归</p></li><li><p>背景是一系列生成模型，如自回归、VAE、可逆流，这些模型都很好</p></li></ol><p>针对VAE、流模型相关的表示学习改进问题，通过设计深度VAE，调整其结构和优化技巧，成功把VAE拓展为有效的生成模型，效果绝佳</p><blockquote><p>PS：这里自回归忘了是啥了，大概是生成过程的强先验，所以此拓展合</p></blockquote><p>本文使用的深度VAE其实就是加深VAE，但是通过网络的设计和优化技巧使之能有效地加深</p><p>网络的设计大概就是使用top-down假设；只用高斯随机层、卷积层和非线性层；有不太明白为什么work的scaling和nearest-neighbor upsampling技巧。优化技巧就是解决VAE优化难的方式，本文用的是高梯度略掉（阈值），称为GRADIENT SKIPPING，但是我很好奇不管它越来越大咋办，估计本文的理论附录有什么证明吧</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>本文的优点：</p><ol><li>写作清晰，摘要一看就nb，性能优异吸引人，深度VAE干了什么也介绍了七七八八；后续模型来龙去脉也很清楚，层层推进</li><li>动机合理</li><li>后续对深度VAE有分析，对生成过程可视化</li><li>文章第6节末尾给了大量模型的对比</li><li>在CIFAR-10、ImageNe、FFHQ上实验的结果（对数似然、参数量、生成速度1000倍）优于PixelCNN</li><li>深度VAE可进一步完成其它生成模型</li><li>藉VAE可生成高分辨图像，原因应该是VAE有效的分层表示学习</li><li>文章第1节末尾前两个优点</li></ol><p>缺点想不出来。。大概是top-down的结构有无操作空间？好像没有。。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>一些实验的细节显示</p><ul><li>总层数相同，深度增加时，参数量不变，泛化误差减小</li><li>网络结构不变时，初始图像分辨率（大小）增加时，泛化误差减小</li><li>实验过程中先生成全局特征，再学习局部特征，图像变为高分辨</li><li>实验主要是验证生成过程的有效性，合理性，并且检验了哪些因素（如分辨率）对模型的影响</li></ul><h2 id="部分感悟"><a href="#部分感悟" class="headerlink" title="部分感悟"></a>部分感悟</h2><p>我参考的地方</p><ul><li><p>对大量模型的比较方式</p></li><li><p>文章第2节开头对VAE的表述</p></li><li><p>文章第2节先修知识表示，VAE相关方法本身效率相对有些问题，可能有两个原因：</p><ul><li>观测之间要相互独立✔</li><li>不要完全分解分布，可以假定生成过程，本文用的是分层VAE，就是隐变量是top-down的模式，方式应该是使用随机层。这是合理的，有这样的明确意义，从底层特征过渡到高层特征，且隐变量的生成有随机性，带来自由性</li></ul></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Rewon Child. Very deep VAEs generalize autoregressive models and can outperform them on images. In International Conference on Learning Representations, 2021.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;阅读文献&lt;em&gt;Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images&lt;/em&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读36】Dissecting NODEs</title>
    <link href="http://maxliu245.github.io/2021/03/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB36%E3%80%91Dissecting-NODEs/"/>
    <id>http://maxliu245.github.io/2021/03/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB36%E3%80%91Dissecting-NODEs/</id>
    <published>2021-03-01T07:16:24.000Z</published>
    <updated>2021-03-02T07:19:09.516Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>读了好久，不少地方困住了</p><p><em>Dissecting Neural ODEs</em></p></blockquote><a id="more"></a><p>这篇文章大概20年上半年就在<a href="https://arxiv.org/abs/2002.08071" target="_blank" rel="noopener">arXiv</a>上挂出来了，后来才知道中了<a href="https://proceedings.neurips.cc/" target="_blank" rel="noopener">NeurIPS</a>2020，作者日韩，文献地址：<a href="https://proceedings.neurips.cc/paper/2020/hash/293835c2cc75b585649498ee74b395f5-Abstract.html" target="_blank" rel="noopener"><em>Dissecting Neural ODEs</em></a></p><p>如题，本文试图解剖NODE，确实从很多角度给出了一个general的增广NODE框架，总结了一系列的相关模型！</p><h2 id="内容大纲"><a href="#内容大纲" class="headerlink" title="内容大纲"></a>内容大纲</h2><p>这篇文章的主要目的是分（解）析（剖）一下NODE，给出了一个general的NODE框架，叫<strong>general system-theoretic Neural ODE formulation</strong></p><p>文献的背景/idea：</p><ul><li>最近两年来比较有意思的连续深度学习模型NODE解剖分析的需求，需要简明解释NODE结构</li></ul><p>整体的框架是$(1)$式</p> <img src="/2021/03/01/【论文阅读36】Dissecting-NODEs/DNODEs-1.png" title="general system-theoretic Neural ODE formulation"><p>进一步分析这个框架是如何general的。具体分了三大块：</p><ul><li>Depth-Variance<ul><li>基本的idea是NODE不能作为无限近似的连续模型，为什么？当结论看着吧，不过确实参数化更rich</li></ul></li><li>增广策略<ul><li>基于ANODE的增广策略，可以退化为ANODE</li><li>在框架下，分为：<ul><li>对输入层增广</li><li>高阶信息增广</li></ul></li></ul></li><li>增广之外<ul><li>动机是对$\varphi(x)=-x$或者同心环问题，不一定需要增广，由此提出了2种模型：<ul><li>data control</li><li>adaptive depth</li></ul></li></ul></li></ul><h2 id="基于NODE的连续系统"><a href="#基于NODE的连续系统" class="headerlink" title="基于NODE的连续系统"></a>基于NODE的连续系统</h2><p>标题即文中<strong>Continuous–Depth Models</strong>部分，这算是框架的一个背景模型，其实就是回顾NODE。只不过这里的说法指的是general形式的NODE，即添加了输入层$h_x$和输出层$h_y$</p><p>主要回顾了general的连续ODE系统、适定性即解的存在唯一性、训练方法Adjoint</p><h2 id="Depth-Variance"><a href="#Depth-Variance" class="headerlink" title="Depth-Variance"></a>Depth-Variance</h2><p>Depth-Variance指的是啥没读懂，depth和variance应该分别指每个深度（层）和其参数不同，后者应该不是方差的意思</p><p>它的动机是最原始的NODE，虽然说是连续系统模拟，但是即使网络足够深<strong>也不能说</strong>是ResNet的极限，注意这个说法。一个简单的理解是ResNet的每一层的残差模块都应该有自己的参数，记为$\theta_s$，$s$在这里特指为层数，或者说<strong>depth</strong>。这样的话，general的深度ResNet应该至少是$\dot{z}=f_{\theta_s}(s,z(s))$的形式，包括了所有层的变化规律</p><blockquote><p>注：文中表示试图达到ResNet的deep极限的最初尝试就是hypernetwork，日后请浏览！</p></blockquote><p>本文表示直接参数化的做法，在理论上存在弱点。本文藉此考虑<strong>泛函空间中的梯度下降</strong>，直接视$\theta_s$函数存在于一（较）般（大）的函数空间中，这样的空间又往往是无穷维的，所以函数空间中的梯度下降就要算<strong>G导数</strong>，然后拓展使用Adjoint方法的过程中发现无穷维的时候不会算这个导数。</p><p>因此需要进行有限维空间中的近似，具体的做法给了两种，一种是采用有限多个正交基展开$\theta_s$；另一种是暴力地让$\theta_s$分多段常值。这两种方法分别叫<em>Spectral discretization: Galërkin Neural ODEs</em>和<em>Depth discretization: Stacked Neural ODEs</em>。它们从不同的角度参数化了网络模型的参数，增强了表达的能力，对，应该是这样</p><h2 id="增广策略"><a href="#增广策略" class="headerlink" title="增广策略"></a>增广策略</h2><p>本文对NODE相关的增广研究都基于ANODE，要强调的一点是ANODE只是单纯增广了维度，这种增广称为<strong>0-增广</strong>。如果细化一点增广的是什么，可能能得到general的增广策略</p><h3 id="输入层增广"><a href="#输入层增广" class="headerlink" title="输入层增广"></a>输入层增广</h3><p>注意general框架中的$z(0)=h_x(x)$，这就是输入层增广，称为<strong>IL-NODE</strong>，IL表示输入层</p><p>0-增广看成把输入$x$增广为$[x,0]$，然后转化为隐变量（顺序可看成反过来），其中$x$和$0$都是向量；那么输入层增广就是把输入$x$增广为$h_x(x)$，$h_x$取普通网络即可，再在框架中和$s,x$合并为正式输入</p><p>这样的话0-增广就是IL-NODE的一个特例，即$h_x(x)\overset{def}{=}[I,0]x$，维度省略，意思是明显的</p><p>进一步，我在增广策略开头提到<code>细化一点增广的是什么</code>，举个例子，如果让$x$的前多少维度反映重要信息，比如$x$本身信息，后面的维度增广为高阶信息，那增广就能引入微分方程中的高阶导数信息</p><h3 id="高阶信息增广"><a href="#高阶信息增广" class="headerlink" title="高阶信息增广"></a>高阶信息增广</h3><p>高阶信息增广指的是<strong>Higher–order</strong> Neural ODEs，这样增广的<strong>动机</strong>是提高参数效率</p><p>本来只有隐变量$z_1=z_q$，用网络从$z_1$生成$z_2=z_p$，作为$\dot{z}_1$，然后加一个二阶信息（方程）$\dot{z}_2=\ddot{z}_1$，即文章中的$(6)$式，$(7)$式是高阶信息增广合并到一起的写法：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dot{z}_1 &= z_2(s) \\ \dot{z}_2 &= f_{\theta (s)}(s,z_1(s),z_2(s)) \end{aligned} \right.,\ where\ z(s)=[z_1(s),z_2(s)]. \tag{6}</script><script type="math/tex; mode=display">\displaystyle \dfrac{d^nz^1}{ds^n}=f_{\theta (s)}\left(s,z,\dfrac{dz^1}{ds},\cdots,\dfrac{d^{n-1}z^1}{ds^{n-1}} \right),\ where\ z=[z^1,z^2,\cdots,z^n],\ z^i\in\mathbb{R}^{\frac{n_z}{n}}. \tag{7}</script><p>为什么这样合并的形式提高了参数效率呢？此时注意$(7)$式中关键的函数$f_{\theta (s)}$的输出只需要是原来的$\frac{1}{n}$即可，这就是原因了</p><p>进一步推广不太好弄，一直加高阶信息的话需要增加的维度也很多，而且意义也不大了。一个做法是选择出重要的维度来存储信息</p><h3 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h3><p>文中给出了一些实验，表明了这些增广模型都是有效的，一定程度上提高了计算效率</p><p>用了两个<strong>评价指标</strong>，分别是NFE（number of function evaluations），越小越好；和参数量</p><h2 id="增广之外"><a href="#增广之外" class="headerlink" title="增广之外"></a>增广之外</h2><p>这一部分看似有点奇怪，但动机良好，对$\varphi(x)=-x$（称为<strong>reflection</strong>）或者同心环问题，不一定需要增广策略，由此提出了2种模型，<strong>data control</strong> NODE和<strong>adaptive depth</strong> NODE</p><p>对于data control，文章先举了一个例子，对于reflection，控制$z(0)=x$，然后去学习$z(1)$，让$z(1)$随初值的变化而变化，这样学出了$-x$这个函数。这个例子是在框架下的</p><p>然后举了一个data control的归一化流的例子，没看懂。。。但是我觉得这个data control的思路是让初值变化，其实就是一种输入层增广，这样对多个初值能学习到很多条流，这些流被data control，学习到目标函数。这个时候不需要在意轨线可能相交的原因应该是<strong>哪里避免了流在同一时刻达到交点</strong>，这个精妙的地方没有读懂。。</p><p>第2种模型是adaptive depth，字面意思是控制网络深度。差不多，它控制的是积分的上下限，如文中$(5.2)$节的积分上限$g(w)$，把要积到什么时候用网络来参数化，同样<strong>避免了流在同一时刻达到交点</strong>，它能做到的原因应该是学习了一系列的流，但是各自的积分时长其实都是自适应学习的，时刻也有所变化🤔</p><hr><p>最后，文章提了一个东西，叫<strong>Mind your input networks</strong>，意思是说对输入层增广之后可能已经得到了一些重要信息，导致后面再积分的过程冗余，所以输入的处理要小心</p><h2 id="审稿意见"><a href="#审稿意见" class="headerlink" title="审稿意见"></a>审稿意见</h2><p><a href="https://proceedings.neurips.cc/paper/2020/file/293835c2cc75b585649498ee74b395f5-Review.html" target="_blank" rel="noopener">https://proceedings.neurips.cc/paper/2020/file/293835c2cc75b585649498ee74b395f5-Review.html</a></p><p>看得真累，叭看了</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Massaroli, S., Poli, M., Park, J., Yamashita, A., &amp; Asma, H. (2020). Dissecting Neural ODEs. 34th Conference on Neural Information Processing Systems, NeurIPS 2020.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;读了好久，不少地方困住了&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Dissecting Neural ODEs&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读33-35】染色体分割相关</title>
    <link href="http://maxliu245.github.io/2021/02/22/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB33-35%E3%80%91%E6%9F%93%E8%89%B2%E4%BD%93%E5%88%86%E5%89%B2%E7%9B%B8%E5%85%B3/"/>
    <id>http://maxliu245.github.io/2021/02/22/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB33-35%E3%80%91%E6%9F%93%E8%89%B2%E4%BD%93%E5%88%86%E5%89%B2%E7%9B%B8%E5%85%B3/</id>
    <published>2021-02-22T15:20:54.000Z</published>
    <updated>2021-02-22T15:47:17.225Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>读了点染色体分割的小文章，有点平衡不好暴力美学和解释性方法了</p></blockquote><a id="more"></a><h2 id="第一篇"><a href="#第一篇" class="headerlink" title="第一篇"></a>第一篇</h2><p>第一篇文章是专利：<a href="https://www.zhangqiaokeyan.com/patent-detail/06120101534115.html" target="_blank" rel="noopener">一种染色体核型图像切割方法</a></p><p>申请公布日19/12/03，公司写的专利</p><p>粗看了一遍流程，方法是<strong>基础，合理，工程</strong>的</p><p>好多方法都用了，形态学算子、MaskRCNN等等，大概思路就是</p><ol><li>不知道有没有预处理，好像不需要</li><li>连通域提取染色体区域</li><li>重叠染色体进一步提取，方式是阈值判断与置信选择</li><li>进一步提取骨架，找中心点，骨架其实就是染色体条像素宽度1</li><li>后面就是无趣的深度学习工程式套模型，数据增强等等，有多少方法套多少方法</li></ol><h2 id="第二篇"><a href="#第二篇" class="headerlink" title="第二篇"></a>第二篇</h2><p>第二篇文章<a href="https://ieeexplore.ieee.org/document/7163174" target="_blank" rel="noopener">A Geometric Approach To Fully Automatic Chromosome Segmentation</a></p><p>这个文章是2014 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)的</p><p>感觉讲得很结实实在，就是讲染色体图像自动分割，方法就是<code>a geometric method for segmentation of the touching and partially overlapping chromosomes</code></p><p>基本方法：</p><ol><li>去噪（预处理）</li><li>分离重叠或者touching的染色体（key）</li><li>正式分离</li></ol><p>本文的出发点（idea）是基于几何进行自动分割，主要贡献在于检测分离2中的情形。本文强调几何方法的优点（section I最后有三条优点）是不用考虑图片类型，通用。本文的数据也不多，database containing 62 touching and  partially overlapping chromosomes，要考虑减小过拟合。</p><p>上述的2有两大步骤</p><ol><li>第1是把所有染色体簇识别出来，方式是三种几何方法适当组合，虽然每个方法都有偏颇，但组合之后确实可能更有效分别是计算凸包像素比例、外接椭圆长短轴比、骨架端点数</li><li>第2就是把染色体簇分成单个的，方式是找出分割点，有VAMD和SDTP两个准则，都是几何判断，细节不考虑了</li><li>ps：如果有多条染色体成簇，就重复算法，每次分出来一条</li></ol><h2 id="第三篇"><a href="#第三篇" class="headerlink" title="第三篇"></a>第三篇</h2><p>第三篇文章很早之前看过，这次整理一下</p><p><a href="https://ieeexplore.ieee.org/document/8014843" target="_blank" rel="noopener">Crowdsourcing for Chromosome Segmentation and Deep Classification</a>是<a href="https://ieeexplore.ieee.org/xpl/conhome/8014302/proceeding" target="_blank" rel="noopener">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</a>的</p><p>原来是个workshop，怪不得觉得差味道</p><p>这个讲一整套流程，中期（ metaphase ）染色体分析，分割与分类，众包流程。</p><p>众包是人工注释边界。。然后伸直矫正+长度归一化。。再网络分类。。</p><p>哈哈这个文章也提到了染色体分割的难处，叽里呱啦介绍了一堆别人方法，然后表示我们还是深度吧。。</p><p>扫了一遍内容没啥，我觉得就是强调了一遍染色体分类应用落地的流程。整个流程十分工程：</p><ol><li>众包分割单个染色体图像</li><li>众包过程中有细节提高分割效率</li><li>单个染色体有诸如剪切、拼接、扭直、归一化长度的操作</li><li>普通的网络进行分类</li><li>交互式应用界面</li></ol><p>最后，它的数据集不大，准确率泛化性存疑</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>平衡不好暴力美学和解释性方法了</p><p>要是一点点地设计模型，效果是存疑的，但是可解释性会比较优美，所以希望分类的方法能直观，能看出来实际意义，同时保持准确性（安全性）</p><p>要是暴力工程处理，实在不美，效果泛化未必就好，这样来看还是处理general图像的方法好，预处理尽可能忽略图像类型的影响</p><p>大晚上的迷糊了，ヾ(•ω•`)o</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 宋宁, 池浩塬, 秦玉磊, 韩云鹏, 马伟旗, 沈晓明, 晏青, 吴朝玉, and 杨洁. “一种染色体核型图像切割方法.” 2019.</p><p>[2] Minaee, S., M. Fotouhi, and B. H. Khalaj. “A Geometric Approach to Fully Automatic Chromosome Segmentation.” Paper presented at the 2014 IEEE Signal Processing in Medicine and Biology Symposium (SPMB), 13-13 Dec. 2014 2014.</p><p>[3] Sharma, M., O. Saha, A. Sriraman, R. Hebbalaguppe, L. Vig, and S. Karande. “Crowdsourcing for Chromosome Segmentation and Deep Classification.” Paper presented at the 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 21-26 July 2017 2017.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;读了点染色体分割的小文章，有点平衡不好暴力美学和解释性方法了&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Medical Images" scheme="http://maxliu245.github.io/tags/Medical-Images/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读32】NF小综述</title>
    <link href="http://maxliu245.github.io/2021/01/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB32%E3%80%91NF%E5%B0%8F%E7%BB%BC%E8%BF%B0/"/>
    <id>http://maxliu245.github.io/2021/01/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB32%E3%80%91NF%E5%B0%8F%E7%BB%BC%E8%BF%B0/</id>
    <published>2021-01-28T15:09:17.000Z</published>
    <updated>2021-01-28T15:13:05.276Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读归一化流小综述</p><p><em>Normalizing Flows: An Introduction and Review of Current Methods</em></p></blockquote><a id="more"></a> <img src="/2021/01/28/【论文阅读32】NF小综述/lzgnyq.jpg" title="小拳拳出击"><p>他喵的读文章读了好几天，日常很烦躁。</p><p>这篇文章是关于流模型的一个小综述，发在TPAMI(Early Access)上我是想不到的，截至2021/01/28影响因子17.8。去年5月刊出，现在有2次被引</p><p><a href="https://ieeexplore.ieee.org/document/9089305" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/9089305</a></p><h2 id="NF概述"><a href="#NF概述" class="headerlink" title="NF概述"></a>NF概述</h2><p>总结就是流这个东西属于生成模型建模的一部分，现在的<code>Normalizing流</code>在保证<strong>生成效果</strong>的同时要求<strong>生成过程可逆</strong>，也就是可以来回变。这个变来变去的过程一般包括采样，所以还需保证<strong>采样效率</strong>良好，这三个其实就是目前主要的<strong>模型改进方向</strong></p><p> <code>Normalizing流</code>没有正式翻译，我姑且称为归一化流。本来是<strong>从简单初始分布一步步到复杂数据分布的过程</strong>嘛，要求<strong>可逆可微</strong>（后者应该可以退化成连续）。那么<strong>流有两个方向</strong>，简单到复杂就是<strong>生成方向</strong>；反之称为<strong>normalizing方向</strong>，意思是复杂分布统统归一化为简单分布，就是这个意思</p><p>它的应用方向似乎不少，但是比较专，和生成模型相关的都可以，数据生成什么的也沾边</p><h2 id="NF基础理解"><a href="#NF基础理解" class="headerlink" title="NF基础理解"></a>NF基础理解</h2><p>基础的流理论，主要是概率分布之间的变化，那么自然有Jacobi的引入，后续针对它的结构、行列式计算也有很多改进。另外是基础理论，这个真的觉得难度一下子就上去了，涉及测度论</p><p>注意一个区别，微分同胚和双射不同！微分同胚是更强的，双射比较弱，原文是这么说的。自己感觉的话，微分同胚连续可微，双射不一定连续</p><p>流理论的两种主要应用，密度估计和变分推断，涉及流的两个方向的使用。正向即生成方向是直接计算复杂分布的概率密度的，因此这个过程要计算Jacobi。所以在密度估计问题中，由于这个密度指的是已知数据条件下，从复杂分布推导前面简单分布的概率密度，如果建模生成方向的话，则要计算其Jacobi的逆，这样复杂了，所以对密度估计一般建模归一化方向可能方便一点。</p><p>至于变分推断，就是一般的推断过程，需要重参数化技巧。不过我自己还没有见过有关这方面的流模型文章</p><h2 id="NF方法分类"><a href="#NF方法分类" class="headerlink" title="NF方法分类"></a>NF方法分类</h2><p>一图胜千言系列，文章也是按这个顺序介绍的，而且对应的方法相对前一种多有针对性的改进</p><img src="/2021/01/28/【论文阅读32】NF小综述/NF-1.png" title="方法分类"><ul><li><p>逐点流，其实是逐维度的流，维度分开。显然表达能力比较欠缺，维度之间没有相关性</p></li><li><p>线性流，线性指线性变换。在逐点流的基础上维度之间线性组合，即进行线性变换，不妨设形式$Ax+b$。具体又分<strong>$A$对角，上下三角，置换，正交，$A$矩阵分解，$A$取卷积阵</strong>等，这些都算线性流！</p><p>其中的<strong>Periodic Convolutions可能和XQ师兄提到的变换基的卷积有所关系</strong>！</p><p>线性流的缺点还是表达能力，毕竟是线性（如果直接引入非线性特征变换，线性套非线性变换的话会很奇怪，为什么不直接非线性变换）</p></li><li><p>平面流&amp;径向流，试图突破线性流，取非线性变换</p><ul><li>平面流加了方向，见文中$(10)$式$x+uh(w^Tx+b)$，观察知，有一点残差的味道，前面弄出来个$x$好像是有利于Jacobi行列式估计的；另外，后面的$h$非线性，先线性再非线性，前面还有个所谓的方向$u$，这大概是平面流名称的由来</li><li>径向流用的是那种中心点的形式，有点像核函数的那种形式，见文中$(14)$式</li></ul></li><li><p>耦合（coupling）流，<strong>有技巧的非线性变换</strong>，<strong>耦合函数也叫conditioner</strong>。一般的操作是维度拆开，一部分id，一部分用耦合函数作用，以前看的NICE就是这个套路，还取了名字叫加性耦合函数。</p><ul><li>问题一：哪一部分变量取耦合作用，这些可能涉及到顺序的问题。常用的套路是每次非线性变换一部分变量，到后面，<strong>还能id的变量维度是减少的</strong>，因为先前非线性变换的信息已经够多</li><li>问题二：回去即归一化的方向，在问题一的假设中，此方向id的维度依次增多，语义信息保留，指的是高阶信息逐渐变成id，且还能<strong>在归一化的过程中保留</strong></li></ul><p>针对问题一，耦合往往使用分割维度的方式，其顺序可以随机置换，也有mask方式和选择Jacobi对角值更高的维度（信息更多吧）</p></li></ul><p>中间插一段<strong>各种耦合函数</strong>的介绍：</p><ol><li>直接仿射变换</li><li>非线性的二次变换</li><li>连续的混合密度</li><li>样条（插值？），又包括分段线性，分段二次，三次样条，etc</li><li>神经网络建模的自回归耦合方式，应该是依次套层</li><li>多项式平方和</li><li>分段双射耦合</li></ol><ul><li><p>自回归流，其实就是上述耦合函数<strong>作用对象变化</strong>，依次作用在先前所有的输入上</p><p>这样做的一个缺点是逆不好算；且由于是顺序的，难以并行计算</p><img src="/2021/01/28/【论文阅读32】NF小综述/NF-2.png" title="自回归流的一般结构"></li><li><p>以残差网络为代表的流，正逆向建模的都有</p><ul><li><p>正向是自然理解，用了耦合coupling的手段，维度分开，用残差加性处理加性和前面说的还不是太一样，对每次的输出也有耦合作用，见$(30)$式</p></li><li><p>逆向需要所谓re-arrange，这个记不清了，暂时不太明白</p></li></ul><p>缺点是Jacobi难算，一个方案是采用det估计，由Lipschitz控制把det转换为计算迹，其中还有采样近似估计的trick。估计的方式不少，有偏无偏都有</p><p>对于这一类流，一个理解是ODE系统，这类网络可设计为可逆，有文中命题7保证，要求残差block被常数1，Lipschitz控制。但不好控制，一般需要控制网络的结构，由此又衍生出一些模型</p></li><li><p>连续流，字面上指离散得足够精细，也可依据上面ODE理解，中间状态足够精细就逼近连续系统。但是直接加深ResNet深度太SB了。基于此，这个分两类，ODE-based和SDE-based</p><ul><li><p>前者即熟知的NODE+adjoint方法</p><p>相关改进有陈天琦参与的FFJORD，估计迹，降低计算和存储（连续流）复杂度，还有个思路是正则限制</p><p>ODE方法类也有缺点，<strong>一条path上Jacobi行列式不变号</strong>，解决方式是维度增广ANODE，以前读ANODE的时候一直对这个path不交叉有点迷惑，现在又多了一个解释！</p><p>我看的DDNF他们也介绍了，路径由许多微分同胚构成</p></li><li><p>SDE-based没怎么看过（Langevin flows）：大概就是ODE与时间相关了，有随机项，也有固定的偏移项之类的东西</p></li></ul></li></ul><h2 id="NF常用数据"><a href="#NF常用数据" class="headerlink" title="NF常用数据"></a>NF常用数据</h2><p>实验数据方面比较固定。除了人工数据，参考文中表2、4即可。分别是UCI和常用实际数据</p><p>似乎UCI的数据都连续化了de-quantized，方式是对离散数据加均匀噪声，看成连续数据</p><h2 id="NF挑战"><a href="#NF挑战" class="headerlink" title="NF挑战"></a>NF挑战</h2><p>这个文章提的挑战不多，感觉很多核心的东西没有明说，我也没看出来太多</p><ol><li><p>从基础理论开始，自然是测度论太难做了，基测度，即初始分布的选取可以看成一种先验，也就是大家说取简单的好采样的就完事了。有生成的复杂度和效果之间的权衡？</p></li><li><p>另外，微分同胚的建模也很重要，上一篇看的<a href="https://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/">DNNF</a>就是</p></li><li><p>还有一点是损失函数的选取，现在普遍KL，也有其它距离介导的损失</p></li><li><p>再提一个理论上的东西，从欧氏空间到非欧空间哈哈。黎曼来袭，怎么把欧式转为黎曼。计算上必然复杂。这其中涉及到黎曼几何课上学习的东西，哈哈什么测地完备则测地线可以无限延伸，即空间中处处可以转换，也有切空间近似方式，亦或是考虑特定的黎曼空间，李群结构什么的😄</p></li><li><p>最后至于不连续流，个人觉得是特定应用场景下再使用就算了，而且一般也就是离散流de-quantized近似为连续流</p></li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Kobyzev, I., Prince, S., &amp; Brubaker, M. (2020). Normalizing Flows: An Introduction and Review of Current Methods. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1-1. <a href="https://doi.org/10.1109/TPAMI.2020.2992934" target="_blank" rel="noopener">https://doi.org/10.1109/TPAMI.2020.2992934</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读归一化流小综述&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Normalizing Flows: An Introduction and Review of Current Methods&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【Windows技巧3】奇怪的网页广告统统走开</title>
    <link href="http://maxliu245.github.io/2021/01/26/%E3%80%90Windows%E6%8A%80%E5%B7%A73%E3%80%91%E5%A5%87%E6%80%AA%E7%9A%84%E7%BD%91%E9%A1%B5%E5%B9%BF%E5%91%8A%E7%BB%9F%E7%BB%9F%E8%B5%B0%E5%BC%80/"/>
    <id>http://maxliu245.github.io/2021/01/26/%E3%80%90Windows%E6%8A%80%E5%B7%A73%E3%80%91%E5%A5%87%E6%80%AA%E7%9A%84%E7%BD%91%E9%A1%B5%E5%B9%BF%E5%91%8A%E7%BB%9F%E7%BB%9F%E8%B5%B0%E5%BC%80/</id>
    <published>2021-01-26T08:58:53.000Z</published>
    <updated>2021-01-26T09:14:19.632Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>大家吼！给大家安利去网页广告神器ADBlock！</p></blockquote><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>凡安利必有因，本来打算用学校的vpn下波文献，研究研究《傅雷家书》的版权问题。毕竟傅雷早已过世，为什么傅雷家书还不算公版书呢？</p><p>以下文献讲得还可以，我感觉我明白了，《傅雷家书》是傅聪整理的，而且有所创新，其<strong>著作权现在归属傅聪</strong>。get</p><blockquote><p><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2017&amp;filename=FBZX201726164&amp;v=xscXH%25mmd2F5%25mmd2BzQVsz6bvAycyaGFAlQY3yZkHtJAdqbO7AuEXwv3Jgdg0xh2Bec06j25V" target="_blank" rel="noopener">浅论公版图书的版权问题——以《傅雷家书》版权案为例</a></p><p>许姗. (2017). 浅论公版图书的版权问题——以《傅雷家书》版权案为例. 法制博览(26), 252. </p></blockquote><h2 id="哈哈哈哪里都有奇怪的广告"><a href="#哈哈哈哪里都有奇怪的广告" class="headerlink" title="哈哈哈哪里都有奇怪的广告"></a>哈哈哈哪里都有奇怪的广告</h2><p>但是这波上了学校vpn之后出现的奇怪的广告，导致我<strong>点击不了文献</strong>，包括大半个网页屏幕区域</p><img src="/2021/01/26/【Windows技巧3】奇怪的网页广告统统走开/Webvpn-1.png" title="请问是Webvpn的锅么"><p>刚开始尝试开发者工具删除element，但是直接找看不出来哪个是这个广告</p><p>突然惊醒，👴有<strong>去广告神器ADBlock</strong>嘻嘻🤭</p><img src="/2021/01/26/【Windows技巧3】奇怪的网页广告统统走开/Webvpn-2.png" title="懂我意思吧hxd"><p>🆗</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>最后<strong>怒喷</strong>一波，学校这个服务还带广告的？？？这波是算合理外快还是又什么操作？？？搜文献的时候点击不了很毁人心情的</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;大家吼！给大家安利去网页广告神器ADBlock！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Windows" scheme="http://maxliu245.github.io/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>【Hexo4】公式渲染出错更正——渲染位置失效问题</title>
    <link href="http://maxliu245.github.io/2021/01/13/%E3%80%90Hexo4%E3%80%91%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E5%87%BA%E9%94%99%E6%9B%B4%E6%AD%A3%E2%80%94%E2%80%94%E6%B8%B2%E6%9F%93%E4%BD%8D%E7%BD%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/"/>
    <id>http://maxliu245.github.io/2021/01/13/%E3%80%90Hexo4%E3%80%91%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E5%87%BA%E9%94%99%E6%9B%B4%E6%AD%A3%E2%80%94%E2%80%94%E6%B8%B2%E6%9F%93%E4%BD%8D%E7%BD%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/</id>
    <published>2021-01-13T06:12:41.000Z</published>
    <updated>2021-01-13T06:39:20.755Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>记录一下长久以来困扰我的公式渲染问题</p></blockquote><a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>很早就有这个问题了，<code>hexo</code>对公式的渲染莫名其妙会出现问题，自己在本地<code>Typora</code>编辑器中渲染得都非常漂亮，但是一旦发布或者在本地服务器上预览就会出问题，本来的<strong>应该被渲染的公式可能没有被渲染或者被渲染到了别的地方</strong>。这次好好写的笔记又炸了，如下图所示：</p><img src="/2021/01/13/【Hexo4】公式渲染出错更正——渲染位置失效问题/error.jpg" title="MathJax Error"><p>主要的问题在于：</p><ol><li><p>用来生成$\{\}$的代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\&#123;\&#125;</span><br></pre></td></tr></table></figure><p>中花括号的转义字符<code>\</code>会消失导致渲染失败</p></li><li><p>下标转义字符<code>_</code>会偶尔消失，主要是行内公式</p></li><li><p>由以上问题导致非公式文本会被渲染</p></li></ol><p>太难看了，这次从网上找了解决方案，聊记于此，原因是<strong>原来的渲染包<code>hexo-renderer-marked</code>不太行</strong>。。。我先自己更新了一下，发现问题没有改观，然后卸载之并安装<code>hexo-renderer-kramed</code>，问题仍未改观。最后按照解决方案修改<code>js</code>规则，总算🆗啦！</p><h2 id="试错顺序"><a href="#试错顺序" class="headerlink" title="试错顺序"></a>试错顺序</h2><p>第一步观察是不是工具包未升级的问题：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g npm</span><br></pre></td></tr></table></figure><p>第二步观察是不是新的工具包就好了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><p>第三步按链接找到<code>../node_modules/kramed/lib/rules/inline.js</code>中第11行和第20行并修改转义规则：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span></span><br><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([`*\[\]()#$+\-.!_&gt;])/</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span></span><br><span class="line">em: <span class="regexp">/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span>,</span><br></pre></td></tr></table></figure><p>再重新渲染就🆗啦！</p><h2 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h2><p><a href="https://home.cnblogs.com/u/Ai-heng/" target="_blank" rel="noopener">VitaHeng</a>的博客<a href="https://www.cnblogs.com/Ai-heng/p/7282110.html" target="_blank" rel="noopener">hexo博客MathJax公式渲染问题</a>，顺便发现这位大兄弟的主页了，前两年还有两篇文章，加油！</p><p>自己确实试了错，加了自己的探索过程，除了代码，我觉得不算转载。如果的确需要授权，请联系我商议解决~</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;记录一下长久以来困扰我的公式渲染问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Hexo" scheme="http://maxliu245.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读31】DDNF——深度微分同胚的Normalizing Flow</title>
    <link href="http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/"/>
    <id>http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/</id>
    <published>2021-01-13T03:45:18.000Z</published>
    <updated>2021-01-13T03:58:21.384Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读文章<em>Deep Diffeomorphic Normalizing Flows</em></p><p>感觉写得不错，但是引用量很少，我觉得是代码没有开源的缘故</p></blockquote><a id="more"></a><h2 id="Deep-Diffeomorphic-Normalizing-Flows"><a href="#Deep-Diffeomorphic-Normalizing-Flows" class="headerlink" title="Deep Diffeomorphic Normalizing Flows"></a>Deep Diffeomorphic Normalizing Flows</h2><h2 id="心路历程"><a href="#心路历程" class="headerlink" title="心路历程"></a>心路历程</h2><p>很长时间没有看过流模型了，这次也看到了许多之前没有接触过的概念，包括很多细节，本来打算这些细节将在文末实验部分单独一一列出，但是太累了不写了，需要的时候自己看看吧</p><p>另外文章中介绍了不少以往的模型，这些也不介绍了，以后见到慢慢补充</p><h2 id="文献简介"><a href="#文献简介" class="headerlink" title="文献简介"></a>文献简介</h2><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-1.png" title="DDNF"><ul><li><p>作者信息</p><p>一作是微软的工程师Hadi Salman，看了看他的<a href="https://www.microsoft.com/en-us/research/people/hasalman/" target="_blank" rel="noopener">个人主页</a>和<a href="https://scholar.google.com/citations?user=Kr8JjF0AAAAJ&amp;hl=en&amp;oi=sra" target="_blank" rel="noopener">学术主页</a>，这个人主要是做对抗攻防的，带一点稳健动力系统。其余作者来自弗吉尼亚大学和匹兹堡大学</p></li><li><p>文献信息</p><p>文献链接：<a href="https://arxiv.org/abs/1810.03256" target="_blank" rel="noopener">https://arxiv.org/abs/1810.03256</a></p><p>这篇文章18年挂出来，截至2021/01/12谷歌学术上的引用量是11</p></li><li><p>文献简述</p><p>这个文章有些意思，它提出了一种新的对流模型的建模<strong><em>DDNF</em></strong>，主要的思想是借用ODE中每个state可以看成流模型中隐变量的多次映射过程，即 $z_0\rightarrow z_1\rightarrow\cdots\rightarrow z_n$，那么隐变量的每一步更新看成ODE的积分过程，这个过程可以进一步反应在抽象出来的流形上，如下图所示：</p><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-2.png" title="隐变量如何多次映射"></li></ul><p>我想把它对于流模型的建模步骤归纳为：</p><pre class="mermaid">graph LRA(DDNF<br>Deep Diffeomorphic Normalizing Flows) -->B(Idea<br>介绍微分同胚和ODE之间的关联)A -->C(DDNF的结构<br>主要是建模过程,模型设置)A -->D(Jacobi计算<br>泰勒展开以及行列式的迹估计)A -->E(正则引入<br>有两种方法改善模型效果,分别是测地正则和逆一致正则)</pre><h2 id="基本任务——对归纳偏执建模"><a href="#基本任务——对归纳偏执建模" class="headerlink" title="基本任务——对归纳偏执建模"></a>基本任务——对归纳偏执建模</h2><p>写总结的时候发现还是要写像target一样的东西放在前面</p><p>对流的建模基本不变，即数据 $X=\{x_1,\cdots,x_N\}$，引入生成模型及其隐变量 $z$，目标是最大似然</p><script type="math/tex; mode=display">\begin{align} \displaystyle \log p_{\theta}(X)&=\sum_{i=1}^N \log p_{\theta}x_i \tag{1}\\ &\overset{p_{\theta}(x)=\int p_{\theta}(z,x)dz}{\geq} \mathbb{E}_{q_{\lambda}(z|x)}[\log p_{\theta}(x|z)-KL(q_{\lambda}(z|x)|p(z))]. \tag{2}\end{align}</script><p>现在给出归纳偏置，由于主要是<strong>建模隐变量</strong> $z$，试图近似它的后验分布，那么本文假设的是<strong>最终的隐变量 $z$ 由一系列可逆变换 $\phi_k$ 作用在初始分布 $q_0$ 上得到</strong>，即</p><script type="math/tex; mode=display">\displaystyle final\ latent\ variable\ z_K = \phi_K\circ\cdots\circ\phi_2\circ\phi_1(z_0) \tag{3}</script><p>之后要写出对应的变分目标，具体的过程就是 $(3)$ 式<strong>概率密度函数分解</strong>，由</p><script type="math/tex; mode=display">\begin{align} \displaystyle q_{k+1}(z_{k+1})&=q_k(z_k)\bigg|det\dfrac{\partial \phi_{k+1}(z_k)}{\partial z_k}\bigg|^{-1} \tag{4}\\ &=q_k(\phi_{k+1}^{-1}(z_{k+1}))\bigg|det\dfrac{\partial \phi_{k+1}^{-1}(z_{k+1})}{\partial z_{k+1}}\bigg| \tag{5}\end{align}</script><p>可得分解后的变分目标（其实不难，就是要写半天。。。）为</p><script type="math/tex; mode=display">\begin{align} \displaystyle \mathcal{F}(\theta,\lambda)&=\mathbb{E}_{q_{\lambda}}[\log q_{\lambda}(z|x)-\log p_{\theta}(x,z)] \tag{6}\\ &=\mathbb{E}_{q_0}[\log q_0(z_0|x)-\log p_{\theta}(x,z_K)] - \mathbb{E}_{q_0}\left[\sum_{k=1}^K \log  \bigg|det\dfrac{\partial \phi_{k}(z_{k-1})}{\partial z_{k-1}}\bigg|\right] \tag{7}\end{align}</script><p>因此，DDNF的目标其实就是<strong>针对这一系列的可逆变换设计流模型</strong>，进一步引入微分同胚保持可逆和光滑性，而这恰好引入了ODE-Net的思想</p><h2 id="Idea——微分同胚如何引入"><a href="#Idea——微分同胚如何引入" class="headerlink" title="Idea——微分同胚如何引入"></a>Idea——微分同胚如何引入</h2><p>这要联系ODE中<strong>连续流</strong>的概念，并结合美妙的<strong>黎曼几何</strong>。如文首所述：</p><blockquote><p>主要的思想是借用ODE中每个state可以看成流模型中隐变量的<strong>多次映射</strong>过程，即 $z_0\rightarrow z_1\rightarrow\cdots\rightarrow z_n$，那么<strong>隐变量的每一步更新看成ODE的积分过程</strong>，这个过程可以进一步反应在抽象出来的流形上</p><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-2.png" title="隐变量如何多次映射"></blockquote><p>具体设置为（细节拜拜，反之就是Hilbert空间假设，然后随便推导），每个可逆变换 $\phi_k:\Omega\rightarrow\Omega$，其中 $\Omega\subset\mathbb{R}^d$，就是切向量之间的映射，设 $\Omega$ 的切丛（从这里看出它把 $\Omega$ 直接看成带有内积的流形了，不妨当成黎曼流形就好）的完备化空间为 $V\overset{def}{=}H^s(\mathcal{T}\Omega)$，$s$ 代表切向量的几阶导存在，且都默认二次可积。总之，完备化+黎曼流形就瞎推了</p><p>那么<strong>关键</strong>来了，之前说隐变量的前进过程看成ODE上的积分过程，这需要<strong>切向量在流形上的平行移动（其实就是积分）</strong>，所以先要模拟切向量，这里设其形式为一般的可随时间变化的切向量 $v(t,\cdot):[0,1]\rightarrow V$，应该是指流形上每一点处可以得到与时间相关的切向量。那么<strong>隐变量的每一步更新看成ODE的积分过程</strong>：</p><script type="math/tex; mode=display">\displaystyle \dfrac{d}{dt}\phi_k(t,z)=v(t,\phi_k(t,z)). \tag{8}</script><p>这样，如果能用像ResNet之类的网络模拟一阶导 $v$，那么ResNet输出的就相当于积分后的方程，输出的是 $\phi_k$；那么再配合上RNN之类的结构把这一系列变换 $\phi_k$ 串起来，那就是整个流的建模过程了</p><p>最后再声明，上述建模过程说得很轻巧，看起来也比较合理，那有没有理论保证，你这个就一定行呢？有的，参考原文第3页左下角部分，大概就是</p><ul><li>前人结论：<ul><li>若 $v$ 充分光滑，那 $\phi$ 就相当于微分同胚</li><li>这样的flow中的Jacobi行列式总是非负的（<strong>为0不就gg，估计有trick处理，阈值截断什么的</strong>）</li></ul></li><li>原作者总结的性质：<ul><li>一系列微分同胚 $\phi_k$ 保持代数运算，它们在代数群上✅</li><li>假定空间存在合适的内积，那就成为黎曼流形，进一步可以引入测地线概念，引入测地正则✅</li></ul></li></ul><h2 id="网络结构——RNN-ResNet-ODE-Net"><a href="#网络结构——RNN-ResNet-ODE-Net" class="headerlink" title="网络结构——RNN+ResNet(ODE-Net)"></a>网络结构——RNN+ResNet(ODE-Net)</h2><p>这个部分本来以为挺难，但是读完了发现文章中图2真是<strong>一图胜千言</strong>。我解读了三次此网络，前两次应该都错了！后一次就是总结出来的┭┮﹏┭┮</p><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-3.png" title="网络设置"><p>首先，观察<strong>最下面的图</strong>，这就是<strong>整个流的建模过程</strong>，即通过 $K$ <strong>个可逆微分同胚变换</strong>，$\{\phi_{k}\}_k$ ，它把初始化的隐变量 $z_0$，逐步映射到最终目标隐变量 $z_K$。因此，最下面的图中每个block都是在流形上某点$z_k$处切空间中进行积分的过程。且注意到在每个切空间  $T_{z_k}\Omega$中，切向量都是不同的，因此每步变换中的切向量或者说速率不同！</p><p>其次，如上图<strong>中间的图</strong>表示，中间的图整个是<strong>一个积分过程，表示一步可逆变换</strong> $z_{k+1}=\phi_{k+1}(z_k)$。<strong>整体是RNN</strong>模型，其中有 $T$ 个block，指的是 $T$ 个ResNet block，$T$ 指的是从 $z_k$ 到 $z_{k+1}$ 的积分过程中离散近似的小区间数目，RNN就是把这离散的过程叠加循环起来。且为了方便，建模时考虑<strong>使用不随时间变化的stationary向量场</strong>，即每个block使用相同的向量场，图中记为 $v^k$ 是很合理的。此时，整个一步积分是自治方程 $(8)$ 的求解过程，，解出来其实是指映射 $\phi^{v_k}=exp(v^k(t,\cdot))=exp(v^k(\cdot))$，如果考虑实验中的近似手段 $T$ 个block的结果叠加，那就是 $\phi^{v_k}=exp(v^k(\cdot)/T)^T$</p><p>最后是<strong>最上面的模型</strong>，即具体<strong>一步积分中一个小区间的近似</strong>过程，为<strong>一个ResNet block</strong>，其中使用多少层，每层宽度多少是可以调整的。我记的没错的话，本文实验多使用的结构只有两层，每层只有两个神经元，目的是验证即使结构简单，其表达能力也很强，这将会验证基于ODE的微分同胚流的模型是优异的</p><hr><p>这样模型就讲完了，下面介绍为什么使用ResNet的结构，计算Jacobi会用到，但是这<strong>和以前我看的不一样</strong>，我记得以前看过哪篇文章，<strong>用ResNet的结构会使Jacobi呈现行列式为1的形式</strong>，进一步微调使之变化（好像是这样，忘了）。这里计算Jacobi不太一样</p><p>本文的思路是借用ResNet中恒等映射的存在<strong>作泰勒展开</strong>近似估计Jacobi行列式：</p><script type="math/tex; mode=display">\begin{align} \displaystyle \log det(\mathcal{J}\phi^v(\Delta t,\cdot))&\overset{RestNet}{=}\log det(I+\Delta t\mathcal{J}v(\cdot)) \tag{9}\\ &\overset{A\overset{def}{=}I+\Delta t\mathcal{J}v(\cdot)}{=}\log det(A) \tag{10}\\ &=\log \left(det(A^2)\right)^\frac{1}{2} \tag{11}\\ &= \dfrac{1}{2}\log \left(det(A^TA)\right) \tag{12}\\ &= \dfrac{1}{2}\log \left(det(I+\Delta t(\mathcal{J}v(\cdot)+\mathcal{J}v(\cdot)^T+\Delta t\mathcal{J}v(\cdot)^T\mathcal{J}v(\cdot)))\right) \tag{13}\\ &\overset{def}{=} \dfrac{1}{2}\log \left(det(I+\Delta tB)\right) \tag{14}\\ &\approx \dfrac{1}{2}\Delta tTr(\mathcal{J}v(\cdot)+\mathcal{J}v(\cdot)^T)-\dfrac{1}{2}(\Delta t)^2Tr(\mathcal{J}v(\cdot)^T\mathcal{J}v(\cdot)). \tag{15}\end{align}</script><p>其中最后一步我<strong>没有推出来</strong>，现在不推了，日后需要再搞。只知道是在 $B=0$ 处二阶泰勒展开，三次及三次以上都近似忽略掉，然后用迹估计的方法即可</p><p>所以使用ResNet的结构并引入泰勒展开，<strong>目的是降低Jacobi计算的复杂度</strong>，一般来说根据模型结构，有 $T$ 个Jacobi的行列式需要计算，所以计算复杂度可看成 $\mathcal{O}(Td^3)$，而转化为 $(15)$ 式后，除了矩阵 $\mathcal{J}v$ 的存储外，迹的计算复杂度只有 $\mathcal{O}(d)$，而近似方法中需要 $M$ 常数次采样，因此最终复杂度由 $\mathcal{O}(Td^3)$ 降低到 $\mathcal{O}(Md)$，的确是比较大的进步！</p><h2 id="微分同胚流的其它亮点"><a href="#微分同胚流的其它亮点" class="headerlink" title="微分同胚流的其它亮点"></a>微分同胚流的其它亮点</h2><h3 id="流的逆简易计算"><a href="#流的逆简易计算" class="headerlink" title="流的逆简易计算"></a>流的逆简易计算</h3><p>流的逆一般需要好求，这往往需要对网络的结构进行限制，本文表示，由于限定每一个可逆映射中的切向量是stationary的，所以求解出来直接就是指数映射，所以逆回去的时候也指数逆回去就好了，即 $\phi^{v_k}=exp(v^k(\cdot)/T)^T$ 逆为 $(\phi^{v_k})^{-1}=exp(-v^k(\cdot)/T)^T$</p><h3 id="两种正则有效"><a href="#两种正则有效" class="headerlink" title="两种正则有效"></a>两种正则有效</h3><p>在最后，本文指出可以引入正则增强模型的性能，有两种：</p><ul><li><p>测地正则，即 $v_0$ 和 $v_K$ 的测地距离尽可能小，原理大概就是测地线喵喵咪</p><script type="math/tex; mode=display">\mathcal{R}(v)=\langle v_0,v_K\rangle_V=\mathbb{E}_{q_0}[v_0^TGv_K] \tag{16}</script><p>其中 $G$ 是黎曼流形的度规矩阵，实际操作的时候用欧氏空间的单位阵即可</p></li><li><p>逆正则，即逆回去得到的 $\phi^{-1}(z_K)$ 与初始的变量 $z_0$ 要恢复好</p><script type="math/tex; mode=display">\mathcal{R}(v)=||z_0-\phi^{-1}(z_K)||_2 \tag{17}</script></li></ul><h2 id="实验简介"><a href="#实验简介" class="headerlink" title="实验简介"></a>实验简介</h2><p>文章的一个不错的地方是实验很充足，我都看了，但是不想写细节了，细节也忘了，需要的时候再回顾吧，写累死了。。。</p><p>有哪些有意思的实验：</p><ul><li>文中图7，模拟数据验证性能可以逼近分布</li><li>文中图4和图6，分别是toy和真实数据中变量分布的逼近，与其它几个模型对比，优势体现在不需要ResNet太多层等</li><li>文中图5和图8，两种正则的效果，看起来不错</li><li>文中表1，MNIST和Omniglot数据上的实验，大模型套的VAE，DDNF用来建模隐变量，似乎效果不错，只是说的好少？</li></ul><h2 id="优缺点简析"><a href="#优缺点简析" class="headerlink" title="优缺点简析"></a>优缺点简析</h2><p>模型优点（根据原文所述）：</p><ul><li>所提的微分同胚流 $f$ 保持了微分同胚的性质，$f$ 可逆，且 $f$ 与 $f^{-1}$ 都光滑</li><li>流的建模引入ODE的概念，流的部分变化过程由可与时间相关的向量场 $v(t,\cdot)$ 完成，此向量场由ResNet模拟</li><li>流的建模还引入了RNN来近似整个流的变化，结构使得似然推断还行，流的逆易求，隐变量的概率密度也好算</li><li>流的建模没有对网络结构有特殊设计</li><li>实验充足，据文章说competitive with SOTA</li><li>黎曼几何有更多的认识么？</li></ul><p>模型缺点：</p><ul><li>文章说代码将会开源，这都2021了我搜不到，迷惑</li><li>其实还是有很多估计，现在还能记起来的有，ODE积分的离散估计；stationary切向量的使用（但是不用这个就没有指数性质）；泰勒展开中只近似到2阶项；Jacobi计算时迹的估计</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Hadi Salman, Payman Yadollahpour, Tom Fletcher, and Kayhan Batmanghelich. Deep diffeomorphic normalizing flows. arXiv e-prints, page arXiv:1810.03256, 2018.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读文章&lt;em&gt;Deep Diffeomorphic Normalizing Flows&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;感觉写得不错，但是引用量很少，我觉得是代码没有开源的缘故&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读30】AI Poincare</title>
    <link href="http://maxliu245.github.io/2021/01/11/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB30%E3%80%91AI-Poincare/"/>
    <id>http://maxliu245.github.io/2021/01/11/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB30%E3%80%91AI-Poincare/</id>
    <published>2021-01-11T01:12:26.000Z</published>
    <updated>2021-01-11T01:34:16.259Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读文章<em>AI Poincaré: Machine Learning Conservation Laws from Trajectories</em></p><p>名字挺炫酷，不过看了一遍，觉得可以借鉴的地方不多，见正文方法部分最后一句</p></blockquote><a id="more"></a><h1 id="AI-Poincare"><a href="#AI-Poincare" class="headerlink" title="AI Poincaré"></a>AI Poincaré</h1><p>还是偏物理的，个人觉得不太算CS的文章，有的格式都不一样；只有5页，不过符号不算少，就是证明没有，难道是保密技术？纯粹是兴趣看一看，<strong>作者MIT学物理的</strong>，不是我，狗头👍。而且可以学习借鉴的地方不多</p><p>文献链接：<a href="https://arxiv.org/abs/2011.04698" target="_blank" rel="noopener">https://arxiv.org/abs/2011.04698</a></p><p>提出的方法叫做 $AI\ Poincar\acute{e}$，是只利用未知动力系统轨线数据自动寻找守恒律的学习算法</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>纯粹数据驱动，从轨线trajectories中学习守恒律</li><li>自动学习，不手动设计特征，且不加显式的偏置归纳</li><li>实验优点：哈密顿系统中发现了所有精确的守恒量，而且似乎有一定的解释性：发现了周期轨道，phase transitions和breakdown timescale</li></ul><h2 id="认为的缺点："><a href="#认为的缺点：" class="headerlink" title="认为的缺点："></a>认为的缺点：</h2><ul><li>方法在建模比赛中应该是非常有意思的，但是在学习领域，觉得不够味道</li><li>虽然走纯数据驱动的路子，但是可解释性不足，发现轨道等概念的解释性和我想的不一样</li><li>方法其实解释得不清楚，只是讲了一遍过程，合理性不足</li><li>实验结果似乎对不上？没看明白ERD图，难道不是中间有几条线下凸，低于阈值就是发现多少守恒律？文章表格和描述的似乎不一致，我很费解，可能是我菜。。。</li></ul><h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>文章自述一个宏伟的目标是<strong>智能学习物理系统中的规律，如符号回归得到的方程形式、守恒律、对称性，etc</strong>，我喜欢。本文的具体target是：<strong>从轨线trajectories中学习守恒律</strong>。</p><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><p>一般求守恒律可能要限制方程形式？所以以往方法可能是模型驱动。现在的idea就是表示只用轨线，对方程形式没有任何假设，就是要<strong>纯粹数据驱动</strong>试试。</p><p>具体的思想见建模的过程，本质是概念的对应，实现的方式比较基础</p><h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p>用于对比批判的方法：</p><ul><li>用AE、暹罗网络的正交方法（我自己未验证此方法），可以寻找对称性。缺点是要手动设计（对称性）特征</li><li>把守恒律作为偏执归纳先验，但这不是纯数据驱动</li></ul><p>重点参考的方法：</p><p>sampling manifolds方法和动力系统<strong>概念的对应</strong>（我一直在想这个问题但是想不通。。）看了这篇文章给的对应关系，也只是觉得可能有关系，但是还是没有说清楚概念之间的真正联系，可能<strong>还是要看更基础的文章</strong>！</p><img src="/2021/01/11/【论文略读30】AI-Poincare/AIPoin.png" title="概念对应关系"><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>看完方法觉得在机器学习的范畴内亮点不多。把方法流程大致过一遍。</p><p>首先是模型的基本假设，假定是<strong>带有守恒律</strong> $H_j(\mathbf{x})=h_j$ 的方程（真的是守恒律），每条守恒律都看作是一个高维空间（在可操作意义下都是 $\mathbb{R}^{l}$）中的超平面，满足一条守恒律就意味着有一个<strong>限制条件</strong>（凸分析学的好啊）。本文把所有可行轨线所在的空间看成与满足守恒律的空间一致，称之为可允许状态流形<code>permissible state manifold (PSM)</code> $\mathcal{M}$，且<strong>假设</strong>轨线数据集 $\mathcal{S}=\{\mathbf{x}(t)|t\geq 0\}$ 都分布在这个流形 $\mathcal{M}$ 上。它定义为</p><script type="math/tex; mode=display">\begin{equation} \mathcal{M} = \{\mathbf{x}\in\mathbb{R}^N|H_j(\mathbf{x})=h_j\} \tag{1}\end{equation}</script><p>那么每满足一条守恒律，此流形其实就有了一个的限制，相当于在 $\mathbb{R}^N$ 的基础上维度<strong>降低一维</strong>，如果观察到总维度（应该是提前已知）减去估计出的轨线数据集 $\mathcal{S}$ 的维度不为0，那就是找出了守恒律。</p><p>那么第二点是模型怎么算的。<strong>第1步是对轨线数据预处理</strong>，标准化，这样会有一个协方差矩阵，对角元对应特征值，有特征值就说明找到了重要的维度，初始时的非0特征值个数就应该是上一段说的总维度，然后一旦<strong>有特征值在迭代的过程中变得很小</strong>，那就是守恒律被发现了，这个维度就对应守恒律。第2步是对轨线数据加噪，干扰之，得到<strong>近似的流形</strong>（我认为是这样），再蒙特卡洛采样，学习恢复流形的函数，这一步的目的应该想把干扰后的轨线投影到切空间，如果守恒律存在，那么<strong>合适的干扰对守恒律会有较大的影响</strong>。那么第3步就是把投影后的轨线数据PCA降维处理得到最后的维度，如果降维的过程中发现<strong>维度变化很大</strong>，说明合适水平的噪声影响到了守恒律。这时根据<code>explained ratio diagram (ERD)</code>（我真不懂这个图怎么对应几条守恒律，因为好像和结果描述的不一致）可<strong>看出</strong>守恒律有几条。</p><p>思路就是这样，有点意思，意思在于<strong>干扰影响了守恒律</strong>，且合适水平的干扰可以最大影响守恒律；另外就是其实专门去寻找可能存在的守恒律，这一点与流形上有些概念似乎可以对应。私以为本文<strong>只有这两点可以借鉴</strong>。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>做了5种有守恒律的哈密顿方程的实验。但是私以为讲得不清楚，因为用ERD看出的守恒律数目和文章描述的似乎不一样😶。也可能是我菜看不出来🤡。。。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Ziming Liu and Max Tegmark. AI Poincaré: Machine Learning Conservation Laws from Trajectories. arXiv e-prints, page arXiv:2011.04698, November 2020.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读文章&lt;em&gt;AI Poincaré: Machine Learning Conservation Laws from Trajectories&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;名字挺炫酷，不过看了一遍，觉得可以借鉴的地方不多，见正文方法部分最后一句&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Manifold" scheme="http://maxliu245.github.io/tags/Manifold/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读29】深度生成模型的黎曼几何理论</title>
    <link href="http://maxliu245.github.io/2020/12/19/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB29%E3%80%91%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%BB%8E%E6%9B%BC%E5%87%A0%E4%BD%95%E7%90%86%E8%AE%BA/"/>
    <id>http://maxliu245.github.io/2020/12/19/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB29%E3%80%91%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%BB%8E%E6%9B%BC%E5%87%A0%E4%BD%95%E7%90%86%E8%AE%BA/</id>
    <published>2020-12-19T00:10:08.000Z</published>
    <updated>2021-01-11T00:55:43.299Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读文章<em>The Riemannian Geometry of Deep Generative Models</em></p><p>名字挺吓人</p></blockquote><a id="more"></a><h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><ul><li><p>18年CVPR workshop，据说评价不高</p></li><li><p>作者来自盐湖城犹他大学和IBM</p></li></ul><h2 id="简单笔记"><a href="#简单笔记" class="headerlink" title="简单笔记"></a>简单笔记</h2><div class="table-container"><table><thead><tr><th>Background</th><th>Motivation</th><th>Targets/Contributions</th><th>实验结论：</th></tr></thead><tbody><tr><td>1. 假设实际复杂数据存在流形表示，高维数据在低维流形上有结构</td><td></td><td>1. 研究生成模型中，低维隐空间中流形可能的黎曼几何性质。真研究黎曼几何中的流形，一共三个算法，见表格下方所述</td><td>实际数据的流形非线性，接近０曲率</td></tr><tr><td>2. 假设生成模型学习低维隐空间到高维数据空间的映射，即模型能利用低维隐空间参数化，映射到高维空间中的数据流形（生成器）</td><td></td><td>2. 计算测地线，主要是点到流形距离</td><td>隐空间中的（线性路径）直线相当于流形上的测地线</td></tr><tr><td></td><td></td><td>3. 沿流形path上切向量的平移（对应数据点的语义平移，generate analogies），path是啥我还不知道</td></tr></tbody></table></div><p>表中提到的文章提出三个算法：</p><ul><li>geodesic interpolation between two points on the manifold</li><li>parallel translation of a tangent vector along a path on the manifold</li><li>geodesic shooting from an initial point and velocity on the manifold</li></ul><p>问题：</p><ul><li>Chapter 2中有不少维度让我困惑，最多是D维像集微分同胚于d维隐空间？</li><li>（4）式左边是E？</li><li>为什么（4）的近似可以直接在M上用范数？需要度量来导？有点像欧氏空间了，不知道能不能这样写</li></ul><p>细节：</p><ul><li>雅可比阵把隐空间中切向量映为像集中切向量，通过自动求导计算</li><li>数据空间诱导黎曼度量，提供内积</li><li>黎曼流形平坦，曲率为0，但不一定线性！</li></ul><p>打</p><hr><p><strong>回头再更新，觉得这个文章写得很垃圾，前前后后花了一个星期推导</strong>。。。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读文章&lt;em&gt;The Riemannian Geometry of Deep Generative Models&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;名字挺吓人&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="GAN" scheme="http://maxliu245.github.io/tags/GAN/"/>
    
      <category term="Manifold" scheme="http://maxliu245.github.io/tags/Manifold/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读28】继PDE-Net 2.0后引用它的一系列文章</title>
    <link href="http://maxliu245.github.io/2020/12/12/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB28%E3%80%91%E7%BB%A7PDE-Net-2-0%E5%90%8E%E5%BC%95%E7%94%A8%E5%AE%83%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"/>
    <id>http://maxliu245.github.io/2020/12/12/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB28%E3%80%91%E7%BB%A7PDE-Net-2-0%E5%90%8E%E5%BC%95%E7%94%A8%E5%AE%83%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/</id>
    <published>2020-12-12T07:08:07.000Z</published>
    <updated>2020-12-14T05:56:39.658Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>许久未记录正式的博客笔记了，在此补上一系列文章</p><p>它们是我读完PDE-Net 2.0后顺着这条线索收集的</p></blockquote><a id="more"></a><h2 id="搜集文献（不分顺序）"><a href="#搜集文献（不分顺序）" class="headerlink" title="搜集文献（不分顺序）"></a>搜集文献（不分顺序）</h2><ol><li>Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning<ul><li>董彬老师组</li><li><a href="https://arxiv.org/abs/1905.11079?context=math" target="_blank" rel="noopener">https://arxiv.org/abs/1905.11079?context=math</a></li></ul></li><li>Data-driven recovery of hidden physics in reduced order modeling of fluid flows<ul><li><a href="https://aip.scitation.org/doi/abs/10.1063/5.0002051" target="_blank" rel="noopener">https://aip.scitation.org/doi/abs/10.1063/5.0002051</a></li><li>期刊名Physics of Fluids，20年初</li></ul></li><li>DeepMoD: Deep learning for model discovery in noisy data<ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0021999120307592" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0021999120307592</a></li><li>期刊名Journal of Computational Physics，20年11月</li></ul></li><li>Stability selection enables robust learning of partial differential equations from limited noisy data<ul><li><a href="https://arxiv.org/abs/1907.07810" target="_blank" rel="noopener">https://arxiv.org/abs/1907.07810</a></li><li>ArXiv上的分类是Mathematics—&gt;Numerical Analysis，19年7月</li></ul></li><li>Derivatives Pricing via Machine Learning<ul><li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3352688" target="_blank" rel="noopener">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3352688</a></li><li><a href="https://www.scirp.org/journal/paperinformation.aspx?paperid=94637" target="_blank" rel="noopener">https://www.scirp.org/journal/paperinformation.aspx?paperid=94637</a></li><li>期刊名Business &amp; Economics，19年</li></ul></li><li>Extracting Interpretable Physical Parameters from Spatiotemporal Systems Using Unsupervised Learning<ul><li><a href="https://journals.aps.org/prx/abstract/10.1103/PhysRevX.10.031056" target="_blank" rel="noopener">https://journals.aps.org/prx/abstract/10.1103/PhysRevX.10.031056</a></li><li>期刊名PHYSICAL REVIEW X，20年9月</li></ul></li><li>DLGA-PDE: Discovery of PDEs with incomplete candidate library via combination of deep learning and genetic algorithm<ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0021999120303582" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0021999120303582</a></li><li>期刊名Journal of Computational Physics，20年10月</li></ul></li><li>Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data<ul><li><a href="https://aip.scitation.org/doi/abs/10.1063/1.5136351" target="_blank" rel="noopener">https://aip.scitation.org/doi/abs/10.1063/1.5136351</a></li><li>期刊名Physics of Fluids，20年1月</li></ul></li><li>Data-driven Discovery of Partial Differential Equations for Multiple-Physics Electromagnetic Problem<ul><li><a href="https://arxiv.org/abs/1910.13531" target="_blank" rel="noopener">https://arxiv.org/abs/1910.13531</a></li><li>ArXiv上分类Physics—&gt;Computational Physics，19年10月</li></ul></li><li>TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes<ul><li><a href="https://arxiv.org/abs/2003.02426" target="_blank" rel="noopener">https://arxiv.org/abs/2003.02426</a></li><li>20年5月</li></ul></li><li>Sparse Symplectically Integrated Neural Networks<ul><li><a href="https://proceedings.neurips.cc/paper/2020/hash/439fca360bc99c315c5882c4432ae7a4-Abstract.html" target="_blank" rel="noopener">https://proceedings.neurips.cc/paper/2020/hash/439fca360bc99c315c5882c4432ae7a4-Abstract.html</a></li><li>NIPS’20</li></ul></li><li>DeepM&amp;Mnet: Inferring the electroconvection multiphysics fields based on operator approximation by neural networks<ul><li><a href="https://arxiv.org/abs/2009.12935" target="_blank" rel="noopener">https://arxiv.org/abs/2009.12935</a></li><li>ArXiv上分类Physics—&gt;Computational Physics，20年9月</li></ul></li><li>Integration of Neural Network-Based Symbolic Regression in Deep Learning for Scientific Discovery<ul><li><a href="https://ieeexplore.ieee.org/abstract/document/9180100" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/9180100</a></li><li>IEEE Transactions on Neural Networks and Learning Systems，20年8月</li></ul></li></ol><h2 id="1-Learning-to-Discretize-Solving-1D-Scalar-Conservation-Laws-via-Deep-Reinforcement-Learning"><a href="#1-Learning-to-Discretize-Solving-1D-Scalar-Conservation-Laws-via-Deep-Reinforcement-Learning" class="headerlink" title="1. Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning"></a>1. Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning</h2><h3 id="文献资料"><a href="#文献资料" class="headerlink" title="文献资料"></a>文献资料</h3><ol><li><p>董彬老师组的文章，2020/10挂出来</p></li><li><p><a href="https://arxiv.org/abs/1905.11079?context=math" target="_blank" rel="noopener">https://arxiv.org/abs/1905.11079?context=math</a></p></li></ol><h3 id="表格总结"><a href="#表格总结" class="headerlink" title="表格总结"></a>表格总结</h3><p>总结完了觉得文章的<strong>思路正常</strong>，文章的一个<strong>亮点</strong>是抽象数值方法为RL问题时<strong>引入了meta-learner</strong>的概念？</p><table id="tfhover" class="tftable" border="1" style="table-layout:fixed;">    <col style="width: 15%">    <col style="width: 85%"><tr><th>文献条目</th><th>具体内容</th></tr><tr><td>Target</td><td><body>  <ul type="disc">    <li>先声明大领域，依然是拟合PDE数据，包括数值方法、DL方法</li>    <li>本文针对求解特定的PDE，守恒律方程（associated with conservation laws）</li>  </ul></body></td></tr><tr><td>Motivation/Idea</td><td><body>  <ul type="disc">    <li>守恒律很重要，应用多。且Burgers方程就是其一个特例</li>    <li>从数值方法出发，把PDE-solver看成MDP（Markov Decision Process），进而抽象为强化学习基本问题</li>    <li>上述数值方法是WENO（Weighted Essentially Non-Oscillatory Schemes），稍后在细节介绍，基于它有两个ideas：<ul><li>自动化得到方法中的weights</li><li>自动（原WENO需要进行数值判断）判断方法中的upwind direction，此概念在细节中介绍</li></ul></li>  </ul></body></td></tr><tr><td>Method</td><td><body>  <ul type="disc">    整个模型没有命名，其实提供了一种把数值方法转化为网络、DL问题的思路    <li>基本模型就是求解PDE的WENO数值方法抽象为MDP形式</li>    <li>MDP问题再引入RL，具体细节将在下面介绍</li>  </ul></body></td></tr><tr><td>Pros and Cons</td><td><body>  <ul type="disc">    Pros:      <li>把求解1维情况下守恒律方程的数值方法转化为RL问题，其建模过程很标准，可以说是一个framework</li>      <li>数值方法直接转化为MDP，RL，model-driven么</li>      <li><b>文章重点提到action的构建是个meta-learner,一个说法是，这样的模型泛化不错，一个功劳就归meta-learner</b></li>    <br>Cons:      <li>别问我为什么meta-learner，怎么就meta-learner了，原因我放在后面单独提一下</li>      <li>只考虑了1维情形下守恒律，不能直接推广的话。。。</li>      <li>流（flux）的建模依托于WENO，插值太多，虽然插值很精细但总觉得不优美，说不清楚</li>  </ul><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body></td></tr></table><h3 id="部分细节"><a href="#部分细节" class="headerlink" title="部分细节"></a>部分细节</h3><h4 id="模型基本设置"><a href="#模型基本设置" class="headerlink" title="模型基本设置"></a>模型基本设置</h4><p>先讲讲所谓有守恒律的方程指什么吧，其实就是指这个方程有守恒律，形式如下：</p><script type="math/tex; mode=display">\displaystyle u_x(x,t)+(f(u(x,t)))_x = 0,\ where\ a\leq x\leq b,\ t\in [0,T],\ u(x,0)=u_0(x) \tag{1}</script><p>这个形式就叫守恒律。由参数 $\{x,t\}$ 取值在区间上可知，ob数据的形式是把时空间分别分割，得到网格式数据，分割一般均匀，设分割长度和总数分别为 $\Delta x, \Delta t$ 和 $J, N$，详见原文公式 $(2.2)$。</p><p>然后有几个概念要说一下，真实解 $u(x,t)$ 在网格上的取值为 $u(x_j,t_n)$，它的近似记为 $\mathcal{U}_j^n$；另外，$(1)$ 式中间的 $f$ 称为flux，可以理解为守恒律中的流，真实的flux记为 $f_j^n=f(u(x_j,t_n))$。</p><p>最后有个空间中的插值，记号为 $\displaystyle x_{j\pm\frac{1}{2}}=x_j\pm\frac{\Delta x}{2}$，感觉就是更细一点的插值。</p><h4 id="WENO数值方法"><a href="#WENO数值方法" class="headerlink" title="WENO数值方法"></a>WENO数值方法</h4><p>从名字上看这个方法，Weighted Essentially Non-Oscillatory Schemes，推测就是<strong>插值更细</strong>因此可能拟合结果波动更小，插值的时候还有重要性（插值准确性）加权。</p><p>下面给个WENO方法的计算过程：</p><div class="row">    <embed src="20201212-1D-1.pdf" width="100%" height="550" type="application/pdf"></div><p>如上最后两行，WENO就像一个<strong>多重平均插值</strong>近似，<strong>主要问题</strong>在于不同插值权重的计算、和最后一个upwind direction计算。后者应该是希望数值解不要震荡的方法，参考<a href="https://baike.baidu.com/item/%E4%BA%8C%E9%98%B6%E8%BF%8E%E9%A3%8E%E6%A0%BC%E5%BC%8F/3533165" target="_blank" rel="noopener">二阶迎风格式</a>。</p><h4 id="WENO对应到MDP"><a href="#WENO对应到MDP" class="headerlink" title="WENO对应到MDP"></a>WENO对应到MDP</h4><p>没啥好说的，根据WENO的计算方法写成算法，然后对应到MDP中的state $S$，action $A$，transition dynamics $P$，reward $r$。</p><img src="/2020/12/12/【论文略读28】继PDE-Net-2-0后引用它的一系列文章/1D-1.png" title="WENO算法"><img src="/2020/12/12/【论文略读28】继PDE-Net-2-0后引用它的一系列文章/1D-2.png" title="RL对应"><p>这样就完事了，再简要介绍一下里面的东西是什么：</p><ul><li>$s$ 是state，有个state function，把指标集对应的$\mathcal{U}_j^\lambda,\ \lambda\in \Lambda$ 映射到 $\hat{f}_j^n$。一个例子是对pdf的三次插值，那 $s$ 就映到3个向量，每个向量是每次插值的所有点（$f_j^\lambda$）和该次插值对应的权重，具体实现是方式是用6层，每层64神经元的MLP，并use the Twin Delayed Deep Deterministic (TD3) policy gradient algorithm to train the RL policy。。。</li><li>$A$ 是action，就是pdf最后一行提到的选择哪些插值，由 $s$ 函数生成</li><li>$P$ 相当于迭代机制，比如前向欧拉对应的迭代形式。。。</li><li>$r$ 用的插值时的无穷范数的相反数</li></ul><h4 id="哪来的meta-learner"><a href="#哪来的meta-learner" class="headerlink" title="哪来的meta-learner"></a>哪来的meta-learner</h4><p>思想不错，$A$ 成为一个meta-learner，原因只有这个靠谱：这个RL里的 $A$ 是通过 $s$ 函数输出得到的，是从当前状态判断的，不是像原来的数值方法那样，在没有其它网络（如上文MLP）的帮助下直接从数值机制推断的。</p><p>文章提的其它原因不太靠谱：</p><ul><li>Learning the policy $P$ within the RL framework makes the algorithm meta-learning like [1, 5, 10, 20, 29].</li><li>The learned policy network is carefully designed to determine a good local discrete approximation based on the current state of the solution, which essentially makes the proposed method a meta-learning approach.</li><li>We attribute the good generalization ability of RL-WENO to our careful action design, which essentially makes RL-WENO a meta-learner under the WENO framework and thus have  strong out-of-distribution generalization.</li></ul><h2 id="2-DeepMoD-Deep-learning-for-model-discovery-in-noisy-data"><a href="#2-DeepMoD-Deep-learning-for-model-discovery-in-noisy-data" class="headerlink" title="2. DeepMoD: Deep learning for model discovery in noisy data"></a>2. DeepMoD: Deep learning for model discovery in noisy data</h2><p><strong><font color="#FF0000">突然想到一个问题，目前没看到几篇文章很关注PDE的边界条件！</font></strong>本文也没有考虑。</p><h3 id="文献资料-1"><a href="#文献资料-1" class="headerlink" title="文献资料"></a>文献资料</h3><ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0021999120307592" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0021999120307592</a></li><li>好像是巴黎大学的研究者写的</li><li>期刊名Journal of Computational Physics，20年11月</li></ul><h3 id="小结：我觉得不彳亍"><a href="#小结：我觉得不彳亍" class="headerlink" title="小结：我觉得不彳亍"></a>小结：我觉得不彳亍</h3><h4 id="模型：DeepMoD及具体内容"><a href="#模型：DeepMoD及具体内容" class="headerlink" title="模型：DeepMoD及具体内容"></a>模型：DeepMoD及具体内容</h4><p>本文提出模型，DeepMoD，指的是deep learning based model discovery algorithm，目标是从数据中学习背后的PDE。该PDE模型的形式其实比较局限，固定为：</p><script type="math/tex; mode=display">\displaystyle \partial_t u = \partial_t u(x,t)=\mathcal{F}(u,u_x,uu_x,u_xx\cdots)\approx \Theta\xi \tag{1}</script><p>两个大困惑，读了好几遍搞不明白，文章为什么要刻意避开这个问题❔我觉得只考虑了这样的形式是因为把神经网络 $f_i$ 作为函数字典，输入是 $(\mathbf{x, t})$，那么输出对输出自动求导看成偏导数。但是<strong>为什么原文公式 $(1)$ 没有 $u$ 对 $t$ 求导呢，是不是在刻意混淆</strong>？而且文章的实验表示不是整个grid上都有数据，可以随机取，那么偏导数也是不能全的啊，怎么保证神经网络就能对输入求导得到字典中的基函数，见下面图中的Library？</p><img src="/2020/12/12/【论文略读28】继PDE-Net-2-0后引用它的一系列文章/DeepMoD-1.png" title="DeepMoD"><p>具体方法采用了函数字典，使用稀疏回归，回归时加正则。使用densely-connected feed-forward neural network作为函数的估计，来构建函数字典。考虑了三种loss，MSE损失针对 $u(x,t)$，只考虑每条轨线末端值的监督；回归损失针对 $\Theta\xi$ 的拟合，但是原文的式子下标没写清楚，弄不明白哪里做了监督；最后是字典系数 $\xi$ 的 $L_1$ 正则</p><p>网络训练有2个骚操作：</p><ul><li>数据有一些处理，当神经网络训练完之后，得到的函数字典的稀疏系数其实会不那么稀疏（$L_1$ 不能保证完全稀疏），进一步进行无量纲化，方式是所有变量标准化，包括原文 $(2)$ 式中的 $\partial_t u,\Theta,\xi$，具体意义见原文 $(3,4)$ 式。</li><li>网络训练完之后，再练一次，不加 $L_1$ 正则了，回归项只用之前筛选出来的，原文只说这样得系数的无偏估计❔</li></ul><p>这个方法起效果需要函数字典充足，不过实验结果似乎表示很充足也不至于过拟合，有对函数系数的正则，这个正则和系数某个阈值的设置有关。这个设置似乎不是general的（见Discussion部分）。字典中函数的系数代表了某种模型选择。</p><h4 id="Pros-and-Cons"><a href="#Pros-and-Cons" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h4><p>前两个文章自己说的优点很奇怪：</p><ul><li><p>一个是<strong>对噪声非常稳健</strong>，是实验结论</p></li><li><p>第二个是<strong>不需要训练集</strong>。这应该指的是<strong>不需要太多训练数据，小样本</strong>也可以，并不是完全不需要，原文进行了5种方程的人工实验，一个结论是几种方程的模拟只需要 $\mathcal{O}(10^2)$ 的数据量。</p><blockquote><p>优点原文：This construction makes it <strong>extremely robust to noise</strong>, <strong>applicable to small data sets</strong>, and, contrary to other deep learning methods, <strong>does not require a training set</strong>.</p><p>实验结果之一：</p><p>find that it requires as few as $\mathcal{O}(10^2)$ samples and works at noise levels up to 75%</p></blockquote></li><li><p>第三个是DeepMoD对数据的维度没有要求，之前有些模型是针对1维数据的</p></li><li>第四个，函数字典有模型选择的功能，只是少了点味</li></ul><p>文章表示DeepMoD很稳健，需要数据量少是因为利用regression-based approach完成model discovery任务，用神经网络infer system parameters。。。说🔨呢，真的是原文。。。我很不喜欢这样的说法</p><p>缺点来了，读不明白就甩锅：</p><ul><li>PDE模型的形式到底局限么？原文是不是在故意回避这个问题</li><li>怎么保证神经网络就能对输入求导得到字典中的基函数？偏导数不一定能全？</li><li>两次训练为什么是无偏估计，没说</li><li>阈值的设置好像是special的</li><li>只靠loss得到所谓的稳健、小样本。难道又是实验验证？我不信，而且全是模拟数据</li><li>本文提了一下边界条件，但是仍然没考虑</li></ul><h2 id="10-TIME-A-Transparent-Interpretable-Model-Adaptive-and-Explainable-Neural-Network-for-Dynamic-Physical-Processes"><a href="#10-TIME-A-Transparent-Interpretable-Model-Adaptive-and-Explainable-Neural-Network-for-Dynamic-Physical-Processes" class="headerlink" title="10. TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes"></a>10. TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes</h2><ul><li><a href="https://arxiv.org/abs/2003.02426" target="_blank" rel="noopener">https://arxiv.org/abs/2003.02426</a></li><li>20年5月</li></ul><div class="row">    <embed src="TIME.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>APA 7th格式</p><p>[1] Wang, Y., Shen, Z., Long, Z., &amp; Dong, B. (2019). Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning. arXiv e-prints, arXiv:1905.11079. <a href="https://ui.adsabs.harvard.edu/abs/2019arXiv190511079W" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2019arXiv190511079W</a> </p><p>[2] Pawar, S., Ahmed, S. E., San, O., &amp; Rasheed, A. (2020). Data-driven recovery of hidden physics in reduced order modeling of fluid flows. Physics of Fluids, 32(3), 036602. <a href="https://doi.org/10.1063/5.0002051" target="_blank" rel="noopener">https://doi.org/10.1063/5.0002051</a> </p><p>[3] Both, G.-J., Choudhury, S., Sens, P., &amp; Kusters, R. (2020). DeepMoD: Deep learning for model discovery in noisy data. Journal of Computational Physics, 109985. <a href="https://doi.org/https://doi.org/10.1016/j.jcp.2020.109985" target="_blank" rel="noopener">https://doi.org/https://doi.org/10.1016/j.jcp.2020.109985</a> </p><p>[4] Maddu, S., Cheeseman, B. L., Sbalzarini, I. F., &amp; Müller, C. L. (2019). Stability selection enables robust learning of partial differential equations from limited noisy data. arXiv e-prints, arXiv:1907.07810. <a href="https://ui.adsabs.harvard.edu/abs/2019arXiv190707810M" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2019arXiv190707810M</a> </p><p>[5] Ye, T., &amp; Zhang, L. (2019). Derivatives Pricing via Machine Learning. Journal of Mathematical Finance, 09, 561-589. <a href="https://doi.org/10.4236/jmf.2019.93029" target="_blank" rel="noopener">https://doi.org/10.4236/jmf.2019.93029</a> </p><p>[6] Lu, P. Y., Kim, S., &amp; Soljačić, M. (2020). Extracting Interpretable Physical Parameters from Spatiotemporal Systems Using Unsupervised Learning. Physical Review X, 10(3), 031056. <a href="https://doi.org/10.1103/PhysRevX.10.031056" target="_blank" rel="noopener">https://doi.org/10.1103/PhysRevX.10.031056</a> </p><p>[7] Xu, H., Chang, H., &amp; Zhang, D. (2020). DLGA-PDE: Discovery of PDEs with incomplete candidate library via combination of deep learning and genetic algorithm. Journal of Computational Physics, 418, 109584. <a href="https://doi.org/https://doi.org/10.1016/j.jcp.2020.109584" target="_blank" rel="noopener">https://doi.org/https://doi.org/10.1016/j.jcp.2020.109584</a> </p><p>[8] Vaddireddy, H., Rasheed, A., Staples, A. E., &amp; San, O. (2020). Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data. Physics of Fluids, 32(1), 015113. <a href="https://doi.org/10.1063/1.5136351" target="_blank" rel="noopener">https://doi.org/10.1063/1.5136351</a> </p><p>[9] Xiong, B., Fu, H., Xu, F., &amp; Jin, Y. (2019). Data-driven Discovery of Partial Differential Equations for Multiple-Physics Electromagnetic Problem. arXiv e-prints, arXiv:1910.13531. <a href="https://ui.adsabs.harvard.edu/abs/2019arXiv191013531X" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2019arXiv191013531X</a> </p><p>[10] Singh, G., Gupta, S., Lease, M., &amp; Dawson, C. N. (2020). TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes. arXiv e-prints, arXiv:2003.02426. <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200302426S" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200302426S</a> </p><p>[11] DiPietro, D. M., Xiong, S., &amp; Zhu, B. (2020). Sparse Symplectically Integrated Neural Networks. arXiv e-prints, arXiv:2006.12972. <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200612972D" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200612972D</a> </p><p>[12] Cai, S., Wang, Z., Lu, L., Zaki, T. A., &amp; Karniadakis, G. E. (2020). DeepM&amp;Mnet: Inferring the electroconvection multiphysics fields based on operator approximation by neural networks. arXiv e-prints, arXiv:2009.12935. <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200912935C" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200912935C</a> </p><p>[13] Kim, S., Lu, P. Y., Mukherjee, S., Gilbert, M., Jing, L., Čeperić, V., &amp; Soljačić, M. (2020). Integration of Neural Network-Based Symbolic Regression in Deep Learning for Scientific Discovery. IEEE Transactions on Neural Networks and Learning Systems, 1-12. <a href="https://doi.org/10.1109/TNNLS.2020.3017010" target="_blank" rel="noopener">https://doi.org/10.1109/TNNLS.2020.3017010</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;许久未记录正式的博客笔记了，在此补上一系列文章&lt;/p&gt;
&lt;p&gt;它们是我读完PDE-Net 2.0后顺着这条线索收集的&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读27】RODE-Net——不确定性引入与GAN的精妙引入</title>
    <link href="http://maxliu245.github.io/2020/11/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB27%E3%80%91RODE-Net%E2%80%94%E2%80%94%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%BC%95%E5%85%A5%E4%B8%8EGAN%E7%9A%84%E7%B2%BE%E5%A6%99%E5%BC%95%E5%85%A5/"/>
    <id>http://maxliu245.github.io/2020/11/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB27%E3%80%91RODE-Net%E2%80%94%E2%80%94%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%BC%95%E5%85%A5%E4%B8%8EGAN%E7%9A%84%E7%B2%BE%E5%A6%99%E5%BC%95%E5%85%A5/</id>
    <published>2020-11-21T12:52:01.000Z</published>
    <updated>2020-11-21T13:47:58.554Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>许久的颓废之后重新开始看文章，这次给大家带来一首隐式meta和GAN结合的思想之歌！</p><p><code>RODE-Net: Learning Ordinary Differential Equations with Randomness from Data</code></p></blockquote><a id="more"></a><h1 id="Overview-amp-Target"><a href="#Overview-amp-Target" class="headerlink" title="Overview &amp; Target"></a>Overview &amp; Target</h1><img src="/2020/11/21/【论文阅读27】RODE-Net——不确定性引入与GAN的精妙引入/RODE-Net-1.png" title="文献概览"><p>这是董彬老师组于2020/06挂在Arxiv上的文章，文章链接：<a href="https://arxiv.org/abs/2006.02377" target="_blank" rel="noopener">https://arxiv.org/abs/2006.02377</a></p><p>文献主要<strong>研究对象</strong>叫RODE，全称<code>Random ordinary differential equations</code>，指的是ODE系统中的参数看成随机变量。研究的基本问题还是从ODE的轨线（轨迹）数据学习背后的方程究竟是什么</p><p>不过读完了文章不是很推荐，因为走的还是拟合（如果ODE-Net基本模型有解释性那么不错）的路子。只是觉得有些思路可以借鉴</p><h1 id="Background-amp-Motivation"><a href="#Background-amp-Motivation" class="headerlink" title="Background &amp; Motivation"></a>Background &amp; Motivation</h1><p>文献<strong>背景</strong></p><ul><li>RODE这类方程引入了一定的随机性</li><li>实际数据可能有不同量纲的特征，这对拟合影响很大</li></ul><p>过去方法缺点：</p><ol><li>如果采用暴力拟合，总归是不好的</li><li>从实际数据获取背后的ODE系统往往需要强先验（ODE形式的归纳偏置）</li><li>即使加了强先验，大家过去也假设参数固定，因此只是平均意义下近似真实ODE系统；真实情况下还有随机性</li></ol><p>进一步地，文章的<strong>动机</strong>就出来了，其实就是一般的从轨线找背后ODE规律的问题，只是相当于直接把原来的ODE中参数添加先验，期以引入不确定性更符合实际，然后为了拟合加了GAN的对抗机制，请见下文</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Data-generation"><a href="#Data-generation" class="headerlink" title="Data generation"></a>Data generation</h2><p>刚开始看不懂数据是怎么采样出来的，后来明白了，数据生成的过程以文中 $(4.1)$ 节为例。先有模型参数的归纳偏置即先验假设，然后生成 $M$ 组参数，这样就有 $M$ 个ODE，选择初始点 $N_i$ 个，分别用4阶龙格-库塔法生成轨线，这样每个确定的ODE采样了 $N_i$ 条轨线，共 $M$ 个确定的ODE。所以最后得到的数据就是</p><script type="math/tex; mode=display">X=\{x_{\eta_i}^j(t_k)|1\leq i\leq M,\ 1\leq j\leq N_i,\ 0\leq k\leq S\} \tag{1}</script><p>其中 $(1)$ 中 $x$ 是其实是轨线向量，下标 $\eta_i$ 就是每次采样的参数，上标 $j$ 表示初值的编号，后面的 $t_k$ 就是龙格-库塔得到的不同采样时刻</p><blockquote><p>原文表述：</p><p>we generate data $x_{\eta_i}^j(t_k)$ by solving $ODE-\eta_i$ using the fourth order Runge-Kutta method with $N_i$ different initial values$x_{\eta_i}^j(t_0),j=1,\cdots,k$</p></blockquote><h2 id="RODE-Net"><a href="#RODE-Net" class="headerlink" title="RODE-Net"></a>RODE-Net</h2><p>文章提出的引入不确定性的模型，以及对应的网络模型称为RODE-Net。前者即：</p><script type="math/tex; mode=display">\displaystyle \dfrac{dx}{dt} = F_{\eta}(x), x=(x_1,\cdots,x_d)\in \mathbb{R}^d,t\geq 0\tag{2}</script><p>其中 $\eta$ 就是假定有先验分布的参数。后者RODE-Net的结构图如下：</p><img src="/2020/11/21/【论文阅读27】RODE-Net——不确定性引入与GAN的精妙引入/RODE-Net-2.png" title="RODE-Net"><blockquote><p>ps：上面的先验假设应该是可以嵌套的</p></blockquote><p>这个结构里有如下亮点：</p><ul><li>中间的ODE-Net其实就可以是以往的暴力拟合框架，这里文章用了所谓的SymNet中包含了符号运算，内蕴了dynamic操作，因此某种程度上有可解释性。这个SymNet我不知道具体是怎么进行符号运算的，但是我推测是他们组PDE-Net2.0中卷积相关的操作，这个可以；但是后文提到引入GAN的目的之一是避免符号预算的求导，我就<strong>不懂</strong>了，既然符号运算不便求导，那主网络是怎么BP的？</li><li>基础模型ODE-Net之外引入GAN，目的之一是避免SymNet中符号运算求导，目的之二是提供原网络参数更好的监督，进而形成目的三是作为了原网络的正则。联想到之前的ODE2VAE应该是有类似的考虑！</li><li><strong>引入GAN的同时有meta-learning的味道，体现在GAN的double使用，生成之后反过来指导主网络的训练</strong>，类比一下是不是所有模型与GAN嵌套都有这个作用，生成的数据质量越来越高，乃至接近于meta数据，大概也是为什么GAN效果好的解释之一？</li></ul><p>RODE-Net中具体用的ODE-Net主模型就是PDE-Net中变过来的带有符号运算性质的网络；GAN用了WGAN（Wasserstein GAN），细节应该问题不大</p><p>最后讲一下整个RODE-Net是怎么训练的以及其目标函数，从这里感觉，其训练方式是有meta-learning的味道的，这个GAN的double使用，但是<strong>loss上看还是所谓的外练筋骨皮</strong></p><p>训练的过程很像meta方法。先是主网络正常训练，有数据点拟合的监督和对应于异常点不容忍的Huber正则；第二步是第一步得到的模型参数生成，扔到WGAN里训练一下，期中也加了一个梯度惩罚正则，即WGAN-GP；第三步是WGAN返回来作为主模型的正则，希望对抗前后主模型的参数不要相差过大，这样提供了一种整体上的控制</p><blockquote><p>Huber损失介绍，介于 $L_1$ 和 $L_2$ 之间，思想是调整对异常的容忍程度，因此有额外的一个超参数，很棒，可以日后借鉴：</p><p>知乎用户<a href="https://www.zhihu.com/org/jing-lue-ji-zhi" target="_blank" rel="noopener">景略集智</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/39239829" target="_blank" rel="noopener">机器学习从业者必知的5种回归损失函数</a>，细节满满</p><p>博客园用户<a href="https://www.cnblogs.com/nowgood/" target="_blank" rel="noopener">nowgood</a>的博客<a href="https://www.cnblogs.com/nowgood/p/Huber-Loss.html" target="_blank" rel="noopener">Huber Loss</a>，主要是函数的介绍</p></blockquote><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><div class="table-container"><table><thead><tr><th>Pros</th><th></th></tr></thead><tbody><tr><td>RODE建模的不确定性是指参数本身的不确定性，实际意义挺好</td><td>文章有一处不懂的：既然符号运算不便求导而引入GAN，那主网络是怎么BP的</td></tr><tr><td>GAN交替使用，相当于用两个GAN，有meta的味道</td><td>这里的多次正则也只是相对于ob数据的，没有真正意义上的泛化</td></tr><tr><td>GAN作为数据驱动正则的思想（目前比 $L_1$ 效果上好）</td><td>文章最后提了一句先验引入可以使高维参数降维，我寻思着不是一般升维了…</td></tr><tr><td>GAN和RODE的”R”天然契合，因为GAN本身就是参数分布的一种估计</td><td>文章最后说non-transparency，确实某种程度上没有建模深层次的dynamic性质（符号运算？）</td></tr></tbody></table></div><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>这次会用EndNote了，试试APA 7th格式，其它参考链接见文中注释部分</p><p>[1] Liu, J., Long, Z., Wang, R., Sun, J., &amp; Dong, B. (2020). RODE-Net: Learning Ordinary Differential Equations with Randomness from Data. arXiv:2006.02377. Retrieved June 01, 2020, from <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200602377L" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200602377L</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;许久的颓废之后重新开始看文章，这次给大家带来一首隐式meta和GAN结合的思想之歌！&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RODE-Net: Learning Ordinary Differential Equations with Randomness from Data&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Regularization" scheme="http://maxliu245.github.io/tags/Regularization/"/>
    
  </entry>
  
  <entry>
    <title>MLA‘20见闻</title>
    <link href="http://maxliu245.github.io/2020/11/10/MLA%E2%80%9820%E8%A7%81%E9%97%BB/"/>
    <id>http://maxliu245.github.io/2020/11/10/MLA%E2%80%9820%E8%A7%81%E9%97%BB/</id>
    <published>2020-11-09T16:24:40.000Z</published>
    <updated>2020-11-10T06:38:56.887Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>MLA‘20之行让我学到了很多，包括领域知识，对学习生活的前瞻，以及更多对当下学习困境的思考</p><p>故创文记之，以思故我。就当是小小随笔</p><p>不太好写啊！干脆随便总结下吧，细节留在网盘里就好</p></blockquote><a id="more"></a><img src="/2020/11/10/MLA‘20见闻/MLA-1.JPG" title="MLA" alt="20开冲！"><p>会议日程 <a href="http://www.lamda.nju.edu.cn/conf/mla20/program.html" target="_blank" rel="noopener">http://www.lamda.nju.edu.cn/conf/mla20/program.html</a></p><h1 id="流水账"><a href="#流水账" class="headerlink" title="流水账"></a>流水账</h1><h2 id="第一天上午"><a href="#第一天上午" class="headerlink" title="第一天上午"></a>第一天上午</h2><p>第一场，北大王立威教授介绍深度学习，主要提到了泛化理论的新解释。</p><p>先介绍了下深度学习的方向：</p><pre class="mermaid">graph LRA(深度学习) -->B(模型/结构)A(深度学习) -->C(训练/优化)A(深度学习) -->D(泛化/测试优化)B -->E[CNN]B -->F[RNN]B -->G[LPWHW, 2017]B -->H[Cybenko, 1998]</pre><blockquote><p>ps：画图的时候要选择mermaid而不是flow，否则报错</p><p><code>ERROR: [Flowchart] Cannot set property &#39;next&#39; of undefined</code></p><p>ps2：mermaid在hexo中需要安装包才能使用，且里面所有的操作都要加上 <a href="https://www.dazhuanlan.com/2019/11/20/5dd4ec5f4f552/" target="_blank" rel="noopener">https://www.dazhuanlan.com/2019/11/20/5dd4ec5f4f552/</a> <a href="https://tyloafer.github.io/posts/7790/" target="_blank" rel="noopener">https://tyloafer.github.io/posts/7790/</a></p></blockquote><p>重点提到了学习理论的泛化解释可能是有问题的。</p><img src="/2020/11/10/MLA‘20见闻/IMG_1996.JPG" title="过参数化而非过拟合"><p>即过拟合并不是过拟合，而是过参数化，过参数化不会导致泛化性能的大幅下降，还能保持一定的泛化能力。</p><p>然后讲了优化，一个小背景是即便是4阶多项式局部极小的优化也是NP难的问题。然后有个结论是一般的SGD方法在绝大多数方法上都work well，为什么？2019年ICML的DLLWZ证明了梯度下降GD可以以一个线性收敛速度（in a linear convergence rate）找到全局极小，但是有两个条件（没条件显然不太对头），一是网络要足够宽（即足够过参数化），然后参数的初始化选择Gauss，选择其中的协方差参数，最后选合适的step size。ResNet的确更好。</p><p>当网络无限宽时，网络会退化成kernel machine。</p><img src="/2020/11/10/MLA‘20见闻/MLA-3.JPG" title="神经网络的拟合能力"><p>方法的一个insight是，在这样的初始点附近，其邻域的性质好，存在一个所谓内在的全局极优？</p><img src="/2020/11/10/MLA‘20见闻/IMG_1998.JPG" title="DLLWZ, 2019"><p>最后有个文章列表</p><img src="/2020/11/10/MLA‘20见闻/IMG_2011.JPG" title="老师组内文章列表（仅参考）"><hr><p>第二位老师是UCLA的印卧涛，主题是Faster Learning over Networks and Opensource Framework BlueFog，介绍大规模模型。</p><p>大规模数据或者模型的处理方式是</p><pre class="mermaid">graph LRA(大规模) -->B(数据并行)A(深度学习) -->C(模型并行)A(深度学习) -->D(模型分割后并行?)</pre><p>其中一种方案是parameter server approach，但不适合大规模。方式是一张卡和多张卡之间传输数据，但是n21似乎不太好整合。</p><pre class="mermaid">graph LRA(大卡) -->B(卡1)A(大卡) -.1对多.->C(...)A(大卡) -->D(卡n)E(左到右:1对多<br>右到左:多对1)</pre><p>报告中指出一个方案是环上的整合，叫ring allreduce，缺点是同一时刻edge只有一个</p><p>然后推荐了他们自己的framework：bluefog，好像几行代码能完成相关工作。后面没听了</p><hr><p>第三场是微软亚洲研究院的秦涛讲神经语言合成。</p><pre class="mermaid">graph LRA(神经语言合成) -->B(拼接方法<br>比如concatenative TTS<br>缺点是自由度低)A -->C(参数化方法<br>parametric TTS<br>优点是灵活,缺点是可能不自然)A -->D(神经网络方法<br>更前沿就对了)%%E(左到右:1对多<br>右到左:多对1)</pre><p>然后倒是讲了不少neural方法的例子：</p><ul><li>Deep Voice 3(ICLR 2018)</li><li>Tacotron 2(LSTM)</li><li>Transformer TTS(AAAI 2019)</li><li>Fast Speech(NIPS 2019)</li></ul><hr><p>第四场是是顶会交流介绍。列表参考 <a href="http://www.lamda.nju.edu.cn/conf/mla20/poster.html#spotlight%2011_07" target="_blank" rel="noopener">http://www.lamda.nju.edu.cn/conf/mla20/poster.html#spotlight%2011_07</a> ，有需求的时候自取。</p><p>其中我自己想看的列在这里：</p><ul><li>王红师姐的模型驱动+数据驱动</li><li>清华的Understanding and Exploring the Network with Stochastic Architectures</li></ul><h2 id="第一天下午"><a href="#第一天下午" class="headerlink" title="第一天下午"></a>第一天下午</h2><p>第五场是孙剑介绍CV前沿，自己的笔记记得挺多的。太多了所以不想整理了喵。不过注意他这里面讲得非常全的，有几个我感兴趣的，比如过参数化的解释、shuffleNet特征图间操作、目标检测的一些东西，etc。</p><hr><p>第六场是南大吴建鑫介绍CNN压缩。一个背景是小设备上需要轻量网络。一般的方法是剪枝，总结如下：</p><pre class="mermaid">graph LRA(网络剪枝) -->B(剪枝基本方法<br>网络权重低于某阈值时就压缩<br>缺点是使模型非结构化,难以加速)B --> E(一篇文章作为例子 Han Song NIPS 2015)A -->C(结构化剪枝<br>即保持网络形状不变)C --> F(剪哪些<br>idea是剪一部分,后面对应的net也会受影响)C --> G(怎么剪<br>具体没听清楚,大概是数学优化的角度做reconstruction,最小化下一层的啥目标)%%E(左到右:1对多<br>右到左:多对1)</pre><p>上面是以往设计的压缩剪枝方式，总结的话就是人工剪枝三段式：确定权重/重要性，剪掉，再微调网络参数。现在呢，有人在做自动压缩的方法，咋做没记笔记，大概是auto-pruner，另外还有人做ResNet剪枝、小数据任务上的剪枝，等等。</p><hr><p>第七场是复旦黄萱菁讲中文命名实体识别，感觉是NLP方法的一些变种，具体没有咋听。</p><hr><p>第八场是孟老师操作一手，讲模型驱动与数据驱动之间的差异、联系、结合。</p><p>以图像去噪为例，模型驱动主要是生成方式的理解， $\displaystyle \arg\min_{z} L(Y-z)+R(z)$ ，其中 $Y$ 是带噪图， $z$ 是潜在的干净图，所以 $Y-z$ 其实就相当于噪声；数据驱动则直接网络拟合干净图，</p><script type="math/tex; mode=display">\displaystyle \arg\min_{w} ||z-net_w (Y)||_2</script><p>其中 $z$ 可以是提供的真实干净图，但也可以去拟合噪声啊，这样就是 </p><script type="math/tex; mode=display">\displaystyle \arg\min_{w} ||\varepsilon-ResNet_w (Y)||_2</script><p>但是数据驱动的确是黑箱操作，缺点是解释性相对较差，无生成功能，且依赖于监督标记。</p><p>孟老师操作了一手模型、数据驱动结合的理解，二者能否互补？由此孟老师来了一手外练筋骨皮、内练一口气、万法归宗的比喻，具体放在图里看一下：</p><pre class="mermaid">graph LRA(模型驱动&数据驱动) -->B(外练筋骨皮<br>需要知道/建模数据是怎么走的)A -->C(内练一口气<br>网络结构需要有可解释性)A -->D(万法归宗<br>数据驱动学习生成规律?)B -.paper1.-> E(MAP的, TPAMI 18, 讲CT的,链接放在文末)B -.paper2.-> F(王红大佬的去雨模型<br>ps:我怎么觉得这个是内练?可能笔记记错了)C -.idea.-> G(idea<br>网络由黑箱隐式函数到显示函数<br>优化算法解释为网络结构的迭加形式)C -.e.g..-> H(deep unfolding就是其中一类方法)%%E(左到右:1对多<br>右到左:多对1)</pre><hr><p>第九场也非常精彩！是朱军老师介绍贝叶斯深度学习，但是我的笔记没有记全😭。只记了以下几点：</p><ol><li><p>Bayes和NN的结合要回到Hopfield当年一个学生的博士论文</p></li><li><p>BNN可以与高斯过程联系起来！</p></li><li><p>Drop out也可以看/理解成是一种贝叶斯</p></li><li><p>NICE中的flow-based-model</p></li><li><p>VFlow没有拍到，但是好像非常有意思，回头搜一下</p><blockquote><p>搜到了：<em>VFlow: More Expressive Generative Flows with Variational Data Augmentation</em></p><p><a href="https://www.aminer.cn/pub/5e54f1813a55acae32a25d67/vflow-more-expressive-generative-flows-with-variational-data-augmentation" target="_blank" rel="noopener">https://www.aminer.cn/pub/5e54f1813a55acae32a25d67/vflow-more-expressive-generative-flows-with-variational-data-augmentation</a></p><p><a href="https://arxiv.org/abs/2002.09741" target="_blank" rel="noopener">https://arxiv.org/abs/2002.09741</a></p><p><a href="https://github.com/thu-ml/vflow" target="_blank" rel="noopener">https://github.com/thu-ml/vflow</a></p></blockquote></li></ol><hr><p>第十场是京东的易津峰老师介绍对抗攻击。基本的idea就是准确率不是唯一的度量模型好坏的标准，在某种程度上准确率上升，稳健性会下降。以图像任务为例就是抗像素扰动能力下降了。笔记没咋记，又一篇京东在ECV18上面的文章，有空的话浏览下吧。</p><blockquote><p>搜到了：<em>Is Robustness the Cost of Accuracy? — A Comprehensive Study on the Robustness of 18 Deep Image Classification Models</em></p><p><a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Dong_Su_Is_Robustness_the_ECCV_2018_paper.html" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_ECCV_2018/html/Dong_Su_Is_Robustness_the_ECCV_2018_paper.html</a></p></blockquote><h2 id="第一天晚上"><a href="#第一天晚上" class="headerlink" title="第一天晚上"></a>第一天晚上</h2><p>第一天晚上结束，和同学讨论了dual-SVM中QP问题转化为minmax问题的细节哈哈哈，都忘了，好在最后推出来了</p><h2 id="第二天上午"><a href="#第二天上午" class="headerlink" title="第二天上午"></a>第二天上午</h2><p>第二天，第十一场，南方科技大学的姚新讲博弈、共生演化问题。总的来说这是老问题了，但是和机器学习的联系不是非常紧密，现在做这个的人很少了。其实我也不太想弄，在这里打个广告科普一下吧qwq。</p><p>姚老师举了很多例子：囚徒困境、协同演化的有效性验证实验、学生AA（忘了具体是什么了）问题、晚自习关灯（电量浪费）问题、农场主共用草场问题，etc。老师表示这背后其实都有数学理论，只是没时间分享了，手动狗头[doge]。理论的概览提了一下，放在下图中：</p><pre class="mermaid">graph LRA(共生演化问题例子<br>老师以NIPD为例给出了许多实验结果) -->B(历史记录<br>一般问题中玩家/用户只能记住前几步的经验,记得越多结果的总体效益越好)A -->C(有个group size<br>我忘了是啥了,反正就是越小越好)A -->D(迭代次数影响最终结果)B --> E(一般共生演化问题)C --> ED --> EE --> F(无训练集,数据都是即时模拟生成的)E --> G(初始化一般是随机的)E --> H(需要环境中用户的交互)</pre><hr><p>第十二场是阿里的华先胜讲城市大规模视觉数据、交通的预测和调度。老师先广告一波，表示Ali旗下做ML的越来越多了，包括machine vision、speech、NLP、DL及其优化问题，etc。然后华老师介绍了城市大脑和交通管理安全的概念，其中需要大规模的感知认知和优化技术。一般来说城市中交通数据中的异常数据都是imbalanced data，且都有突变性，可以看作是异常检测问题，可以直接分类，方法众多，如KNN、SVR、VAR，不过这些方法有利有弊。另外，城市中红绿灯感应方面的协同调度比较复杂，也是一个重要应用。</p><p>最后有个东西我可以参考，应该算是重要的，我截了一张图好像，讲的是记忆卷积，是否在ODE中可以考虑前几步的数据+重加权成为meta方法？</p><img src="/2020/11/10/MLA‘20见闻/MLA-2.PNG" title="记忆卷积截图"><hr><p>第十三场是山世光老师讲自监督学习，主要是视觉感知计算中的标记增强。自监督学习就是一种无监督，没有标记的数据，但是还是能提取出一些标记，可以说是弱标签。</p><blockquote><p>ps：师兄表示山老师是人脸识别领域中国带🐂，绕不过去的那种</p></blockquote><p>无标记的data本身不一定就是完全没有标记的，一般会有一些弱标签；预训练的迁移也一定程度上缓解了标签较弱的问题，但是缺点是过早进行分类会丢失信息（是指预训练提取的特征不够么🤔）；而任务的迁移一般是多任务，需要上下游任务之间联系；另外，对于图像任务，自然语言中的一些常识也有机会迁移过来，比如考虑图像的词法、句法，成为视觉的常识表示。标记如何增强？增广、数据再生（包括打乱、图像擦补等手段）。</p><h2 id="第二天下午"><a href="#第二天下午" class="headerlink" title="第二天下午"></a>第二天下午</h2><p>最后一天下午的听得都不细致了，主要是企业打广告，讲的内容比较少。主要是有一些有趣的应用，比如：</p><ul><li>英特尔的陈玉荣博士讲以人为中心的视觉分析，有个视线预测的例子很有意思</li><li>南大毕业的倍漾科技冯霁博士讲了金融投资的一些idea，网上发表的相关文章几乎没有核心技术，而且往往出错众多😂。提到了金融投资分几类，瞬发的高频决策，中高频的几时内的决策（割散户韭菜❓），以及低频（数月或者季度）的决策（如公司价值的跃迁）。另外，一个idea是量化交易是团队合作！自己一个人搞模型瞎投似乎不切实际</li><li>涂威威介绍第四范式，做各个方面应用产品的公司</li></ul><hr><p>最后的最后是顶会介绍，基本上全听了，不过不方便写在这里。就只说个结论，强化学习意外地成为近期最火热的方向，其次是自监督学习、对抗、表示学习等等。</p><h1 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h1><p>这次南京之行，对领域的各个方向有了进一步了解，以及了解了近期火热的方向（可惜暂时我不是很感兴趣），以及各个方向基础的一些方法，有意思的一些应用。目前磕盐吃还是磕磕自己原来感兴趣的吧。</p><p>其实帮助最大的还是师兄的几番谈话，对未来的打算又有了一些思考，先走一步看一步吧，11月底正式想一想接下来该怎么走。</p><p>另外，读文章还是慢了些，最近我要试图再加快读文章的速度、把握文章的重点并重点记录，流水账式的描述就先放放吧，先达到师兄描述的境界~</p><hr><p>回来想看的文章：</p><ul><li>前面提到的大概2-3篇</li><li>TPAMI文章，好像是有关模型驱动与数据驱动的结合 Kronecker-basis-representation based tensor sparsity and its applications to tensor recovery <a href="https://ieeexplore.ieee.org/document/8000407" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/8000407</a></li><li>去之前留的一些没看完的</li><li>回来之后老师推荐的一篇NIP20文章Ode to an ODE <a href="https://proceedings.neurips.cc/paper/2020/file/228669109aa3ab1b4ec06b7722efb105-Paper.pdf" target="_blank" rel="noopener">https://proceedings.neurips.cc/paper/2020/file/228669109aa3ab1b4ec06b7722efb105-Paper.pdf</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;MLA‘20之行让我学到了很多，包括领域知识，对学习生活的前瞻，以及更多对当下学习困境的思考&lt;/p&gt;
&lt;p&gt;故创文记之，以思故我。就当是小小随笔&lt;/p&gt;
&lt;p&gt;不太好写啊！干脆随便总结下吧，细节留在网盘里就好&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="随笔" scheme="http://maxliu245.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>【文献阅读26】YoloV4</title>
    <link href="http://maxliu245.github.io/2020/11/03/%E3%80%90%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB26%E3%80%91YoloV4/"/>
    <id>http://maxliu245.github.io/2020/11/03/%E3%80%90%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB26%E3%80%91YoloV4/</id>
    <published>2020-11-03T02:25:45.000Z</published>
    <updated>2020-11-03T15:01:54.821Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>头一次正式看目标检测方面的文章，有些功利，直接从YoloV4开始！</p><p><code>YOLOv4: Optimal Speed and Accuracy of Object Detection</code></p></blockquote><a id="more"></a><img src="/2020/11/03/【文献阅读26】YoloV4/YoloV4-1.png" title="YoloV4文献简介"><h1 id="文献简介"><a href="#文献简介" class="headerlink" title="文献简介"></a>文献简介</h1><p>先放文献地址： <a href="https://arxiv.org/abs/2004.10934" target="_blank" rel="noopener">https://arxiv.org/abs/2004.10934</a></p><p>YoloV4于2020/04挂在Arxiv上，作者之一是之前Yolo代码的维护者之一，<a href="https://github.com/AlexeyAB" target="_blank" rel="noopener">Alexey Bochkovskiy</a>，暂时没有找到他的更多资料，另外两个作者是台湾中央研究院的，不认识。</p><h1 id="先修知识"><a href="#先修知识" class="headerlink" title="先修知识"></a>先修知识</h1><p>直接上手这篇目标检测领域的文章稍有困难，因为以前没咋接触过目标检测，现在直接来一手业界极强的文章，很多名词概念都不清楚。</p><p>本来打算补一补，但是发现YoloV4用的模型方法实在是有（多）些（炸）多（了），所以其实只补了文章刚开始的一些概念，码在这里：</p><ul><li><p>Pareto optimality curve，中文名帕累托最优曲线，以本文图 $(1,8)$ 为例，都是2维曲线，这是因为本文选取的评价指标（目标）有两个。我联想到了宏观经济学中的供求曲线、价格需求曲线，感觉道理有一点点像（瞎想的）。</p><blockquote><p>具体可参考知乎用户<a href="https://www.zhihu.com/people/li-lin-song-85" target="_blank" rel="noopener">木木松</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/54691447" target="_blank" rel="noopener">多目标优化之帕累托最优</a></p></blockquote></li><li><p>Anchor-based和Anchor-free方法，都是目标检测中的方法。前者参考下面的链接，讲得很清楚了，依次设计锚点的位置、锚框的个数大小，我猜最后是根据ground truth去判断标记框的优劣；后者似乎是没有具体设置所谓的锚点，只是先识别目标的中心，然后根据中心进行回归得到标记框（未求证）</p><blockquote><p>具体可参考知乎用户<a href="https://www.zhihu.com/people/emiya-98" target="_blank" rel="noopener">emiya</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/86741707" target="_blank" rel="noopener">Anchor-Based-01 目标检测算法设计思想一：anchor是什么</a></p></blockquote></li></ul><h1 id="YoloV4"><a href="#YoloV4" class="headerlink" title="YoloV4"></a>YoloV4</h1><h2 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h2><p>其实刚开始看觉得很舒服，讲的东西都非常合理有道理（后面也是），但是后面讲的名词知识太多了，让我觉得这模型不会就是<strong>各种已有的优秀方法组合拼接</strong>出来的吧！不会吧不会吧，它还<strong>真的就是这样搞的</strong>！</p><p>经过多篇博客总结查证，我基本上确定这文章就是这样做的，不过人家做的确实猛，优点总结如下：</p><ul><li>文章提出的YoloV4达到了文章目标（预期）：保证准确率大前提下，设计出一个<strong>快速实时轻量准确</strong>的目标识别模型。确实，本文表示<strong>只需要1张</strong>优秀的显卡就可以完成快速训练（又向应用前进一步！），并且的确是轻量实时准确的</li><li>在contributions部分提出可以用YoloV4的想法修饰SOTA模型使之有效轻量，应该是这个意思</li><li>集成了<strong>大量已有tricks</strong>，据参考文献表示至少有20多种；这篇文章的工作量十分之大，值得肯定</li><li>文章开头提出了一个说法：CNN任务的一个完整框架需要理论保证+实验验证。本文的tricks可以说是验证了的东西，然后在多个数据集上也显示出帕累托最优的效果</li></ul><h2 id="主要tricks"><a href="#主要tricks" class="headerlink" title="主要tricks"></a>主要tricks</h2><p>说tricks之前忘了提一嘴YoloV4的整体网络框架了，和经典的目标识别检测框架一致，有一个</p><script type="math/tex; mode=display">input \rightarrow backbone \rightarrow neck \rightarrow head(dense\ prediction \rightarrow sparse\ prediction)</script><p>的整体框架，其中某些部分不知道有没有跨连接的操作。下面放一张原文的图 $(2)$ ：</p><img src="/2020/11/03/【文献阅读26】YoloV4/YoloV4-2.png" title="目标检测框架"><p>那么YoloV4其实就说各种tricks，或者说是<strong>各种模型插件</strong>套进这个框架。</p><p>这个我其实没有细看文章了，毕竟陌生名词太多，搞不清哪些是重点，这里根据他人博客自己总结其中有用的tricks：</p><ul><li><p>首先有个idea起源于Yolo系列的任务是目标识别检测。目标检测方法往往是任务special的，特定任务要特定设计，在通用模型没有发展起来并大规模应用之前我是站这个东西的。本文希望能做到通用的general目标检测模型，那么一个idea就是special特征和general特征，YoloV4在网络模块的使用上<strong>主动选择了很多general特征</strong>（我认为是特征图）</p></li><li><p>为了轻量实时，<strong>选择Yolo系列</strong>的模型是当前合适的做法，本文在head区域使用了YoloV3</p></li><li><p><strong>各种数据增强技术</strong>的使用</p></li><li><p><strong>自对抗方法增强图像风格</strong>，我觉得可以算数据增强了</p></li><li><p>大佬们还总结了“跨最小批的归一化（Cross mini-batch Normal）、修改的SAM（逐点attention）、修改的PAN（通道合并方式改变）”，不过我现在不太懂，先码在这里。这里最后三条参考：</p><blockquote><p>知乎用户<a href="https://www.zhihu.com/people/william.hyin" target="_blank" rel="noopener">william</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/161083602" target="_blank" rel="noopener">一文读懂YOLO V5 与 YOLO V4</a></p><p>知乎用户<a href="https://www.zhihu.com/people/jianghongliang" target="_blank" rel="noopener">元峰</a>的回答<a href="https://www.zhihu.com/question/390191723/answer/1177584901" target="_blank" rel="noopener">如何评价新出的YOLO v4 ？</a>不错，从创新性的角度分析了YoloV4使用的主要tricks</p></blockquote></li></ul><h2 id="个人感想（bb）"><a href="#个人感想（bb）" class="headerlink" title="个人感想（bb）"></a>个人感想（bb）</h2><p>本来头一遍翻完这篇文章觉得还挺ysk（😁）的，但是抱着这个怀疑我去读了他人的总结，包括：</p><blockquote><p>知乎用户<a href="https://www.zhihu.com/people/amusi1994" target="_blank" rel="noopener">Amusi</a>的回答<a href="https://www.zhihu.com/question/390191723/answer/1176986665" target="_blank" rel="noopener">如何评价新出的YOLO v4 ？</a>很好，我很赞同。人家工作量在这里，确实很良心</p><p>知乎用户<a href="https://www.zhihu.com/people/david-12-84-45" target="_blank" rel="noopener">David</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/136172670" target="_blank" rel="noopener">YOLO-V4解读：速度与精度的完美结合[已开源]</a>是一篇简洁的翻译，可以速读参考</p><p>补充资料：知乎用户<a href="https://www.zhihu.com/people/magic-frog-sjtu" target="_blank" rel="noopener">996黄金一代</a>的回答<a href="https://www.zhihu.com/question/399884529/answer/1374024055" target="_blank" rel="noopener">如何评价YOLOv5？</a></p></blockquote><p>我这才有些缓过来，人家毕竟是总结了大量方法，有充足的工作量，而且效果也上去了，那的确是不错的。大家反驳之的意见是似乎大家应用还是不用它，用YoloV3，大概是觉得它这样相当于调参？不过人家做了很多实验，在不少数据集上也足够优秀了，那我是没话说了。</p><p>这种套方法的方式，可取，但是得有充足的调研，充足的实验经验。加油吧骚年！</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Alexey Bochkovskiy, Chien-Yao Wang, and Hong-Yuan Mark Liao. Yolov4: Optimal speed and accuracy of object detection, 2020.</p><p>[2] emiya. Anchor-Based-01 目标检测算法设计思想一：anchor是什么[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/86741707" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/86741707</a>, 2019-10-26.</p><p>[3] 木木松. 多目标优化之帕累托最优[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/54691447" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/54691447</a>, 2020-10-07.</p><p>[4] william. 一文读懂YOLO V5 与 YOLO V4[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/161083602" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/161083602</a>, 2020-07-28.<br>[5] 元峰. 如何评价新出的YOLO v4 ？[EB/OL]. <a href="https://www.zhihu.com/question/390191723/answer/1177584901" target="_blank" rel="noopener">https://www.zhihu.com/question/390191723/answer/1177584901</a>, 2020-04-25.<br>[6] Amusi. 如何评价新出的YOLO v4 ？[EB/OL]. <a href="https://www.zhihu.com/question/390191723/answer/1176986665" target="_blank" rel="noopener">https://www.zhihu.com/question/390191723/answer/1176986665</a>, 2020-04-24.<br>[7] David. YOLO-V4解读：速度与精度的完美结合[已开源][EB/OL]. <a href="https://zhuanlan.zhihu.com/p/136172670" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/136172670</a>, 2020-05-20.<br>[8] 996黄金一代. 如何评价YOLOv5？[EB/OL]. <a href="https://www.zhihu.com/question/399884529/answer/1374024055" target="_blank" rel="noopener">https://www.zhihu.com/question/399884529/answer/1374024055</a>, 2020-07-31.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;头一次正式看目标检测方面的文章，有些功利，直接从YoloV4开始！&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YOLOv4: Optimal Speed and Accuracy of Object Detection&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="CNN" scheme="http://maxliu245.github.io/tags/CNN/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
      <category term="Yolo" scheme="http://maxliu245.github.io/tags/Yolo/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读25】HollowNet——NN对微分算子的模拟</title>
    <link href="http://maxliu245.github.io/2020/10/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB25%E3%80%91HollowNet%E2%80%94%E2%80%94NN%E5%AF%B9%E5%BE%AE%E5%88%86%E7%AE%97%E5%AD%90%E7%9A%84%E6%A8%A1%E6%8B%9F/"/>
    <id>http://maxliu245.github.io/2020/10/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB25%E3%80%91HollowNet%E2%80%94%E2%80%94NN%E5%AF%B9%E5%BE%AE%E5%88%86%E7%AE%97%E5%AD%90%E7%9A%84%E6%A8%A1%E6%8B%9F/</id>
    <published>2020-10-24T07:43:45.000Z</published>
    <updated>2020-10-26T09:49:10.466Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>这篇文章标题并没有提到HollowNet，标题为<em>Neural Networks with Cheap Differential Operators</em></p><p>是去年（19）NIPS，由著名的<a href="http://www.cs.toronto.edu/~rtqichen/" target="_blank" rel="noopener">陈天琦</a>写的文章</p></blockquote><a id="more"></a><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/HollowNet-1.png" title="文献预览"><p>文献链接： <a href="https://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators.pdf</a> ，更详细的地址在 <a href="http://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators" target="_blank" rel="noopener">http://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators</a></p><p>这篇文章我其实没有读透，文中的 $(6)$ 式我还没懂，而且我喜欢挑刺，我总觉得文章里很多记号写得不好不统一…不过问题也不大，记个笔记就好啦~</p><h1 id="Why-HollowNet？——背景"><a href="#Why-HollowNet？——背景" class="headerlink" title="Why HollowNet？——背景"></a>Why HollowNet？——背景</h1><p>本文的标题没有提及HollowNet，但是其实说明了文章做了什么，即用NN来模拟微分算子，只不过模拟的微分算子可能比较简单，所以说是cheap的。</p><p>那么文章是怎么考虑到要用NN模拟微分算子的呢？（我塔喵其实就是在想这个问题！）</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/TAMIAO.jpg" title="我的塔喵是巴萨卡🐷~"><p>其实没什么可考虑的，就是想模拟微分算子嘛，但是微分算子比较复杂，本身就是抽象的数学记号，而且还有各种微妙的复杂性，如对时间、或者是对空间等变量的<strong>变化</strong>的描述。</p><p>这篇文章就是基于此想法，提出了HollowNet，它完成的任务是对输入为向量 $\mathbf{x}$ 的向量函数 $\mathbf{f}(\mathbf{x})$ 求对 $\mathbf{x}$ 的单变量 $x_j$ （以第 $j$ 元为例）的高阶偏导数，即 $\displaystyle \dfrac{\partial^k \mathbf{f}(\mathbf{x})}{\partial x_j^k}$ 。文中称之为<font color="#0000FF">dimension-wise k-th order derivatives</font>。</p><h1 id="How-HollowNet？——挖空NN"><a href="#How-HollowNet？——挖空NN" class="headerlink" title="How HollowNet？——挖空NN"></a>How HollowNet？——挖空NN</h1><p>这里要先声明文章完成的<strong>任务</strong>是模拟了<font color="#0000FF">dimension-wise k-th order derivatives</font> $\displaystyle \dfrac{\partial^k \mathbf{f}(\mathbf{x})}{\partial \mathbf{x}_j^k}$ ，其中 $\mathbf{f}:\mathbb{R}^d\rightarrow \mathbb{R}^d$ ，<font color="#0000FF">dimension-wise k-th order derivatives</font>为：</p><script type="math/tex; mode=display">\displaystyle \mathcal{D}_{dim}^k(\mathbb{f}) = \dfrac{\partial^k \mathbf{f}(\mathbf{x})}{\partial \mathbf{x}_j^k} = \left[\dfrac{\partial^k f_1(\mathbf{x})}{\partial \mathbf{x}_1^k}\ \dfrac{\partial^k f_2(\mathbf{x})}{\partial \mathbf{x}_2^k}\ \cdots,\ \dfrac{\partial^k f_d(\mathbf{x})}{\partial \mathbf{x}_d^k} \right]^T\in \mathbb{R}^d</script><p>文章这里就有一些小问题，这些真的是dimension-wise的，如果需要混合偏导，比如 $\dfrac{\partial^k f_i(\mathbf{x})}{\partial x_j^k},\ where\ i\neq j$ ，那这个式子就无能为力了，这大概也是为什么文章标题说是“cheap”的微分算子</p><hr><p>至于具体怎么用网络实现，话不多说，日常上图：</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/HollowNet-2.png" title="HollowNet结构"><p><strong>左图是完整的前向计算过程</strong>，这里为了求 $f_k$ 对 $x_k$ 的偏导数，先由除了 $x_k$ 之外的所有分量 $\mathbf{x}_{-k} \triangleq \{x_1, x_2, \cdots, x_d\}/ \{x_k\}$ ，计算一个 $h_k = c_k(\mathbf{x}_{-k})$ ，其中 $h_k$ 不一定是标量，因为标量的信息一般不够描述高阶导数，一般是向量，这里先假定为 $d_h(\forall k)$ 维，然后这个 $h_k$ 和 $x_k$ 再作为输入得到函数值分量 $f_k=\tau_k(h_k,x_k)$ 。这样设计的目的是为了方便后面挖空网络之后，函数值分量 $f_k$ 只保留对输入分量 $x_k$ 的偏导数。</p><p>那么<strong>右图就是挖空计算图的操作</strong>了。由左图的设计，只要在编程中通过<code>detach</code>一类的操作断掉 $f_k$ 和 $h_k$ 之间的联系，那么在计算图中就只保留了 $\dfrac{\partial f_k}{\partial x_k}$ ，对其它分量的偏导数一律为0。</p><p>在左图中，从输入变量的分量 $\mathbf{x}_{-k}$ 到中间变量 $h_k$ 的过程叫做<code>conditioner</code>，表示这种特殊设计的条件关系；从中间变量 $h_k$ 到最终函数分量 $f_k$ 的过程则叫做<code>transformer</code>，这个不太好解释，反正是这么个说法。</p><p>有了这个挖空计算图的操作还不够，因为显然我们会注意到 $f_k$ 本身还是由所有分量计算得到的，单独切掉 $\mathbf{x}_{-i}$ 对应的计算图，那么如果有对 $f_k$ 的后续计算，比如计算损失函数 $c$ ，那么就有 $\displaystyle \dfrac{\partial c}{x_k} = \sum_j \dfrac{\partial c}{\partial f_j}\dfrac{\partial f_j}{\partial x_k}$ ，而这样的话相当于在计算图中，右边只能保留一项梯度 $\dfrac{\partial c}{\partial f_k}\dfrac{\partial f_k}{\partial x_k}$ ，这和我们的认知不符，我认为文章<strong>基于这个考虑对挖空的计算图做了一个补全</strong>，即文章的 $(6)$ 式，我自己学了点计算图想推一下，但是<strong>应该是推错了</strong>，过程记录如下：</p><script type="math/tex; mode=display">\displaystyle \begin{aligned} \dfrac{\partial \mathcal{D}_{dim}(\mathbb{f})}{\partial w} &= \sum_j\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial h_j} \dfrac{\partial h_j}{\partial w} = \sum_j\left(\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}\dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial h_j}\right) \dfrac{\partial h_j}{\partial w}\\ &= \sum_j\left(\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})} \left(\dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}}_j)}{\partial h_j} \bigoplus \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}}_{-j})}{\partial h_j}\right)\right) \dfrac{\partial h_j}{\partial w}\\ &?= \sum_j\left(\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})} \left(\dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial \hat{h}} \bigoplus \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}}_{-j})}{\partial h_j}\right)\right) \dfrac{\partial h_j}{\partial w}\\ &?= \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial \hat{h}}\dfrac{\partial h}{\partial w} + \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial w}\end{aligned}</script><font color="#FF0000"> 最后两行我是懵了，看了点计算图还是不懂，先放在这里了</font><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><p>讲方法优劣之前，其实看了一点点实验，为文章的 $(5.2)$ 节，大概就是说对于一个随机微分方程，这个HollowNet模拟得不错</p><div class="table-container"><table><thead><tr><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>cheap微分算子的成功模拟❕</td><td>只构建了cheap微分算子，维度-wise的，那么混合偏导等算子呢</td></tr><tr><td>HollowNet构建方式和我想的不一样，这也是我可以借鉴的地方之一</td><td>原文$(2.1)$ 节提到 $d_h$ 要小一些，这样可以大量减少计算量，但是这样维度较小，信息流足够么❓</td></tr><tr><td>HollowNet没有太多对模型的限制，之前很多流模型，包括NICE等都有很多限制（原文 $(2.1)$ 节）</td><td>原文 $(6)$ 式的计算图补偿方式讲得不洗，没看懂哇，是不是和图 $(1)$ 提到的对角分解有关❓</td></tr><tr><td></td><td>原文的例子都看起来很复杂，有实例的一个还是SDE，为何不举像NODE中那样一般的简单例子呢❓</td></tr></tbody></table></div><h1 id="补充知识——学习计算图"><a href="#补充知识——学习计算图" class="headerlink" title="补充知识——学习计算图"></a>补充知识——学习计算图</h1><p>学这个是因为开始看文章的时候 $(6)$ 式不明白，所以先快速补一下</p><p>参考的资源是B大李宏毅深度学习(2017)课程第三讲： <a href="https://www.bilibili.com/video/BV1Ux411S7rk?p=3" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Ux411S7rk?p=3</a></p><h2 id="一般计算图"><a href="#一般计算图" class="headerlink" title="一般计算图"></a>一般计算图</h2><p>计算图的目的是计算梯度，一般的有效方法是BP，不过程序计算大多都是通过计算图。</p><p>计算图可以看成描述函数的语言，包括节点（变量）和边（运算），和PRML第8章讲得差不多。</p><p>举了好几个例子，都看懂了，注意一点就是每个中间变量都可以单独作为一个节点；另一点是链式法则可以根据计算图考虑，把箭头连接看成偏微分再写出链式法则的式子。</p><p>使用计算图的几个原因：</p><ol><li>一般我们会得到一个loss，对这个单输出求参数的偏导数，在计算图上从单输出reverse比较有效率</li><li>NN中往往存在参数共享的时候，同一参数可能反复使用，这时考虑从该变量到输出的所有路径，偏导加起来就好了，非常直接</li></ol><h2 id="前馈网络的计算图"><a href="#前馈网络的计算图" class="headerlink" title="前馈网络的计算图"></a>前馈网络的计算图</h2><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY1.png" title="前馈网络计算图表示（图源B站，侵删）"><p>算好每条边上对应的偏导数，然后reverse计算总的偏导数就好了。不过真正的计算过程挺麻烦的，我直接截一张图了：</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY2.png" title="前馈网络梯度计算过程（图源B站，侵删）"><h2 id="RNN的计算图"><a href="#RNN的计算图" class="headerlink" title="RNN的计算图"></a>RNN的计算图</h2><p>RNN都忘光了，放一张图在这里吧：</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY3.png" title="RNN模型（图源B站，侵删）"><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY4.png" title="RNN计算图（图源B站，侵删）"><p>行了，大概明白具体是怎么算的了</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>[1] Ricky T. Q. Chen and David K Duvenaud. Neural networks with cheap differential operators. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 9961–9971. Curran Associates, Inc., 2019.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇文章标题并没有提到HollowNet，标题为&lt;em&gt;Neural Networks with Cheap Differential Operators&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;是去年（19）NIPS，由著名的&lt;a href=&quot;http://www.cs.toronto.edu/~rtqichen/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈天琦&lt;/a&gt;写的文章&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读24】On Second Order Behaviour in ANODE——真二阶NODE</title>
    <link href="http://maxliu245.github.io/2020/10/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB24%E3%80%91On-Second-Order-Behaviour-in-ANODE%E2%80%94%E2%80%94%E7%9C%9F%E4%BA%8C%E9%98%B6NODE/"/>
    <id>http://maxliu245.github.io/2020/10/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB24%E3%80%91On-Second-Order-Behaviour-in-ANODE%E2%80%94%E2%80%94%E7%9C%9F%E4%BA%8C%E9%98%B6NODE/</id>
    <published>2020-10-19T11:11:29.000Z</published>
    <updated>2020-10-31T14:02:39.949Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p><code>On Second Order Behaviour in Augmented Neural ODEs</code>，简称<strong>SONODE</strong>，似乎是2020ICML的文章但是我没有搜到…</p></blockquote><a id="more"></a><img src="/2020/10/19/【论文阅读24】On-Second-Order-Behaviour-in-ANODE——真二阶NODE/2nd-NODE-1.png" title="文献预览"><p>文献链接：<a href="https://arxiv.org/abs/2006.07220" target="_blank" rel="noopener">https://arxiv.org/abs/2006.07220</a></p><p><code>SONODE</code>是非常新的一篇文章，发布于2020/06，是剑桥的人写的。该文是一个非常理论的东西，基本上是基于ANODE、NODE，附录有好多证明，现在还是啃不动，只能啃一些浅层的东西，记录于此</p><h1 id="Hook——a-simple-comparison"><a href="#Hook——a-simple-comparison" class="headerlink" title="Hook——a simple comparison"></a>Hook——a simple comparison</h1><p>之前写过一篇比较ODE2VAE和ANODE文章的比较，大概意思是说ODE2VAE中对二阶导的建模本质上可以看成ANODE在维度上进行增广的一个特例。而本文<code>SONODE</code>是我读的一篇关于ANODE<strong>对2阶导处理</strong>的文章，可以看成是两个NODE在ANODE的框架下套娃，而且比较理论了，基于原始NODE的理论进行了拓展，不过更多地和ANODE进行比较</p><p>笔记写得差不多了，这里再补上一些比较，原文认为SONODE不错的一个原因是它更多地考虑了实际ODE，模型的动力性质，对物理过程的描述更好一些。不过我觉得也就是多建模了一个二阶导啊，只是结合了增广维度的思想，建模的过程也没有那么物理…</p><h1 id="Why-SONODE？——背景"><a href="#Why-SONODE？——背景" class="headerlink" title="Why SONODE？——背景"></a>Why SONODE？——背景</h1><p>话不多说，直接上背景</p><p>背景之一是基于NODE、ANODE，这类模型非常不错，就是奔着描述连续动力系统去的，未来应用一定大好👍；背景之二是之前这些模型只讨论了一阶的性质，缺乏对ODE二阶导的讨论，这也是我在关注的</p><p>所以本文的idea很朴素，就是<font color="#0000FF">顺着ANODE推广到2阶导</font>的情形，就成为SONODE模型。不过idea朴素，方法却比较复杂，本文顺着NODE推广了它的<code>adjoint sensitivity</code>方法，这个尤其复杂，都在附录里我就不看了嘻嘻。另外，本文在得到SONODE之后做了大量实验，<font color="#0000FF">探究了许多对ANODE和SONODE的理解与比较</font>，这些东西内容满满啊！</p><h1 id="What’s-SONODE——实现方法"><a href="#What’s-SONODE——实现方法" class="headerlink" title="What’s SONODE——实现方法"></a>What’s SONODE——实现方法</h1><p>先回顾一下在NODE上做了维度增广的ANODE：</p><script type="math/tex; mode=display">\displaystyle \dfrac{d}{dt}\begin{bmatrix} \textbf{h}(t) \\ \textbf{a}(t) \end{bmatrix} = f(\begin{bmatrix} \textbf{h}(t) \\ \textbf{a}(t) \end{bmatrix}, t),\ \begin{bmatrix} \textbf{h}(t_0) \\ \textbf{a}(t_0) \end{bmatrix} = \begin{bmatrix} \textbf{h}(0) \\ \textbf{a}(0) \end{bmatrix} \triangleq \begin{bmatrix} \textbf{x} \\ \textbf{0} \end{bmatrix}</script><p>2阶NODE的建模考虑到了要拟合二阶导，SONODE就是这样一个非常暴力直观的想法，直接对二阶导建模（联想之前ODE2VAE利用贝叶斯神经网络来学习之），如下所示：</p><script type="math/tex; mode=display">\mathbf{h}^{\prime\prime} = \mathbf{f}^{(a)}(\mathbf{h}, \mathbf{h}^{\prime}, t, \theta_\mathbf{f}),\ where\ \mathbf{h}(t_0) = \mathbf{H}_0,\ \mathbf{h}^{\prime}(t_0) = \mathbf{g}(\mathbf{h}(t_0), \theta_\mathbf{g}) \tag{1}</script><p>其中上标 $(a)$ 表示这个网络函数 $\mathbf{f}$ 相当于是拟合加速度的函数。原始函数初值 $\mathbf{h}(t_0)$ 和一阶导初值 $\mathbf{h}^{\prime}(t_0)$ 都给定了</p><p>而这个暴力的建模方式相当于把ANODE的增广维度设置成一阶导 $\mathbf{h}^\prime(t)$ ：</p><script type="math/tex; mode=display">\displaystyle \mathbf{z} = \begin{bmatrix} \textbf{h}(t) \\ \textbf{h}^\prime(t) \end{bmatrix},\ \mathbf{z}^\prime = \dfrac{d}{dt}\begin{bmatrix} \textbf{h}(t) \\ \textbf{h}^\prime(t) \end{bmatrix} = \mathbf{f}^{(v)}(\begin{bmatrix} \textbf{h}(t) \\ \textbf{h}^\prime(t) \end{bmatrix}, t, \theta_\mathbf{f}) = \begin{bmatrix} \textbf{h}^\prime(t) \\ \mathbf{f}^{(a)}(\mathbf{h}, \mathbf{h}^{\prime}, t, \theta_\mathbf{f}) \end{bmatrix},\ where\ IV\ is\ \mathbf{z}(t_0) = \begin{bmatrix} \mathbf{H}_0 \\ \mathbf{g}(\mathbf{h}(t_0), \theta_\mathbf{g}) \end{bmatrix}\tag{2}</script><p>如上所示， $(1)$ 式和 $(2)$ 式形式上其实是一样的，即<font color="#0000FF">对二阶导的暴力建模 $\Leftrightarrow$ 两个NODE以ANODE的方式嵌套</font>！</p><h1 id="Theory-of-SONODE——NODE理论延拓"><a href="#Theory-of-SONODE——NODE理论延拓" class="headerlink" title="Theory of SONODE——NODE理论延拓"></a>Theory of SONODE——NODE理论延拓</h1><p>这个主要是NODE中<code>adjoint method</code>的延拓了。由于SONODE可以看作两个NODE在ANODE的框架下套娃，那么作者就考虑了一阶<code>adjoint method</code>延拓成二阶，进而辅助网络的训练</p><p>式子为原文命题 $(3.1)$ 但是我真心不想看证明估计也看不太明白…</p><p>进一步，原文给出了这个<code>adjoint method</code>的计算性质比较，即原文命题 $(3.2)$ ，说的是计算复杂度的问题，只用两组一阶<code>adjoint method</code>计算要优于用二阶的<code>adjoint method</code>，后者应该是需要更多的矩阵乘法运算。因此，文中的实验都是准备用两组一阶<code>adjoint method</code>来计算的</p><h1 id="How-to-Use-SONODE——Experiments"><a href="#How-to-Use-SONODE——Experiments" class="headerlink" title="How to Use SONODE——Experiments"></a>How to Use SONODE——Experiments</h1><p>这篇文章做了很多实验，我稍微整理了一下，前三个主要是为了说明SONODE的基本性质；第4个是为了说明SONODE和ANODE二阶性质的比较；后面的是为了进一步以困难数据说明二者二阶性质的比较：</p><div class="table-container"><table><thead><tr><th>实验名称</th><th>实验简介</th><th>实验结果</th></tr></thead><tbody><tr><td>Generalised Parity Problems</td><td>是原来NODE提到的相图不交问题的高维推广——高维初值问题</td><td>ANODE没能学到最一般的轨迹；SONODE学到了（结果如此但我不太明白）</td></tr><tr><td>Nested N-Spheres</td><td>似乎是两个N维球面嵌套的分离问题，并在流（轨）形（迹）意义下讨论</td><td>NODE不能在<strong>原来</strong>的实空间中分离轨迹；ANODE在增广的维度上分离了轨迹；SONODE在实空间中就做到了轨迹分（相）离（交）（不太明白原理），并提出了命题 $(3.3)$ ，SONODE不被限制在实空间上的同胚变换，毕竟实空间上就成功做到相图相交了</td></tr><tr><td>2 Damped Harmonic Oscillators</td><td>即2个衰减简谐振动轨迹的学习</td><td>只是说明了，ANODE扩充维度不用超过原来实空间维度，也能学到一定的二阶性质</td></tr><tr><td>Interpretability of ANODES</td><td>对一些较不规则螺旋线进行学习</td><td>SONODE和ANODE在该问题上的表现为：ANODE在不同初始化条件下结果不同，其实空间上轨迹一致，但增广维度上轨迹不同（有点迷）；SONODE轨迹始终一致。这说明ANODE的二阶导学习得还是可能有问题，<strong>可能</strong>不适合实际问题的应用。更进一步的结果是，原文提出命题 $(5.2, 5.3)$ ，表示ANODE可学习的非平凡二阶导形式是无限的，SONODE的则是唯一的（这么强的么？👍）</td></tr><tr><td>Noise Robustness</td><td>对 $\sin$ 函数加不同水平高斯噪声</td><td>图7的结果表示SONODE更稳健</td></tr><tr><td>Real-world Dynamic Systems</td><td>实际数据</td><td>不太明白，反正看图猛就完了</td></tr></tbody></table></div><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><p>写到这里总觉得文章哪里不太对劲，先这样吧，说不定用到的时候就明白了。</p><div class="table-container"><table><thead><tr><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>本文的idea很正统，基于ANODE研究2阶性质，不仅给出了adjoint方法的延拓，还与双ANODE联系在一起</td><td>此类方法由于应用非常直接，确实很容易用于不好的用途。。这个问题挺人文的，我还是希望人类能和平发展技术。。</td></tr><tr><td>理论的保证还是比较足了，主要是adjoint方法、以及确实是在对<strong>真正</strong>的二阶导建模</td><td>文中提到了一手ANODE增广的维度可能发生混乱，是指学到的东西没有可解释性么，这个只提了几句没讲清楚</td></tr><tr><td>对比ANODE的实验做得很多，确实让我们看到了建模二阶导带来的优势</td><td>二阶导adjoint方法推导似乎就比较复杂，那高阶推导难道要一直嵌套么？这不是我们想要的</td></tr><tr><td>此一类方法的潜力都很好，应用场景必然很多，且已经出现！本文二阶方法则尤其适合存在加速度的场景</td><td>TBD</td></tr></tbody></table></div><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>[1] Alexander Norcliffe, Cristian Bodnar, Ben Day, Nikola Simidjievski, and Pietro Liò. On second order behaviour in augmented neural odes. arXiv preprint arXiv:2006.07220, 2020.</p><p>[2] Emilien Dupont, Arnaud Doucet, and Yee Whye Teh. Augmented neural odes. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3140–3150. Curran Associates, Inc., 2019.</p><p>[3] Cagatay Yildiz, Markus Heinonen, and Harri Lahdesmaki. Ode2vae: Deep generative second order odes with bayesian neural networks. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 13412–13421. Curran Associates, Inc., 2019.</p><p>[4] Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt and David Duvenaud. Neural Ordinary Differential Equations[EB/OL]. <a href="https://arxiv.org/abs/1806.07366" target="_blank" rel="noopener">https://arxiv.org/abs/1806.07366</a>, 2018.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;On Second Order Behaviour in Augmented Neural ODEs&lt;/code&gt;，简称&lt;strong&gt;SONODE&lt;/strong&gt;，似乎是2020ICML的文章但是我没有搜到…&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
</feed>
