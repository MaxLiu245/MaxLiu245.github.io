<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Max Liu&#39;s Blog</title>
  
  <subtitle>Earlier birds eat more worms</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://maxliu245.github.io/"/>
  <updated>2020-12-14T05:56:39.658Z</updated>
  <id>http://maxliu245.github.io/</id>
  
  <author>
    <name>Max Liu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【论文略读28】继PDE-Net 2.0后引用它的一系列文章</title>
    <link href="http://maxliu245.github.io/2020/12/12/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB28%E3%80%91%E7%BB%A7PDE-Net-2-0%E5%90%8E%E5%BC%95%E7%94%A8%E5%AE%83%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/"/>
    <id>http://maxliu245.github.io/2020/12/12/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB28%E3%80%91%E7%BB%A7PDE-Net-2-0%E5%90%8E%E5%BC%95%E7%94%A8%E5%AE%83%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0/</id>
    <published>2020-12-12T07:08:07.000Z</published>
    <updated>2020-12-14T05:56:39.658Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>许久未记录正式的博客笔记了，在此补上一系列文章</p><p>它们是我读完PDE-Net 2.0后顺着这条线索收集的</p></blockquote><a id="more"></a><h2 id="搜集文献（不分顺序）"><a href="#搜集文献（不分顺序）" class="headerlink" title="搜集文献（不分顺序）"></a>搜集文献（不分顺序）</h2><ol><li>Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning<ul><li>董彬老师组</li><li><a href="https://arxiv.org/abs/1905.11079?context=math" target="_blank" rel="noopener">https://arxiv.org/abs/1905.11079?context=math</a></li></ul></li><li>Data-driven recovery of hidden physics in reduced order modeling of fluid flows<ul><li><a href="https://aip.scitation.org/doi/abs/10.1063/5.0002051" target="_blank" rel="noopener">https://aip.scitation.org/doi/abs/10.1063/5.0002051</a></li><li>期刊名Physics of Fluids，20年初</li></ul></li><li>DeepMoD: Deep learning for model discovery in noisy data<ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0021999120307592" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0021999120307592</a></li><li>期刊名Journal of Computational Physics，20年11月</li></ul></li><li>Stability selection enables robust learning of partial differential equations from limited noisy data<ul><li><a href="https://arxiv.org/abs/1907.07810" target="_blank" rel="noopener">https://arxiv.org/abs/1907.07810</a></li><li>ArXiv上的分类是Mathematics—&gt;Numerical Analysis，19年7月</li></ul></li><li>Derivatives Pricing via Machine Learning<ul><li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3352688" target="_blank" rel="noopener">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3352688</a></li><li><a href="https://www.scirp.org/journal/paperinformation.aspx?paperid=94637" target="_blank" rel="noopener">https://www.scirp.org/journal/paperinformation.aspx?paperid=94637</a></li><li>期刊名Business &amp; Economics，19年</li></ul></li><li>Extracting Interpretable Physical Parameters from Spatiotemporal Systems Using Unsupervised Learning<ul><li><a href="https://journals.aps.org/prx/abstract/10.1103/PhysRevX.10.031056" target="_blank" rel="noopener">https://journals.aps.org/prx/abstract/10.1103/PhysRevX.10.031056</a></li><li>期刊名PHYSICAL REVIEW X，20年9月</li></ul></li><li>DLGA-PDE: Discovery of PDEs with incomplete candidate library via combination of deep learning and genetic algorithm<ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0021999120303582" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0021999120303582</a></li><li>期刊名Journal of Computational Physics，20年10月</li></ul></li><li>Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data<ul><li><a href="https://aip.scitation.org/doi/abs/10.1063/1.5136351" target="_blank" rel="noopener">https://aip.scitation.org/doi/abs/10.1063/1.5136351</a></li><li>期刊名Physics of Fluids，20年1月</li></ul></li><li>Data-driven Discovery of Partial Differential Equations for Multiple-Physics Electromagnetic Problem<ul><li><a href="https://arxiv.org/abs/1910.13531" target="_blank" rel="noopener">https://arxiv.org/abs/1910.13531</a></li><li>ArXiv上分类Physics—&gt;Computational Physics，19年10月</li></ul></li><li>TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes<ul><li><a href="https://arxiv.org/abs/2003.02426" target="_blank" rel="noopener">https://arxiv.org/abs/2003.02426</a></li><li>20年5月</li></ul></li><li>Sparse Symplectically Integrated Neural Networks<ul><li><a href="https://proceedings.neurips.cc/paper/2020/hash/439fca360bc99c315c5882c4432ae7a4-Abstract.html" target="_blank" rel="noopener">https://proceedings.neurips.cc/paper/2020/hash/439fca360bc99c315c5882c4432ae7a4-Abstract.html</a></li><li>NIPS’20</li></ul></li><li>DeepM&amp;Mnet: Inferring the electroconvection multiphysics fields based on operator approximation by neural networks<ul><li><a href="https://arxiv.org/abs/2009.12935" target="_blank" rel="noopener">https://arxiv.org/abs/2009.12935</a></li><li>ArXiv上分类Physics—&gt;Computational Physics，20年9月</li></ul></li><li>Integration of Neural Network-Based Symbolic Regression in Deep Learning for Scientific Discovery<ul><li><a href="https://ieeexplore.ieee.org/abstract/document/9180100" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/9180100</a></li><li>IEEE Transactions on Neural Networks and Learning Systems，20年8月</li></ul></li></ol><h2 id="1-Learning-to-Discretize-Solving-1D-Scalar-Conservation-Laws-via-Deep-Reinforcement-Learning"><a href="#1-Learning-to-Discretize-Solving-1D-Scalar-Conservation-Laws-via-Deep-Reinforcement-Learning" class="headerlink" title="1. Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning"></a>1. Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning</h2><h3 id="文献资料"><a href="#文献资料" class="headerlink" title="文献资料"></a>文献资料</h3><ol><li><p>董彬老师组的文章，2020/10挂出来</p></li><li><p><a href="https://arxiv.org/abs/1905.11079?context=math" target="_blank" rel="noopener">https://arxiv.org/abs/1905.11079?context=math</a></p></li></ol><h3 id="表格总结"><a href="#表格总结" class="headerlink" title="表格总结"></a>表格总结</h3><p>总结完了觉得文章的<strong>思路正常</strong>，文章的一个<strong>亮点</strong>是抽象数值方法为RL问题时<strong>引入了meta-learner</strong>的概念？</p><table id="tfhover" class="tftable" border="1" style="table-layout:fixed;">    <col style="width: 15%">    <col style="width: 85%"><tr><th>文献条目</th><th>具体内容</th></tr><tr><td>Target</td><td><body>  <ul type="disc">    <li>先声明大领域，依然是拟合PDE数据，包括数值方法、DL方法</li>    <li>本文针对求解特定的PDE，守恒律方程（associated with conservation laws）</li>  </ul></body></td></tr><tr><td>Motivation/Idea</td><td><body>  <ul type="disc">    <li>守恒律很重要，应用多。且Burgers方程就是其一个特例</li>    <li>从数值方法出发，把PDE-solver看成MDP（Markov Decision Process），进而抽象为强化学习基本问题</li>    <li>上述数值方法是WENO（Weighted Essentially Non-Oscillatory Schemes），稍后在细节介绍，基于它有两个ideas：<ul><li>自动化得到方法中的weights</li><li>自动（原WENO需要进行数值判断）判断方法中的upwind direction，此概念在细节中介绍</li></ul></li>  </ul></body></td></tr><tr><td>Method</td><td><body>  <ul type="disc">    整个模型没有命名，其实提供了一种把数值方法转化为网络、DL问题的思路    <li>基本模型就是求解PDE的WENO数值方法抽象为MDP形式</li>    <li>MDP问题再引入RL，具体细节将在下面介绍</li>  </ul></body></td></tr><tr><td>Pros and Cons</td><td><body>  <ul type="disc">    Pros:      <li>把求解1维情况下守恒律方程的数值方法转化为RL问题，其建模过程很标准，可以说是一个framework</li>      <li>数值方法直接转化为MDP，RL，model-driven么</li>      <li><b>文章重点提到action的构建是个meta-learner,一个说法是，这样的模型泛化不错，一个功劳就归meta-learner</b></li>    <br>Cons:      <li>别问我为什么meta-learner，怎么就meta-learner了，原因我放在后面单独提一下</li>      <li>只考虑了1维情形下守恒律，不能直接推广的话。。。</li>      <li>流（flux）的建模依托于WENO，插值太多，虽然插值很精细但总觉得不优美，说不清楚</li>  </ul><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body></td></tr></table><h3 id="部分细节"><a href="#部分细节" class="headerlink" title="部分细节"></a>部分细节</h3><h4 id="模型基本设置"><a href="#模型基本设置" class="headerlink" title="模型基本设置"></a>模型基本设置</h4><p>先讲讲所谓有守恒律的方程指什么吧，其实就是指这个方程有守恒律，形式如下：</p><script type="math/tex; mode=display">\displaystyle u_x(x,t)+(f(u(x,t)))_x = 0,\ where\ a\leq x\leq b,\ t\in [0,T],\ u(x,0)=u_0(x) \tag{1}</script><p>这个形式就叫守恒律。由参数 ${x,t}$ 取值在区间上可知，ob数据的形式是把时空间分别分割，得到网格式数据，分割一般均匀，设分割长度和总数分别为 $\Delta x, \Delta t$ 和 $J, N$，详见原文公式 $(2.2)$。</p><p>然后有几个概念要说一下，真实解 $u(x,t)$ 在网格上的取值为 $u(x_j,t_n)$，它的近似记为 $\mathcal{U}_j^n$；另外，$(1)$ 式中间的 $f$ 称为flux，可以理解为守恒律中的流，真实的flux记为 $f_j^n=f(u(x_j,t_n))$。</p><p>最后有个空间中的插值，记号为 $\displaystyle x_{j\pm\frac{1}{2}}=x_j\pm\frac{\Delta x}{2}$，感觉就是更细一点的插值。</p><h4 id="WENO数值方法"><a href="#WENO数值方法" class="headerlink" title="WENO数值方法"></a>WENO数值方法</h4><p>从名字上看这个方法，Weighted Essentially Non-Oscillatory Schemes，推测就是<strong>插值更细</strong>因此可能拟合结果波动更小，插值的时候还有重要性（插值准确性）加权。</p><p>下面给个WENO方法的计算过程：</p><div class="row">    <embed src="20201212-1D-1.pdf" width="100%" height="550" type="application/pdf"></div><p>如上最后两行，WENO就像一个<strong>多重平均插值</strong>近似，<strong>主要问题</strong>在于不同插值权重的计算、和最后一个upwind direction计算。后者应该是希望数值解不要震荡的方法，参考<a href="https://baike.baidu.com/item/%E4%BA%8C%E9%98%B6%E8%BF%8E%E9%A3%8E%E6%A0%BC%E5%BC%8F/3533165" target="_blank" rel="noopener">二阶迎风格式</a>。</p><h4 id="WENO对应到MDP"><a href="#WENO对应到MDP" class="headerlink" title="WENO对应到MDP"></a>WENO对应到MDP</h4><p>没啥好说的，根据WENO的计算方法写成算法，然后对应到MDP中的state $S$，action $A$，transition dynamics $P$，reward $r$。</p><img src="/2020/12/12/【论文略读28】继PDE-Net-2-0后引用它的一系列文章/1D-1.png" title="WENO算法"><img src="/2020/12/12/【论文略读28】继PDE-Net-2-0后引用它的一系列文章/1D-2.png" title="RL对应"><p>这样就完事了，再简要介绍一下里面的东西是什么：</p><ul><li>$s$ 是state，有个state function，把指标集对应的$\mathcal{U}_j^\lambda,\ \lambda\in \Lambda$ 映射到 $\hat{f}_j^n$。一个例子是对pdf的三次插值，那 $s$ 就映到3个向量，每个向量是每次插值的所有点（$f_j^\lambda$）和该次插值对应的权重，具体实现是方式是用6层，每层64神经元的MLP，并use the Twin Delayed Deep Deterministic (TD3) policy gradient algorithm to train the RL policy。。。</li><li>$A$ 是action，就是pdf最后一行提到的选择哪些插值，由 $s$ 函数生成</li><li>$P$ 相当于迭代机制，比如前向欧拉对应的迭代形式。。。</li><li>$r$ 用的插值时的无穷范数的相反数</li></ul><h4 id="哪来的meta-learner"><a href="#哪来的meta-learner" class="headerlink" title="哪来的meta-learner"></a>哪来的meta-learner</h4><p>思想不错，$A$ 成为一个meta-learner，原因只有这个靠谱：这个RL里的 $A$ 是通过 $s$ 函数输出得到的，是从当前状态判断的，不是像原来的数值方法那样，在没有其它网络（如上文MLP）的帮助下直接从数值机制推断的。</p><p>文章提的其它原因不太靠谱：</p><ul><li>Learning the policy $P$ within the RL framework makes the algorithm meta-learning like [1, 5, 10, 20, 29].</li><li>The learned policy network is carefully designed to determine a good local discrete approximation based on the current state of the solution, which essentially makes the proposed method a meta-learning approach.</li><li>We attribute the good generalization ability of RL-WENO to our careful action design, which essentially makes RL-WENO a meta-learner under the WENO framework and thus have  strong out-of-distribution generalization.</li></ul><h2 id="2-DeepMoD-Deep-learning-for-model-discovery-in-noisy-data"><a href="#2-DeepMoD-Deep-learning-for-model-discovery-in-noisy-data" class="headerlink" title="2. DeepMoD: Deep learning for model discovery in noisy data"></a>2. DeepMoD: Deep learning for model discovery in noisy data</h2><p><strong><font color="#FF0000">突然想到一个问题，目前没看到几篇文章很关注PDE的边界条件！</font></strong>本文也没有考虑。</p><h3 id="文献资料-1"><a href="#文献资料-1" class="headerlink" title="文献资料"></a>文献资料</h3><ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0021999120307592" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0021999120307592</a></li><li>好像是巴黎大学的研究者写的</li><li>期刊名Journal of Computational Physics，20年11月</li></ul><h3 id="小结：我觉得不彳亍"><a href="#小结：我觉得不彳亍" class="headerlink" title="小结：我觉得不彳亍"></a>小结：我觉得不彳亍</h3><h4 id="模型：DeepMoD及具体内容"><a href="#模型：DeepMoD及具体内容" class="headerlink" title="模型：DeepMoD及具体内容"></a>模型：DeepMoD及具体内容</h4><p>本文提出模型，DeepMoD，指的是deep learning based model discovery algorithm，目标是从数据中学习背后的PDE。该PDE模型的形式其实比较局限，固定为：</p><script type="math/tex; mode=display">\displaystyle \partial_t u = \partial_t u(x,t)=\mathcal{F}(u,u_x,uu_x,u_xx\cdots)\approx \Theta\xi \tag{1}</script><p>两个大困惑，读了好几遍搞不明白，文章为什么要刻意避开这个问题❔我觉得只考虑了这样的形式是因为把神经网络 $f_i$ 作为函数字典，输入是 $(\mathbf{x, t})$，那么输出对输出自动求导看成偏导数。但是<strong>为什么原文公式 $(1)$ 没有 $u$ 对 $t$ 求导呢，是不是在刻意混淆</strong>？而且文章的实验表示不是整个grid上都有数据，可以随机取，那么偏导数也是不能全的啊，怎么保证神经网络就能对输入求导得到字典中的基函数，见下面图中的Library？</p><img src="/2020/12/12/【论文略读28】继PDE-Net-2-0后引用它的一系列文章/DeepMoD-1.png" title="DeepMoD"><p>具体方法采用了函数字典，使用稀疏回归，回归时加正则。使用densely-connected feed-forward neural network作为函数的估计，来构建函数字典。考虑了三种loss，MSE损失针对 $u(x,t)$，只考虑每条轨线末端值的监督；回归损失针对 $\Theta\xi$ 的拟合，但是原文的式子下标没写清楚，弄不明白哪里做了监督；最后是字典系数 $\xi$ 的 $L_1$ 正则</p><p>网络训练有2个骚操作：</p><ul><li>数据有一些处理，当神经网络训练完之后，得到的函数字典的稀疏系数其实会不那么稀疏（$L_1$ 不能保证完全稀疏），进一步进行无量纲化，方式是所有变量标准化，包括原文 $(2)$ 式中的 $\partial_t u,\Theta,\xi$，具体意义见原文 $(3,4)$ 式。</li><li>网络训练完之后，再练一次，不加 $L_1$ 正则了，回归项只用之前筛选出来的，原文只说这样得系数的无偏估计❔</li></ul><p>这个方法起效果需要函数字典充足，不过实验结果似乎表示很充足也不至于过拟合，有对函数系数的正则，这个正则和系数某个阈值的设置有关。这个设置似乎不是general的（见Discussion部分）。字典中函数的系数代表了某种模型选择。</p><h4 id="Pros-and-Cons"><a href="#Pros-and-Cons" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h4><p>前两个文章自己说的优点很奇怪：</p><ul><li><p>一个是<strong>对噪声非常稳健</strong>，是实验结论</p></li><li><p>第二个是<strong>不需要训练集</strong>。这应该指的是<strong>不需要太多训练数据，小样本</strong>也可以，并不是完全不需要，原文进行了5种方程的人工实验，一个结论是几种方程的模拟只需要 $\mathcal{O}(10^2)$ 的数据量。</p><blockquote><p>优点原文：This construction makes it <strong>extremely robust to noise</strong>, <strong>applicable to small data sets</strong>, and, contrary to other deep learning methods, <strong>does not require a training set</strong>.</p><p>实验结果之一：</p><p>find that it requires as few as $\mathcal{O}(10^2)$ samples and works at noise levels up to 75%</p></blockquote></li><li><p>第三个是DeepMoD对数据的维度没有要求，之前有些模型是针对1维数据的</p></li><li>第四个，函数字典有模型选择的功能，只是少了点味</li></ul><p>文章表示DeepMoD很稳健，需要数据量少是因为利用regression-based approach完成model discovery任务，用神经网络infer system parameters。。。说🔨呢，真的是原文。。。我很不喜欢这样的说法</p><p>缺点来了，读不明白就甩锅：</p><ul><li>PDE模型的形式到底局限么？原文是不是在故意回避这个问题</li><li>怎么保证神经网络就能对输入求导得到字典中的基函数？偏导数不一定能全？</li><li>两次训练为什么是无偏估计，没说</li><li>阈值的设置好像是special的</li><li>只靠loss得到所谓的稳健、小样本。难道又是实验验证？我不信，而且全是模拟数据</li><li>本文提了一下边界条件，但是仍然没考虑</li></ul><h2 id="10-TIME-A-Transparent-Interpretable-Model-Adaptive-and-Explainable-Neural-Network-for-Dynamic-Physical-Processes"><a href="#10-TIME-A-Transparent-Interpretable-Model-Adaptive-and-Explainable-Neural-Network-for-Dynamic-Physical-Processes" class="headerlink" title="10. TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes"></a>10. TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes</h2><ul><li><a href="https://arxiv.org/abs/2003.02426" target="_blank" rel="noopener">https://arxiv.org/abs/2003.02426</a></li><li>20年5月</li></ul><div class="row">    <embed src="TIME.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>APA 7th格式</p><p>[1] Wang, Y., Shen, Z., Long, Z., &amp; Dong, B. (2019). Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning. arXiv e-prints, arXiv:1905.11079. <a href="https://ui.adsabs.harvard.edu/abs/2019arXiv190511079W" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2019arXiv190511079W</a> </p><p>[2] Pawar, S., Ahmed, S. E., San, O., &amp; Rasheed, A. (2020). Data-driven recovery of hidden physics in reduced order modeling of fluid flows. Physics of Fluids, 32(3), 036602. <a href="https://doi.org/10.1063/5.0002051" target="_blank" rel="noopener">https://doi.org/10.1063/5.0002051</a> </p><p>[3] Both, G.-J., Choudhury, S., Sens, P., &amp; Kusters, R. (2020). DeepMoD: Deep learning for model discovery in noisy data. Journal of Computational Physics, 109985. <a href="https://doi.org/https://doi.org/10.1016/j.jcp.2020.109985" target="_blank" rel="noopener">https://doi.org/https://doi.org/10.1016/j.jcp.2020.109985</a> </p><p>[4] Maddu, S., Cheeseman, B. L., Sbalzarini, I. F., &amp; Müller, C. L. (2019). Stability selection enables robust learning of partial differential equations from limited noisy data. arXiv e-prints, arXiv:1907.07810. <a href="https://ui.adsabs.harvard.edu/abs/2019arXiv190707810M" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2019arXiv190707810M</a> </p><p>[5] Ye, T., &amp; Zhang, L. (2019). Derivatives Pricing via Machine Learning. Journal of Mathematical Finance, 09, 561-589. <a href="https://doi.org/10.4236/jmf.2019.93029" target="_blank" rel="noopener">https://doi.org/10.4236/jmf.2019.93029</a> </p><p>[6] Lu, P. Y., Kim, S., &amp; Soljačić, M. (2020). Extracting Interpretable Physical Parameters from Spatiotemporal Systems Using Unsupervised Learning. Physical Review X, 10(3), 031056. <a href="https://doi.org/10.1103/PhysRevX.10.031056" target="_blank" rel="noopener">https://doi.org/10.1103/PhysRevX.10.031056</a> </p><p>[7] Xu, H., Chang, H., &amp; Zhang, D. (2020). DLGA-PDE: Discovery of PDEs with incomplete candidate library via combination of deep learning and genetic algorithm. Journal of Computational Physics, 418, 109584. <a href="https://doi.org/https://doi.org/10.1016/j.jcp.2020.109584" target="_blank" rel="noopener">https://doi.org/https://doi.org/10.1016/j.jcp.2020.109584</a> </p><p>[8] Vaddireddy, H., Rasheed, A., Staples, A. E., &amp; San, O. (2020). Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data. Physics of Fluids, 32(1), 015113. <a href="https://doi.org/10.1063/1.5136351" target="_blank" rel="noopener">https://doi.org/10.1063/1.5136351</a> </p><p>[9] Xiong, B., Fu, H., Xu, F., &amp; Jin, Y. (2019). Data-driven Discovery of Partial Differential Equations for Multiple-Physics Electromagnetic Problem. arXiv e-prints, arXiv:1910.13531. <a href="https://ui.adsabs.harvard.edu/abs/2019arXiv191013531X" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2019arXiv191013531X</a> </p><p>[10] Singh, G., Gupta, S., Lease, M., &amp; Dawson, C. N. (2020). TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes. arXiv e-prints, arXiv:2003.02426. <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200302426S" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200302426S</a> </p><p>[11] DiPietro, D. M., Xiong, S., &amp; Zhu, B. (2020). Sparse Symplectically Integrated Neural Networks. arXiv e-prints, arXiv:2006.12972. <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200612972D" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200612972D</a> </p><p>[12] Cai, S., Wang, Z., Lu, L., Zaki, T. A., &amp; Karniadakis, G. E. (2020). DeepM&amp;Mnet: Inferring the electroconvection multiphysics fields based on operator approximation by neural networks. arXiv e-prints, arXiv:2009.12935. <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200912935C" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200912935C</a> </p><p>[13] Kim, S., Lu, P. Y., Mukherjee, S., Gilbert, M., Jing, L., Čeperić, V., &amp; Soljačić, M. (2020). Integration of Neural Network-Based Symbolic Regression in Deep Learning for Scientific Discovery. IEEE Transactions on Neural Networks and Learning Systems, 1-12. <a href="https://doi.org/10.1109/TNNLS.2020.3017010" target="_blank" rel="noopener">https://doi.org/10.1109/TNNLS.2020.3017010</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;许久未记录正式的博客笔记了，在此补上一系列文章&lt;/p&gt;
&lt;p&gt;它们是我读完PDE-Net 2.0后顺着这条线索收集的&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读27】RODE-Net——不确定性引入与GAN的精妙引入</title>
    <link href="http://maxliu245.github.io/2020/11/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB27%E3%80%91RODE-Net%E2%80%94%E2%80%94%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%BC%95%E5%85%A5%E4%B8%8EGAN%E7%9A%84%E7%B2%BE%E5%A6%99%E5%BC%95%E5%85%A5/"/>
    <id>http://maxliu245.github.io/2020/11/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB27%E3%80%91RODE-Net%E2%80%94%E2%80%94%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%BC%95%E5%85%A5%E4%B8%8EGAN%E7%9A%84%E7%B2%BE%E5%A6%99%E5%BC%95%E5%85%A5/</id>
    <published>2020-11-21T12:52:01.000Z</published>
    <updated>2020-11-21T13:47:58.554Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>许久的颓废之后重新开始看文章，这次给大家带来一首隐式meta和GAN结合的思想之歌！</p><p><code>RODE-Net: Learning Ordinary Differential Equations with Randomness from Data</code></p></blockquote><a id="more"></a><h1 id="Overview-amp-Target"><a href="#Overview-amp-Target" class="headerlink" title="Overview &amp; Target"></a>Overview &amp; Target</h1><img src="/2020/11/21/【论文阅读27】RODE-Net——不确定性引入与GAN的精妙引入/RODE-Net-1.png" title="文献概览"><p>这是董彬老师组于2020/06挂在Arxiv上的文章，文章链接：<a href="https://arxiv.org/abs/2006.02377" target="_blank" rel="noopener">https://arxiv.org/abs/2006.02377</a></p><p>文献主要<strong>研究对象</strong>叫RODE，全称<code>Random ordinary differential equations</code>，指的是ODE系统中的参数看成随机变量。研究的基本问题还是从ODE的轨线（轨迹）数据学习背后的方程究竟是什么</p><p>不过读完了文章不是很推荐，因为走的还是拟合（如果ODE-Net基本模型有解释性那么不错）的路子。只是觉得有些思路可以借鉴</p><h1 id="Background-amp-Motivation"><a href="#Background-amp-Motivation" class="headerlink" title="Background &amp; Motivation"></a>Background &amp; Motivation</h1><p>文献<strong>背景</strong></p><ul><li>RODE这类方程引入了一定的随机性</li><li>实际数据可能有不同量纲的特征，这对拟合影响很大</li></ul><p>过去方法缺点：</p><ol><li>如果采用暴力拟合，总归是不好的</li><li>从实际数据获取背后的ODE系统往往需要强先验（ODE形式的归纳偏置）</li><li>即使加了强先验，大家过去也假设参数固定，因此只是平均意义下近似真实ODE系统；真实情况下还有随机性</li></ol><p>进一步地，文章的<strong>动机</strong>就出来了，其实就是一般的从轨线找背后ODE规律的问题，只是相当于直接把原来的ODE中参数添加先验，期以引入不确定性更符合实际，然后为了拟合加了GAN的对抗机制，请见下文</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Data-generation"><a href="#Data-generation" class="headerlink" title="Data generation"></a>Data generation</h2><p>刚开始看不懂数据是怎么采样出来的，后来明白了，数据生成的过程以文中 $(4.1)$ 节为例。先有模型参数的归纳偏置即先验假设，然后生成 $M$ 组参数，这样就有 $M$ 个ODE，选择初始点 $N_i$ 个，分别用4阶龙格-库塔法生成轨线，这样每个确定的ODE采样了 $N_i$ 条轨线，共 $M$ 个确定的ODE。所以最后得到的数据就是</p><script type="math/tex; mode=display">X=\{x_{\eta_i}^j(t_k)|1\leq i\leq M,\ 1\leq j\leq N_i,\ 0\leq k\leq S\} \tag{1}</script><p>其中 $(1)$ 中 $x$ 是其实是轨线向量，下标 $\eta_i$ 就是每次采样的参数，上标 $j$ 表示初值的编号，后面的 $t_k$ 就是龙格-库塔得到的不同采样时刻</p><blockquote><p>原文表述：</p><p>we generate data $x<em>{\eta_i}^j(t_k)$ by solving $ODE-\eta_i$ using the fourth order Runge-Kutta method with $N_i$ different initial values$x</em>{\eta_i}^j(t_0),j=1,\cdots,k$</p></blockquote><h2 id="RODE-Net"><a href="#RODE-Net" class="headerlink" title="RODE-Net"></a>RODE-Net</h2><p>文章提出的引入不确定性的模型，以及对应的网络模型称为RODE-Net。前者即：</p><script type="math/tex; mode=display">\displaystyle \dfrac{dx}{dt} = F_{\eta}(x), x=(x_1,\cdots,x_d)\in \mathbb{R}^d,t\geq 0\tag{2}</script><p>其中 $\eta$ 就是假定有先验分布的参数。后者RODE-Net的结构图如下：</p><img src="/2020/11/21/【论文阅读27】RODE-Net——不确定性引入与GAN的精妙引入/RODE-Net-2.png" title="RODE-Net"><blockquote><p>ps：上面的先验假设应该是可以嵌套的</p></blockquote><p>这个结构里有如下亮点：</p><ul><li>中间的ODE-Net其实就可以是以往的暴力拟合框架，这里文章用了所谓的SymNet中包含了符号运算，内蕴了dynamic操作，因此某种程度上有可解释性。这个SymNet我不知道具体是怎么进行符号运算的，但是我推测是他们组PDE-Net2.0中卷积相关的操作，这个可以；但是后文提到引入GAN的目的之一是避免符号预算的求导，我就<strong>不懂</strong>了，既然符号运算不便求导，那主网络是怎么BP的？</li><li>基础模型ODE-Net之外引入GAN，目的之一是避免SymNet中符号运算求导，目的之二是提供原网络参数更好的监督，进而形成目的三是作为了原网络的正则。联想到之前的ODE2VAE应该是有类似的考虑！</li><li><strong>引入GAN的同时有meta-learning的味道，体现在GAN的double使用，生成之后反过来指导主网络的训练</strong>，类比一下是不是所有模型与GAN嵌套都有这个作用，生成的数据质量越来越高，乃至接近于meta数据，大概也是为什么GAN效果好的解释之一？</li></ul><p>RODE-Net中具体用的ODE-Net主模型就是PDE-Net中变过来的带有符号运算性质的网络；GAN用了WGAN（Wasserstein GAN），细节应该问题不大</p><p>最后讲一下整个RODE-Net是怎么训练的以及其目标函数，从这里感觉，其训练方式是有meta-learning的味道的，这个GAN的double使用，但是<strong>loss上看还是所谓的外练筋骨皮</strong></p><p>训练的过程很像meta方法。先是主网络正常训练，有数据点拟合的监督和对应于异常点不容忍的Huber正则；第二步是第一步得到的模型参数生成，扔到WGAN里训练一下，期中也加了一个梯度惩罚正则，即WGAN-GP；第三步是WGAN返回来作为主模型的正则，希望对抗前后主模型的参数不要相差过大，这样提供了一种整体上的控制</p><blockquote><p>Huber损失介绍，介于 $L_1$ 和 $L_2$ 之间，思想是调整对异常的容忍程度，因此有额外的一个超参数，很棒，可以日后借鉴：</p><p>知乎用户<a href="https://www.zhihu.com/org/jing-lue-ji-zhi" target="_blank" rel="noopener">景略集智</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/39239829" target="_blank" rel="noopener">机器学习从业者必知的5种回归损失函数</a>，细节满满</p><p>博客园用户<a href="https://www.cnblogs.com/nowgood/" target="_blank" rel="noopener">nowgood</a>的博客<a href="https://www.cnblogs.com/nowgood/p/Huber-Loss.html" target="_blank" rel="noopener">Huber Loss</a>，主要是函数的介绍</p></blockquote><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><div class="table-container"><table><thead><tr><th>Pros</th><th></th></tr></thead><tbody><tr><td>RODE建模的不确定性是指参数本身的不确定性，实际意义挺好</td><td>文章有一处不懂的：既然符号运算不便求导而引入GAN，那主网络是怎么BP的</td></tr><tr><td>GAN交替使用，相当于用两个GAN，有meta的味道</td><td>这里的多次正则也只是相对于ob数据的，没有真正意义上的泛化</td></tr><tr><td>GAN作为数据驱动正则的思想（目前比 $L_1$ 效果上好）</td><td>文章最后提了一句先验引入可以使高维参数降维，我寻思着不是一般升维了…</td></tr><tr><td>GAN和RODE的”R”天然契合，因为GAN本身就是参数分布的一种估计</td><td>文章最后说non-transparency，确实某种程度上没有建模深层次的dynamic性质（符号运算？）</td></tr></tbody></table></div><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>这次会用EndNote了，试试APA 7th格式，其它参考链接见文中注释部分</p><p>[1] Liu, J., Long, Z., Wang, R., Sun, J., &amp; Dong, B. (2020). RODE-Net: Learning Ordinary Differential Equations with Randomness from Data. arXiv:2006.02377. Retrieved June 01, 2020, from <a href="https://ui.adsabs.harvard.edu/abs/2020arXiv200602377L" target="_blank" rel="noopener">https://ui.adsabs.harvard.edu/abs/2020arXiv200602377L</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;许久的颓废之后重新开始看文章，这次给大家带来一首隐式meta和GAN结合的思想之歌！&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RODE-Net: Learning Ordinary Differential Equations with Randomness from Data&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Regularization" scheme="http://maxliu245.github.io/tags/Regularization/"/>
    
  </entry>
  
  <entry>
    <title>MLA‘20见闻</title>
    <link href="http://maxliu245.github.io/2020/11/10/MLA%E2%80%9820%E8%A7%81%E9%97%BB/"/>
    <id>http://maxliu245.github.io/2020/11/10/MLA%E2%80%9820%E8%A7%81%E9%97%BB/</id>
    <published>2020-11-09T16:24:40.000Z</published>
    <updated>2020-11-10T06:38:56.887Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>MLA‘20之行让我学到了很多，包括领域知识，对学习生活的前瞻，以及更多对当下学习困境的思考</p><p>故创文记之，以思故我。就当是小小随笔</p><p>不太好写啊！干脆随便总结下吧，细节留在网盘里就好</p></blockquote><a id="more"></a><img src="/2020/11/10/MLA‘20见闻/MLA-1.JPG" title="MLA" alt="20开冲！"><p>会议日程 <a href="http://www.lamda.nju.edu.cn/conf/mla20/program.html" target="_blank" rel="noopener">http://www.lamda.nju.edu.cn/conf/mla20/program.html</a></p><h1 id="流水账"><a href="#流水账" class="headerlink" title="流水账"></a>流水账</h1><h2 id="第一天上午"><a href="#第一天上午" class="headerlink" title="第一天上午"></a>第一天上午</h2><p>第一场，北大王立威教授介绍深度学习，主要提到了泛化理论的新解释。</p><p>先介绍了下深度学习的方向：</p><pre class="mermaid">graph LRA(深度学习) -->B(模型/结构)A(深度学习) -->C(训练/优化)A(深度学习) -->D(泛化/测试优化)B -->E[CNN]B -->F[RNN]B -->G[LPWHW, 2017]B -->H[Cybenko, 1998]</pre><blockquote><p>ps：画图的时候要选择mermaid而不是flow，否则报错</p><p><code>ERROR: [Flowchart] Cannot set property &#39;next&#39; of undefined</code></p><p>ps2：mermaid在hexo中需要安装包才能使用，且里面所有的操作都要加上 <a href="https://www.dazhuanlan.com/2019/11/20/5dd4ec5f4f552/" target="_blank" rel="noopener">https://www.dazhuanlan.com/2019/11/20/5dd4ec5f4f552/</a> <a href="https://tyloafer.github.io/posts/7790/" target="_blank" rel="noopener">https://tyloafer.github.io/posts/7790/</a></p></blockquote><p>重点提到了学习理论的泛化解释可能是有问题的。</p><img src="/2020/11/10/MLA‘20见闻/IMG_1996.JPG" title="过参数化而非过拟合"><p>即过拟合并不是过拟合，而是过参数化，过参数化不会导致泛化性能的大幅下降，还能保持一定的泛化能力。</p><p>然后讲了优化，一个小背景是即便是4阶多项式局部极小的优化也是NP难的问题。然后有个结论是一般的SGD方法在绝大多数方法上都work well，为什么？2019年ICML的DLLWZ证明了梯度下降GD可以以一个线性收敛速度（in a linear convergence rate）找到全局极小，但是有两个条件（没条件显然不太对头），一是网络要足够宽（即足够过参数化），然后参数的初始化选择Gauss，选择其中的协方差参数，最后选合适的step size。ResNet的确更好。</p><p>当网络无限宽时，网络会退化成kernel machine。</p><img src="/2020/11/10/MLA‘20见闻/MLA-3.JPG" title="神经网络的拟合能力"><p>方法的一个insight是，在这样的初始点附近，其邻域的性质好，存在一个所谓内在的全局极优？</p><img src="/2020/11/10/MLA‘20见闻/IMG_1998.JPG" title="DLLWZ, 2019"><p>最后有个文章列表</p><img src="/2020/11/10/MLA‘20见闻/IMG_2011.JPG" title="老师组内文章列表（仅参考）"><hr><p>第二位老师是UCLA的印卧涛，主题是Faster Learning over Networks and Opensource Framework BlueFog，介绍大规模模型。</p><p>大规模数据或者模型的处理方式是</p><pre class="mermaid">graph LRA(大规模) -->B(数据并行)A(深度学习) -->C(模型并行)A(深度学习) -->D(模型分割后并行?)</pre><p>其中一种方案是parameter server approach，但不适合大规模。方式是一张卡和多张卡之间传输数据，但是n21似乎不太好整合。</p><pre class="mermaid">graph LRA(大卡) -->B(卡1)A(大卡) -.1对多.->C(...)A(大卡) -->D(卡n)E(左到右:1对多<br>右到左:多对1)</pre><p>报告中指出一个方案是环上的整合，叫ring allreduce，缺点是同一时刻edge只有一个</p><p>然后推荐了他们自己的framework：bluefog，好像几行代码能完成相关工作。后面没听了</p><hr><p>第三场是微软亚洲研究院的秦涛讲神经语言合成。</p><pre class="mermaid">graph LRA(神经语言合成) -->B(拼接方法<br>比如concatenative TTS<br>缺点是自由度低)A -->C(参数化方法<br>parametric TTS<br>优点是灵活,缺点是可能不自然)A -->D(神经网络方法<br>更前沿就对了)%%E(左到右:1对多<br>右到左:多对1)</pre><p>然后倒是讲了不少neural方法的例子：</p><ul><li>Deep Voice 3(ICLR 2018)</li><li>Tacotron 2(LSTM)</li><li>Transformer TTS(AAAI 2019)</li><li>Fast Speech(NIPS 2019)</li></ul><hr><p>第四场是是顶会交流介绍。列表参考 <a href="http://www.lamda.nju.edu.cn/conf/mla20/poster.html#spotlight%2011_07" target="_blank" rel="noopener">http://www.lamda.nju.edu.cn/conf/mla20/poster.html#spotlight%2011_07</a> ，有需求的时候自取。</p><p>其中我自己想看的列在这里：</p><ul><li>王红师姐的模型驱动+数据驱动</li><li>清华的Understanding and Exploring the Network with Stochastic Architectures</li></ul><h2 id="第一天下午"><a href="#第一天下午" class="headerlink" title="第一天下午"></a>第一天下午</h2><p>第五场是孙剑介绍CV前沿，自己的笔记记得挺多的。太多了所以不想整理了喵。不过注意他这里面讲得非常全的，有几个我感兴趣的，比如过参数化的解释、shuffleNet特征图间操作、目标检测的一些东西，etc。</p><hr><p>第六场是南大吴建鑫介绍CNN压缩。一个背景是小设备上需要轻量网络。一般的方法是剪枝，总结如下：</p><pre class="mermaid">graph LRA(网络剪枝) -->B(剪枝基本方法<br>网络权重低于某阈值时就压缩<br>缺点是使模型非结构化,难以加速)B --> E(一篇文章作为例子 Han Song NIPS 2015)A -->C(结构化剪枝<br>即保持网络形状不变)C --> F(剪哪些<br>idea是剪一部分,后面对应的net也会受影响)C --> G(怎么剪<br>具体没听清楚,大概是数学优化的角度做reconstruction,最小化下一层的啥目标)%%E(左到右:1对多<br>右到左:多对1)</pre><p>上面是以往设计的压缩剪枝方式，总结的话就是人工剪枝三段式：确定权重/重要性，剪掉，再微调网络参数。现在呢，有人在做自动压缩的方法，咋做没记笔记，大概是auto-pruner，另外还有人做ResNet剪枝、小数据任务上的剪枝，等等。</p><hr><p>第七场是复旦黄萱菁讲中文命名实体识别，感觉是NLP方法的一些变种，具体没有咋听。</p><hr><p>第八场是孟老师操作一手，讲模型驱动与数据驱动之间的差异、联系、结合。</p><p>以图像去噪为例，模型驱动主要是生成方式的理解， $\displaystyle \arg\min_{z} L(Y-z)+R(z)$ ，其中 $Y$ 是带噪图， $z$ 是潜在的干净图，所以 $Y-z$ 其实就相当于噪声；数据驱动则直接网络拟合干净图，</p><script type="math/tex; mode=display">\displaystyle \arg\min_{w} ||z-net_w (Y)||_2</script><p>其中 $z$ 可以是提供的真实干净图，但也可以去拟合噪声啊，这样就是 </p><script type="math/tex; mode=display">\displaystyle \arg\min_{w} ||\varepsilon-ResNet_w (Y)||_2</script><p>但是数据驱动的确是黑箱操作，缺点是解释性相对较差，无生成功能，且依赖于监督标记。</p><p>孟老师操作了一手模型、数据驱动结合的理解，二者能否互补？由此孟老师来了一手外练筋骨皮、内练一口气、万法归宗的比喻，具体放在图里看一下：</p><pre class="mermaid">graph LRA(模型驱动&数据驱动) -->B(外练筋骨皮<br>需要知道/建模数据是怎么走的)A -->C(内练一口气<br>网络结构需要有可解释性)A -->D(万法归宗<br>数据驱动学习生成规律?)B -.paper1.-> E(MAP的, TPAMI 18, 讲CT的,链接放在文末)B -.paper2.-> F(王红大佬的去雨模型<br>ps:我怎么觉得这个是内练?可能笔记记错了)C -.idea.-> G(idea<br>网络由黑箱隐式函数到显示函数<br>优化算法解释为网络结构的迭加形式)C -.e.g..-> H(deep unfolding就是其中一类方法)%%E(左到右:1对多<br>右到左:多对1)</pre><hr><p>第九场也非常精彩！是朱军老师介绍贝叶斯深度学习，但是我的笔记没有记全😭。只记了以下几点：</p><ol><li><p>Bayes和NN的结合要回到Hopfield当年一个学生的博士论文</p></li><li><p>BNN可以与高斯过程联系起来！</p></li><li><p>Drop out也可以看/理解成是一种贝叶斯</p></li><li><p>NICE中的flow-based-model</p></li><li><p>VFlow没有拍到，但是好像非常有意思，回头搜一下</p><blockquote><p>搜到了：<em>VFlow: More Expressive Generative Flows with Variational Data Augmentation</em></p><p><a href="https://www.aminer.cn/pub/5e54f1813a55acae32a25d67/vflow-more-expressive-generative-flows-with-variational-data-augmentation" target="_blank" rel="noopener">https://www.aminer.cn/pub/5e54f1813a55acae32a25d67/vflow-more-expressive-generative-flows-with-variational-data-augmentation</a></p><p><a href="https://arxiv.org/abs/2002.09741" target="_blank" rel="noopener">https://arxiv.org/abs/2002.09741</a></p><p><a href="https://github.com/thu-ml/vflow" target="_blank" rel="noopener">https://github.com/thu-ml/vflow</a></p></blockquote></li></ol><hr><p>第十场是京东的易津峰老师介绍对抗攻击。基本的idea就是准确率不是唯一的度量模型好坏的标准，在某种程度上准确率上升，稳健性会下降。以图像任务为例就是抗像素扰动能力下降了。笔记没咋记，又一篇京东在ECV18上面的文章，有空的话浏览下吧。</p><blockquote><p>搜到了：<em>Is Robustness the Cost of Accuracy? — A Comprehensive Study on the Robustness of 18 Deep Image Classification Models</em></p><p><a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Dong_Su_Is_Robustness_the_ECCV_2018_paper.html" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_ECCV_2018/html/Dong_Su_Is_Robustness_the_ECCV_2018_paper.html</a></p></blockquote><h2 id="第一天晚上"><a href="#第一天晚上" class="headerlink" title="第一天晚上"></a>第一天晚上</h2><p>第一天晚上结束，和同学讨论了dual-SVM中QP问题转化为minmax问题的细节哈哈哈，都忘了，好在最后推出来了</p><h2 id="第二天上午"><a href="#第二天上午" class="headerlink" title="第二天上午"></a>第二天上午</h2><p>第二天，第十一场，南方科技大学的姚新讲博弈、共生演化问题。总的来说这是老问题了，但是和机器学习的联系不是非常紧密，现在做这个的人很少了。其实我也不太想弄，在这里打个广告科普一下吧qwq。</p><p>姚老师举了很多例子：囚徒困境、协同演化的有效性验证实验、学生AA（忘了具体是什么了）问题、晚自习关灯（电量浪费）问题、农场主共用草场问题，etc。老师表示这背后其实都有数学理论，只是没时间分享了，手动狗头[doge]。理论的概览提了一下，放在下图中：</p><pre class="mermaid">graph LRA(共生演化问题例子<br>老师以NIPD为例给出了许多实验结果) -->B(历史记录<br>一般问题中玩家/用户只能记住前几步的经验,记得越多结果的总体效益越好)A -->C(有个group size<br>我忘了是啥了,反正就是越小越好)A -->D(迭代次数影响最终结果)B --> E(一般共生演化问题)C --> ED --> EE --> F(无训练集,数据都是即时模拟生成的)E --> G(初始化一般是随机的)E --> H(需要环境中用户的交互)</pre><hr><p>第十二场是阿里的华先胜讲城市大规模视觉数据、交通的预测和调度。老师先广告一波，表示Ali旗下做ML的越来越多了，包括machine vision、speech、NLP、DL及其优化问题，etc。然后华老师介绍了城市大脑和交通管理安全的概念，其中需要大规模的感知认知和优化技术。一般来说城市中交通数据中的异常数据都是imbalanced data，且都有突变性，可以看作是异常检测问题，可以直接分类，方法众多，如KNN、SVR、VAR，不过这些方法有利有弊。另外，城市中红绿灯感应方面的协同调度比较复杂，也是一个重要应用。</p><p>最后有个东西我可以参考，应该算是重要的，我截了一张图好像，讲的是记忆卷积，是否在ODE中可以考虑前几步的数据+重加权成为meta方法？</p><img src="/2020/11/10/MLA‘20见闻/MLA-2.PNG" title="记忆卷积截图"><hr><p>第十三场是山世光老师讲自监督学习，主要是视觉感知计算中的标记增强。自监督学习就是一种无监督，没有标记的数据，但是还是能提取出一些标记，可以说是弱标签。</p><blockquote><p>ps：师兄表示山老师是人脸识别领域中国带🐂，绕不过去的那种</p></blockquote><p>无标记的data本身不一定就是完全没有标记的，一般会有一些弱标签；预训练的迁移也一定程度上缓解了标签较弱的问题，但是缺点是过早进行分类会丢失信息（是指预训练提取的特征不够么🤔）；而任务的迁移一般是多任务，需要上下游任务之间联系；另外，对于图像任务，自然语言中的一些常识也有机会迁移过来，比如考虑图像的词法、句法，成为视觉的常识表示。标记如何增强？增广、数据再生（包括打乱、图像擦补等手段）。</p><h2 id="第二天下午"><a href="#第二天下午" class="headerlink" title="第二天下午"></a>第二天下午</h2><p>最后一天下午的听得都不细致了，主要是企业打广告，讲的内容比较少。主要是有一些有趣的应用，比如：</p><ul><li>英特尔的陈玉荣博士讲以人为中心的视觉分析，有个视线预测的例子很有意思</li><li>南大毕业的倍漾科技冯霁博士讲了金融投资的一些idea，网上发表的相关文章几乎没有核心技术，而且往往出错众多😂。提到了金融投资分几类，瞬发的高频决策，中高频的几时内的决策（割散户韭菜❓），以及低频（数月或者季度）的决策（如公司价值的跃迁）。另外，一个idea是量化交易是团队合作！自己一个人搞模型瞎投似乎不切实际</li><li>涂威威介绍第四范式，做各个方面应用产品的公司</li></ul><hr><p>最后的最后是顶会介绍，基本上全听了，不过不方便写在这里。就只说个结论，强化学习意外地成为近期最火热的方向，其次是自监督学习、对抗、表示学习等等。</p><h1 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h1><p>这次南京之行，对领域的各个方向有了进一步了解，以及了解了近期火热的方向（可惜暂时我不是很感兴趣），以及各个方向基础的一些方法，有意思的一些应用。目前磕盐吃还是磕磕自己原来感兴趣的吧。</p><p>其实帮助最大的还是师兄的几番谈话，对未来的打算又有了一些思考，先走一步看一步吧，11月底正式想一想接下来该怎么走。</p><p>另外，读文章还是慢了些，最近我要试图再加快读文章的速度、把握文章的重点并重点记录，流水账式的描述就先放放吧，先达到师兄描述的境界~</p><hr><p>回来想看的文章：</p><ul><li>前面提到的大概2-3篇</li><li>TPAMI文章，好像是有关模型驱动与数据驱动的结合 Kronecker-basis-representation based tensor sparsity and its applications to tensor recovery <a href="https://ieeexplore.ieee.org/document/8000407" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/8000407</a></li><li>去之前留的一些没看完的</li><li>回来之后老师推荐的一篇NIP20文章Ode to an ODE <a href="https://proceedings.neurips.cc/paper/2020/file/228669109aa3ab1b4ec06b7722efb105-Paper.pdf" target="_blank" rel="noopener">https://proceedings.neurips.cc/paper/2020/file/228669109aa3ab1b4ec06b7722efb105-Paper.pdf</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;MLA‘20之行让我学到了很多，包括领域知识，对学习生活的前瞻，以及更多对当下学习困境的思考&lt;/p&gt;
&lt;p&gt;故创文记之，以思故我。就当是小小随笔&lt;/p&gt;
&lt;p&gt;不太好写啊！干脆随便总结下吧，细节留在网盘里就好&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="随笔" scheme="http://maxliu245.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>【文献阅读26】YoloV4</title>
    <link href="http://maxliu245.github.io/2020/11/03/%E3%80%90%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB26%E3%80%91YoloV4/"/>
    <id>http://maxliu245.github.io/2020/11/03/%E3%80%90%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB26%E3%80%91YoloV4/</id>
    <published>2020-11-03T02:25:45.000Z</published>
    <updated>2020-11-03T15:01:54.821Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>头一次正式看目标检测方面的文章，有些功利，直接从YoloV4开始！</p><p><code>YOLOv4: Optimal Speed and Accuracy of Object Detection</code></p></blockquote><a id="more"></a><img src="/2020/11/03/【文献阅读26】YoloV4/YoloV4-1.png" title="YoloV4文献简介"><h1 id="文献简介"><a href="#文献简介" class="headerlink" title="文献简介"></a>文献简介</h1><p>先放文献地址： <a href="https://arxiv.org/abs/2004.10934" target="_blank" rel="noopener">https://arxiv.org/abs/2004.10934</a></p><p>YoloV4于2020/04挂在Arxiv上，作者之一是之前Yolo代码的维护者之一，<a href="https://github.com/AlexeyAB" target="_blank" rel="noopener">Alexey Bochkovskiy</a>，暂时没有找到他的更多资料，另外两个作者是台湾中央研究院的，不认识。</p><h1 id="先修知识"><a href="#先修知识" class="headerlink" title="先修知识"></a>先修知识</h1><p>直接上手这篇目标检测领域的文章稍有困难，因为以前没咋接触过目标检测，现在直接来一手业界极强的文章，很多名词概念都不清楚。</p><p>本来打算补一补，但是发现YoloV4用的模型方法实在是有（多）些（炸）多（了），所以其实只补了文章刚开始的一些概念，码在这里：</p><ul><li><p>Pareto optimality curve，中文名帕累托最优曲线，以本文图 $(1,8)$ 为例，都是2维曲线，这是因为本文选取的评价指标（目标）有两个。我联想到了宏观经济学中的供求曲线、价格需求曲线，感觉道理有一点点像（瞎想的）。</p><blockquote><p>具体可参考知乎用户<a href="https://www.zhihu.com/people/li-lin-song-85" target="_blank" rel="noopener">木木松</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/54691447" target="_blank" rel="noopener">多目标优化之帕累托最优</a></p></blockquote></li><li><p>Anchor-based和Anchor-free方法，都是目标检测中的方法。前者参考下面的链接，讲得很清楚了，依次设计锚点的位置、锚框的个数大小，我猜最后是根据ground truth去判断标记框的优劣；后者似乎是没有具体设置所谓的锚点，只是先识别目标的中心，然后根据中心进行回归得到标记框（未求证）</p><blockquote><p>具体可参考知乎用户<a href="https://www.zhihu.com/people/emiya-98" target="_blank" rel="noopener">emiya</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/86741707" target="_blank" rel="noopener">Anchor-Based-01 目标检测算法设计思想一：anchor是什么</a></p></blockquote></li></ul><h1 id="YoloV4"><a href="#YoloV4" class="headerlink" title="YoloV4"></a>YoloV4</h1><h2 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h2><p>其实刚开始看觉得很舒服，讲的东西都非常合理有道理（后面也是），但是后面讲的名词知识太多了，让我觉得这模型不会就是<strong>各种已有的优秀方法组合拼接</strong>出来的吧！不会吧不会吧，它还<strong>真的就是这样搞的</strong>！</p><p>经过多篇博客总结查证，我基本上确定这文章就是这样做的，不过人家做的确实猛，优点总结如下：</p><ul><li>文章提出的YoloV4达到了文章目标（预期）：保证准确率大前提下，设计出一个<strong>快速实时轻量准确</strong>的目标识别模型。确实，本文表示<strong>只需要1张</strong>优秀的显卡就可以完成快速训练（又向应用前进一步！），并且的确是轻量实时准确的</li><li>在contributions部分提出可以用YoloV4的想法修饰SOTA模型使之有效轻量，应该是这个意思</li><li>集成了<strong>大量已有tricks</strong>，据参考文献表示至少有20多种；这篇文章的工作量十分之大，值得肯定</li><li>文章开头提出了一个说法：CNN任务的一个完整框架需要理论保证+实验验证。本文的tricks可以说是验证了的东西，然后在多个数据集上也显示出帕累托最优的效果</li></ul><h2 id="主要tricks"><a href="#主要tricks" class="headerlink" title="主要tricks"></a>主要tricks</h2><p>说tricks之前忘了提一嘴YoloV4的整体网络框架了，和经典的目标识别检测框架一致，有一个</p><script type="math/tex; mode=display">input \rightarrow backbone \rightarrow neck \rightarrow head(dense\ prediction \rightarrow sparse\ prediction)</script><p>的整体框架，其中某些部分不知道有没有跨连接的操作。下面放一张原文的图 $(2)$ ：</p><img src="/2020/11/03/【文献阅读26】YoloV4/YoloV4-2.png" title="目标检测框架"><p>那么YoloV4其实就说各种tricks，或者说是<strong>各种模型插件</strong>套进这个框架。</p><p>这个我其实没有细看文章了，毕竟陌生名词太多，搞不清哪些是重点，这里根据他人博客自己总结其中有用的tricks：</p><ul><li><p>首先有个idea起源于Yolo系列的任务是目标识别检测。目标检测方法往往是任务special的，特定任务要特定设计，在通用模型没有发展起来并大规模应用之前我是站这个东西的。本文希望能做到通用的general目标检测模型，那么一个idea就是special特征和general特征，YoloV4在网络模块的使用上<strong>主动选择了很多general特征</strong>（我认为是特征图）</p></li><li><p>为了轻量实时，<strong>选择Yolo系列</strong>的模型是当前合适的做法，本文在head区域使用了YoloV3</p></li><li><p><strong>各种数据增强技术</strong>的使用</p></li><li><p><strong>自对抗方法增强图像风格</strong>，我觉得可以算数据增强了</p></li><li><p>大佬们还总结了“跨最小批的归一化（Cross mini-batch Normal）、修改的SAM（逐点attention）、修改的PAN（通道合并方式改变）”，不过我现在不太懂，先码在这里。这里最后三条参考：</p><blockquote><p>知乎用户<a href="https://www.zhihu.com/people/william.hyin" target="_blank" rel="noopener">william</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/161083602" target="_blank" rel="noopener">一文读懂YOLO V5 与 YOLO V4</a></p><p>知乎用户<a href="https://www.zhihu.com/people/jianghongliang" target="_blank" rel="noopener">元峰</a>的回答<a href="https://www.zhihu.com/question/390191723/answer/1177584901" target="_blank" rel="noopener">如何评价新出的YOLO v4 ？</a>不错，从创新性的角度分析了YoloV4使用的主要tricks</p></blockquote></li></ul><h2 id="个人感想（bb）"><a href="#个人感想（bb）" class="headerlink" title="个人感想（bb）"></a>个人感想（bb）</h2><p>本来头一遍翻完这篇文章觉得还挺ysk（😁）的，但是抱着这个怀疑我去读了他人的总结，包括：</p><blockquote><p>知乎用户<a href="https://www.zhihu.com/people/amusi1994" target="_blank" rel="noopener">Amusi</a>的回答<a href="https://www.zhihu.com/question/390191723/answer/1176986665" target="_blank" rel="noopener">如何评价新出的YOLO v4 ？</a>很好，我很赞同。人家工作量在这里，确实很良心</p><p>知乎用户<a href="https://www.zhihu.com/people/david-12-84-45" target="_blank" rel="noopener">David</a>的专栏文章<a href="https://zhuanlan.zhihu.com/p/136172670" target="_blank" rel="noopener">YOLO-V4解读：速度与精度的完美结合[已开源]</a>是一篇简洁的翻译，可以速读参考</p><p>补充资料：知乎用户<a href="https://www.zhihu.com/people/magic-frog-sjtu" target="_blank" rel="noopener">996黄金一代</a>的回答<a href="https://www.zhihu.com/question/399884529/answer/1374024055" target="_blank" rel="noopener">如何评价YOLOv5？</a></p></blockquote><p>我这才有些缓过来，人家毕竟是总结了大量方法，有充足的工作量，而且效果也上去了，那的确是不错的。大家反驳之的意见是似乎大家应用还是不用它，用YoloV3，大概是觉得它这样相当于调参？不过人家做了很多实验，在不少数据集上也足够优秀了，那我是没话说了。</p><p>这种套方法的方式，可取，但是得有充足的调研，充足的实验经验。加油吧骚年！</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Alexey Bochkovskiy, Chien-Yao Wang, and Hong-Yuan Mark Liao. Yolov4: Optimal speed and accuracy of object detection, 2020.</p><p>[2] emiya. Anchor-Based-01 目标检测算法设计思想一：anchor是什么[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/86741707" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/86741707</a>, 2019-10-26.</p><p>[3] 木木松. 多目标优化之帕累托最优[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/54691447" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/54691447</a>, 2020-10-07.</p><p>[4] william. 一文读懂YOLO V5 与 YOLO V4[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/161083602" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/161083602</a>, 2020-07-28.<br>[5] 元峰. 如何评价新出的YOLO v4 ？[EB/OL]. <a href="https://www.zhihu.com/question/390191723/answer/1177584901" target="_blank" rel="noopener">https://www.zhihu.com/question/390191723/answer/1177584901</a>, 2020-04-25.<br>[6] Amusi. 如何评价新出的YOLO v4 ？[EB/OL]. <a href="https://www.zhihu.com/question/390191723/answer/1176986665" target="_blank" rel="noopener">https://www.zhihu.com/question/390191723/answer/1176986665</a>, 2020-04-24.<br>[7] David. YOLO-V4解读：速度与精度的完美结合[已开源][EB/OL]. <a href="https://zhuanlan.zhihu.com/p/136172670" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/136172670</a>, 2020-05-20.<br>[8] 996黄金一代. 如何评价YOLOv5？[EB/OL]. <a href="https://www.zhihu.com/question/399884529/answer/1374024055" target="_blank" rel="noopener">https://www.zhihu.com/question/399884529/answer/1374024055</a>, 2020-07-31.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;头一次正式看目标检测方面的文章，有些功利，直接从YoloV4开始！&lt;/p&gt;
&lt;p&gt;&lt;code&gt;YOLOv4: Optimal Speed and Accuracy of Object Detection&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="CNN" scheme="http://maxliu245.github.io/tags/CNN/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
      <category term="Yolo" scheme="http://maxliu245.github.io/tags/Yolo/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读25】HollowNet——NN对微分算子的模拟</title>
    <link href="http://maxliu245.github.io/2020/10/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB25%E3%80%91HollowNet%E2%80%94%E2%80%94NN%E5%AF%B9%E5%BE%AE%E5%88%86%E7%AE%97%E5%AD%90%E7%9A%84%E6%A8%A1%E6%8B%9F/"/>
    <id>http://maxliu245.github.io/2020/10/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB25%E3%80%91HollowNet%E2%80%94%E2%80%94NN%E5%AF%B9%E5%BE%AE%E5%88%86%E7%AE%97%E5%AD%90%E7%9A%84%E6%A8%A1%E6%8B%9F/</id>
    <published>2020-10-24T07:43:45.000Z</published>
    <updated>2020-10-26T09:49:10.466Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>这篇文章标题并没有提到HollowNet，标题为<em>Neural Networks with Cheap Differential Operators</em></p><p>是去年（19）NIPS，由著名的<a href="http://www.cs.toronto.edu/~rtqichen/" target="_blank" rel="noopener">陈天琦</a>写的文章</p></blockquote><a id="more"></a><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/HollowNet-1.png" title="文献预览"><p>文献链接： <a href="https://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators.pdf</a> ，更详细的地址在 <a href="http://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators" target="_blank" rel="noopener">http://papers.nips.cc/paper/9187-neural-networks-with-cheap-differential-operators</a></p><p>这篇文章我其实没有读透，文中的 $(6)$ 式我还没懂，而且我喜欢挑刺，我总觉得文章里很多记号写得不好不统一…不过问题也不大，记个笔记就好啦~</p><h1 id="Why-HollowNet？——背景"><a href="#Why-HollowNet？——背景" class="headerlink" title="Why HollowNet？——背景"></a>Why HollowNet？——背景</h1><p>本文的标题没有提及HollowNet，但是其实说明了文章做了什么，即用NN来模拟微分算子，只不过模拟的微分算子可能比较简单，所以说是cheap的。</p><p>那么文章是怎么考虑到要用NN模拟微分算子的呢？（我塔喵其实就是在想这个问题！）</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/TAMIAO.jpg" title="我的塔喵是巴萨卡🐷~"><p>其实没什么可考虑的，就是想模拟微分算子嘛，但是微分算子比较复杂，本身就是抽象的数学记号，而且还有各种微妙的复杂性，如对时间、或者是对空间等变量的<strong>变化</strong>的描述。</p><p>这篇文章就是基于此想法，提出了HollowNet，它完成的任务是对输入为向量 $\mathbf{x}$ 的向量函数 $\mathbf{f}(\mathbf{x})$ 求对 $\mathbf{x}$ 的单变量 $x_j$ （以第 $j$ 元为例）的高阶偏导数，即 $\displaystyle \dfrac{\partial^k \mathbf{f}(\mathbf{x})}{\partial x_j^k}$ 。文中称之为<font color="#0000FF">dimension-wise k-th order derivatives</font>。</p><h1 id="How-HollowNet？——挖空NN"><a href="#How-HollowNet？——挖空NN" class="headerlink" title="How HollowNet？——挖空NN"></a>How HollowNet？——挖空NN</h1><p>这里要先声明文章完成的<strong>任务</strong>是模拟了<font color="#0000FF">dimension-wise k-th order derivatives</font> $\displaystyle \dfrac{\partial^k \mathbf{f}(\mathbf{x})}{\partial \mathbf{x}_j^k}$ ，其中 $\mathbf{f}:\mathbb{R}^d\rightarrow \mathbb{R}^d$ ，<font color="#0000FF">dimension-wise k-th order derivatives</font>为：</p><script type="math/tex; mode=display">\displaystyle \mathcal{D}_{dim}^k(\mathbb{f}) = \dfrac{\partial^k \mathbf{f}(\mathbf{x})}{\partial \mathbf{x}_j^k} = \left[\dfrac{\partial^k f_1(\mathbf{x})}{\partial \mathbf{x}_1^k}\ \dfrac{\partial^k f_2(\mathbf{x})}{\partial \mathbf{x}_2^k}\ \cdots,\ \dfrac{\partial^k f_d(\mathbf{x})}{\partial \mathbf{x}_d^k} \right]^T\in \mathbb{R}^d</script><p>文章这里就有一些小问题，这些真的是dimension-wise的，如果需要混合偏导，比如 $\dfrac{\partial^k f_i(\mathbf{x})}{\partial x_j^k},\ where\ i\neq j$ ，那这个式子就无能为力了，这大概也是为什么文章标题说是“cheap”的微分算子</p><hr><p>至于具体怎么用网络实现，话不多说，日常上图：</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/HollowNet-2.png" title="HollowNet结构"><p><strong>左图是完整的前向计算过程</strong>，这里为了求 $f<em>k$ 对 $x_k$ 的偏导数，先由除了 $x_k$ 之外的所有分量 $\mathbf{x}</em>{-k} \triangleq {x<em>1, x_2, \cdots, x_d}/ {x_k}$ ，计算一个 $h_k = c_k(\mathbf{x}</em>{-k})$ ，其中 $h_k$ 不一定是标量，因为标量的信息一般不够描述高阶导数，一般是向量，这里先假定为 $d_h(\forall k)$ 维，然后这个 $h_k$ 和 $x_k$ 再作为输入得到函数值分量 $f_k=\tau_k(h_k,x_k)$ 。这样设计的目的是为了方便后面挖空网络之后，函数值分量 $f_k$ 只保留对输入分量 $x_k$ 的偏导数。</p><p>那么<strong>右图就是挖空计算图的操作</strong>了。由左图的设计，只要在编程中通过<code>detach</code>一类的操作断掉 $f_k$ 和 $h_k$ 之间的联系，那么在计算图中就只保留了 $\dfrac{\partial f_k}{\partial x_k}$ ，对其它分量的偏导数一律为0。</p><p>在左图中，从输入变量的分量 $\mathbf{x}_{-k}$ 到中间变量 $h_k$ 的过程叫做<code>conditioner</code>，表示这种特殊设计的条件关系；从中间变量 $h_k$ 到最终函数分量 $f_k$ 的过程则叫做<code>transformer</code>，这个不太好解释，反正是这么个说法。</p><p>有了这个挖空计算图的操作还不够，因为显然我们会注意到 $f<em>k$ 本身还是由所有分量计算得到的，单独切掉 $\mathbf{x}</em>{-i}$ 对应的计算图，那么如果有对 $f_k$ 的后续计算，比如计算损失函数 $c$ ，那么就有 $\displaystyle \dfrac{\partial c}{x_k} = \sum_j \dfrac{\partial c}{\partial f_j}\dfrac{\partial f_j}{\partial x_k}$ ，而这样的话相当于在计算图中，右边只能保留一项梯度 $\dfrac{\partial c}{\partial f_k}\dfrac{\partial f_k}{\partial x_k}$ ，这和我们的认知不符，我认为文章<strong>基于这个考虑对挖空的计算图做了一个补全</strong>，即文章的 $(6)$ 式，我自己学了点计算图想推一下，但是<strong>应该是推错了</strong>，过程记录如下：</p><script type="math/tex; mode=display">\displaystyle \begin{aligned} \dfrac{\partial \mathcal{D}_{dim}(\mathbb{f})}{\partial w} &= \sum_j\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial h_j} \dfrac{\partial h_j}{\partial w} = \sum_j\left(\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}\dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial h_j}\right) \dfrac{\partial h_j}{\partial w}\\ &= \sum_j\left(\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})} \left(\dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}}_j)}{\partial h_j} \bigoplus \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}}_{-j})}{\partial h_j}\right)\right) \dfrac{\partial h_j}{\partial w}\\ &?= \sum_j\left(\dfrac{\partial \mathcal{D}_{dim}^k(\mathbb{f})}{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})} \left(\dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial \hat{h}} \bigoplus \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}}_{-j})}{\partial h_j}\right)\right) \dfrac{\partial h_j}{\partial w}\\ &?= \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial \hat{h}}\dfrac{\partial h}{\partial w} + \dfrac{\partial \mathcal{D}_{dim}^k(\hat{\mathbb{f}})}{\partial w}\end{aligned}</script><font color="#FF0000"> 最后两行我是懵了，看了点计算图还是不懂，先放在这里了</font><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><p>讲方法优劣之前，其实看了一点点实验，为文章的 $(5.2)$ 节，大概就是说对于一个随机微分方程，这个HollowNet模拟得不错</p><div class="table-container"><table><thead><tr><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>cheap微分算子的成功模拟❕</td><td>只构建了cheap微分算子，维度-wise的，那么混合偏导等算子呢</td></tr><tr><td>HollowNet构建方式和我想的不一样，这也是我可以借鉴的地方之一</td><td>原文$(2.1)$ 节提到 $d_h$ 要小一些，这样可以大量减少计算量，但是这样维度较小，信息流足够么❓</td></tr><tr><td>HollowNet没有太多对模型的限制，之前很多流模型，包括NICE等都有很多限制（原文 $(2.1)$ 节）</td><td>原文 $(6)$ 式的计算图补偿方式讲得不洗，没看懂哇，是不是和图 $(1)$ 提到的对角分解有关❓</td></tr><tr><td></td><td>原文的例子都看起来很复杂，有实例的一个还是SDE，为何不举像NODE中那样一般的简单例子呢❓</td></tr></tbody></table></div><h1 id="补充知识——学习计算图"><a href="#补充知识——学习计算图" class="headerlink" title="补充知识——学习计算图"></a>补充知识——学习计算图</h1><p>学这个是因为开始看文章的时候 $(6)$ 式不明白，所以先快速补一下</p><p>参考的资源是B大李宏毅深度学习(2017)课程第三讲： <a href="https://www.bilibili.com/video/BV1Ux411S7rk?p=3" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Ux411S7rk?p=3</a></p><h2 id="一般计算图"><a href="#一般计算图" class="headerlink" title="一般计算图"></a>一般计算图</h2><p>计算图的目的是计算梯度，一般的有效方法是BP，不过程序计算大多都是通过计算图。</p><p>计算图可以看成描述函数的语言，包括节点（变量）和边（运算），和PRML第8章讲得差不多。</p><p>举了好几个例子，都看懂了，注意一点就是每个中间变量都可以单独作为一个节点；另一点是链式法则可以根据计算图考虑，把箭头连接看成偏微分再写出链式法则的式子。</p><p>使用计算图的几个原因：</p><ol><li>一般我们会得到一个loss，对这个单输出求参数的偏导数，在计算图上从单输出reverse比较有效率</li><li>NN中往往存在参数共享的时候，同一参数可能反复使用，这时考虑从该变量到输出的所有路径，偏导加起来就好了，非常直接</li></ol><h2 id="前馈网络的计算图"><a href="#前馈网络的计算图" class="headerlink" title="前馈网络的计算图"></a>前馈网络的计算图</h2><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY1.png" title="前馈网络计算图表示（图源B站，侵删）"><p>算好每条边上对应的偏导数，然后reverse计算总的偏导数就好了。不过真正的计算过程挺麻烦的，我直接截一张图了：</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY2.png" title="前馈网络梯度计算过程（图源B站，侵删）"><h2 id="RNN的计算图"><a href="#RNN的计算图" class="headerlink" title="RNN的计算图"></a>RNN的计算图</h2><p>RNN都忘光了，放一张图在这里吧：</p><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY3.png" title="RNN模型（图源B站，侵删）"><img src="/2020/10/24/【论文阅读25】HollowNet——NN对微分算子的模拟/LHY4.png" title="RNN计算图（图源B站，侵删）"><p>行了，大概明白具体是怎么算的了</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>[1] Ricky T. Q. Chen and David K Duvenaud. Neural networks with cheap differential operators. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 9961–9971. Curran Associates, Inc., 2019.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇文章标题并没有提到HollowNet，标题为&lt;em&gt;Neural Networks with Cheap Differential Operators&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;是去年（19）NIPS，由著名的&lt;a href=&quot;http://www.cs.toronto.edu/~rtqichen/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈天琦&lt;/a&gt;写的文章&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读24】On Second Order Behaviour in ANODE——真二阶NODE</title>
    <link href="http://maxliu245.github.io/2020/10/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB24%E3%80%91On-Second-Order-Behaviour-in-ANODE%E2%80%94%E2%80%94%E7%9C%9F%E4%BA%8C%E9%98%B6NODE/"/>
    <id>http://maxliu245.github.io/2020/10/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB24%E3%80%91On-Second-Order-Behaviour-in-ANODE%E2%80%94%E2%80%94%E7%9C%9F%E4%BA%8C%E9%98%B6NODE/</id>
    <published>2020-10-19T11:11:29.000Z</published>
    <updated>2020-10-31T14:02:39.949Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p><code>On Second Order Behaviour in Augmented Neural ODEs</code>，简称<strong>SONODE</strong>，似乎是2020ICML的文章但是我没有搜到…</p></blockquote><a id="more"></a><img src="/2020/10/19/【论文阅读24】On-Second-Order-Behaviour-in-ANODE——真二阶NODE/2nd-NODE-1.png" title="文献预览"><p>文献链接：<a href="https://arxiv.org/abs/2006.07220" target="_blank" rel="noopener">https://arxiv.org/abs/2006.07220</a></p><p><code>SONODE</code>是非常新的一篇文章，发布于2020/06，是剑桥的人写的。该文是一个非常理论的东西，基本上是基于ANODE、NODE，附录有好多证明，现在还是啃不动，只能啃一些浅层的东西，记录于此</p><h1 id="Hook——a-simple-comparison"><a href="#Hook——a-simple-comparison" class="headerlink" title="Hook——a simple comparison"></a>Hook——a simple comparison</h1><p>之前写过一篇比较ODE2VAE和ANODE文章的比较，大概意思是说ODE2VAE中对二阶导的建模本质上可以看成ANODE在维度上进行增广的一个特例。而本文<code>SONODE</code>是我读的一篇关于ANODE<strong>对2阶导处理</strong>的文章，可以看成是两个NODE在ANODE的框架下套娃，而且比较理论了，基于原始NODE的理论进行了拓展，不过更多地和ANODE进行比较</p><p>笔记写得差不多了，这里再补上一些比较，原文认为SONODE不错的一个原因是它更多地考虑了实际ODE，模型的动力性质，对物理过程的描述更好一些。不过我觉得也就是多建模了一个二阶导啊，只是结合了增广维度的思想，建模的过程也没有那么物理…</p><h1 id="Why-SONODE？——背景"><a href="#Why-SONODE？——背景" class="headerlink" title="Why SONODE？——背景"></a>Why SONODE？——背景</h1><p>话不多说，直接上背景</p><p>背景之一是基于NODE、ANODE，这类模型非常不错，就是奔着描述连续动力系统去的，未来应用一定大好👍；背景之二是之前这些模型只讨论了一阶的性质，缺乏对ODE二阶导的讨论，这也是我在关注的</p><p>所以本文的idea很朴素，就是<font color="#0000FF">顺着ANODE推广到2阶导</font>的情形，就成为SONODE模型。不过idea朴素，方法却比较复杂，本文顺着NODE推广了它的<code>adjoint sensitivity</code>方法，这个尤其复杂，都在附录里我就不看了嘻嘻。另外，本文在得到SONODE之后做了大量实验，<font color="#0000FF">探究了许多对ANODE和SONODE的理解与比较</font>，这些东西内容满满啊！</p><h1 id="What’s-SONODE——实现方法"><a href="#What’s-SONODE——实现方法" class="headerlink" title="What’s SONODE——实现方法"></a>What’s SONODE——实现方法</h1><p>先回顾一下在NODE上做了维度增广的ANODE：</p><script type="math/tex; mode=display">\displaystyle \dfrac{d}{dt}\begin{bmatrix} \textbf{h}(t) \\ \textbf{a}(t) \end{bmatrix} = f(\begin{bmatrix} \textbf{h}(t) \\ \textbf{a}(t) \end{bmatrix}, t),\ \begin{bmatrix} \textbf{h}(t_0) \\ \textbf{a}(t_0) \end{bmatrix} = \begin{bmatrix} \textbf{h}(0) \\ \textbf{a}(0) \end{bmatrix} \triangleq \begin{bmatrix} \textbf{x} \\ \textbf{0} \end{bmatrix}</script><p>2阶NODE的建模考虑到了要拟合二阶导，SONODE就是这样一个非常暴力直观的想法，直接对二阶导建模（联想之前ODE2VAE利用贝叶斯神经网络来学习之），如下所示：</p><script type="math/tex; mode=display">\mathbf{h}^{\prime\prime} = \mathbf{f}^{(a)}(\mathbf{h}, \mathbf{h}^{\prime}, t, \theta_\mathbf{f}),\ where\ \mathbf{h}(t_0) = \mathbf{H}_0,\ \mathbf{h}^{\prime}(t_0) = \mathbf{g}(\mathbf{h}(t_0), \theta_\mathbf{g}) \tag{1}</script><p>其中上标 $(a)$ 表示这个网络函数 $\mathbf{f}$ 相当于是拟合加速度的函数。原始函数初值 $\mathbf{h}(t_0)$ 和一阶导初值 $\mathbf{h}^{\prime}(t_0)$ 都给定了</p><p>而这个暴力的建模方式相当于把ANODE的增广维度设置成一阶导 $\mathbf{h}^\prime(t)$ ：</p><script type="math/tex; mode=display">\displaystyle \mathbf{z} = \begin{bmatrix} \textbf{h}(t) \\ \textbf{h}^\prime(t) \end{bmatrix},\ \mathbf{z}^\prime = \dfrac{d}{dt}\begin{bmatrix} \textbf{h}(t) \\ \textbf{h}^\prime(t) \end{bmatrix} = \mathbf{f}^{(v)}(\begin{bmatrix} \textbf{h}(t) \\ \textbf{h}^\prime(t) \end{bmatrix}, t, \theta_\mathbf{f}) = \begin{bmatrix} \textbf{h}^\prime(t) \\ \mathbf{f}^{(a)}(\mathbf{h}, \mathbf{h}^{\prime}, t, \theta_\mathbf{f}) \end{bmatrix},\ where\ IV\ is\ \mathbf{z}(t_0) = \begin{bmatrix} \mathbf{H}_0 \\ \mathbf{g}(\mathbf{h}(t_0), \theta_\mathbf{g}) \end{bmatrix}\tag{2}</script><p>如上所示， $(1)$ 式和 $(2)$ 式形式上其实是一样的，即<font color="#0000FF">对二阶导的暴力建模 $\Leftrightarrow$ 两个NODE以ANODE的方式嵌套</font>！</p><h1 id="Theory-of-SONODE——NODE理论延拓"><a href="#Theory-of-SONODE——NODE理论延拓" class="headerlink" title="Theory of SONODE——NODE理论延拓"></a>Theory of SONODE——NODE理论延拓</h1><p>这个主要是NODE中<code>adjoint method</code>的延拓了。由于SONODE可以看作两个NODE在ANODE的框架下套娃，那么作者就考虑了一阶<code>adjoint method</code>延拓成二阶，进而辅助网络的训练</p><p>式子为原文命题 $(3.1)$ 但是我真心不想看证明估计也看不太明白…</p><p>进一步，原文给出了这个<code>adjoint method</code>的计算性质比较，即原文命题 $(3.2)$ ，说的是计算复杂度的问题，只用两组一阶<code>adjoint method</code>计算要优于用二阶的<code>adjoint method</code>，后者应该是需要更多的矩阵乘法运算。因此，文中的实验都是准备用两组一阶<code>adjoint method</code>来计算的</p><h1 id="How-to-Use-SONODE——Experiments"><a href="#How-to-Use-SONODE——Experiments" class="headerlink" title="How to Use SONODE——Experiments"></a>How to Use SONODE——Experiments</h1><p>这篇文章做了很多实验，我稍微整理了一下，前三个主要是为了说明SONODE的基本性质；第4个是为了说明SONODE和ANODE二阶性质的比较；后面的是为了进一步以困难数据说明二者二阶性质的比较：</p><div class="table-container"><table><thead><tr><th>实验名称</th><th>实验简介</th><th>实验结果</th></tr></thead><tbody><tr><td>Generalised Parity Problems</td><td>是原来NODE提到的相图不交问题的高维推广——高维初值问题</td><td>ANODE没能学到最一般的轨迹；SONODE学到了（结果如此但我不太明白）</td></tr><tr><td>Nested N-Spheres</td><td>似乎是两个N维球面嵌套的分离问题，并在流（轨）形（迹）意义下讨论</td><td>NODE不能在<strong>原来</strong>的实空间中分离轨迹；ANODE在增广的维度上分离了轨迹；SONODE在实空间中就做到了轨迹分（相）离（交）（不太明白原理），并提出了命题 $(3.3)$ ，SONODE不被限制在实空间上的同胚变换，毕竟实空间上就成功做到相图相交了</td></tr><tr><td>2 Damped Harmonic Oscillators</td><td>即2个衰减简谐振动轨迹的学习</td><td>只是说明了，ANODE扩充维度不用超过原来实空间维度，也能学到一定的二阶性质</td></tr><tr><td>Interpretability of ANODES</td><td>对一些较不规则螺旋线进行学习</td><td>SONODE和ANODE在该问题上的表现为：ANODE在不同初始化条件下结果不同，其实空间上轨迹一致，但增广维度上轨迹不同（有点迷）；SONODE轨迹始终一致。这说明ANODE的二阶导学习得还是可能有问题，<strong>可能</strong>不适合实际问题的应用。更进一步的结果是，原文提出命题 $(5.2, 5.3)$ ，表示ANODE可学习的非平凡二阶导形式是无限的，SONODE的则是唯一的（这么强的么？👍）</td></tr><tr><td>Noise Robustness</td><td>对 $\sin$ 函数加不同水平高斯噪声</td><td>图7的结果表示SONODE更稳健</td></tr><tr><td>Real-world Dynamic Systems</td><td>实际数据</td><td>不太明白，反正看图猛就完了</td></tr></tbody></table></div><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><p>写到这里总觉得文章哪里不太对劲，先这样吧，说不定用到的时候就明白了。</p><div class="table-container"><table><thead><tr><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>本文的idea很正统，基于ANODE研究2阶性质，不仅给出了adjoint方法的延拓，还与双ANODE联系在一起</td><td>此类方法由于应用非常直接，确实很容易用于不好的用途。。这个问题挺人文的，我还是希望人类能和平发展技术。。</td></tr><tr><td>理论的保证还是比较足了，主要是adjoint方法、以及确实是在对<strong>真正</strong>的二阶导建模</td><td>文中提到了一手ANODE增广的维度可能发生混乱，是指学到的东西没有可解释性么，这个只提了几句没讲清楚</td></tr><tr><td>对比ANODE的实验做得很多，确实让我们看到了建模二阶导带来的优势</td><td>二阶导adjoint方法推导似乎就比较复杂，那高阶推导难道要一直嵌套么？这不是我们想要的</td></tr><tr><td>此一类方法的潜力都很好，应用场景必然很多，且已经出现！本文二阶方法则尤其适合存在加速度的场景</td><td>TBD</td></tr></tbody></table></div><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>[1] Alexander Norcliffe, Cristian Bodnar, Ben Day, Nikola Simidjievski, and Pietro Liò. On second order behaviour in augmented neural odes. arXiv preprint arXiv:2006.07220, 2020.</p><p>[2] Emilien Dupont, Arnaud Doucet, and Yee Whye Teh. Augmented neural odes. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3140–3150. Curran Associates, Inc., 2019.</p><p>[3] Cagatay Yildiz, Markus Heinonen, and Harri Lahdesmaki. Ode2vae: Deep generative second order odes with bayesian neural networks. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 13412–13421. Curran Associates, Inc., 2019.</p><p>[4] Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt and David Duvenaud. Neural Ordinary Differential Equations[EB/OL]. <a href="https://arxiv.org/abs/1806.07366" target="_blank" rel="noopener">https://arxiv.org/abs/1806.07366</a>, 2018.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;On Second Order Behaviour in Augmented Neural ODEs&lt;/code&gt;，简称&lt;strong&gt;SONODE&lt;/strong&gt;，似乎是2020ICML的文章但是我没有搜到…&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读23】CLNN——用于图像分类的跨层神经元+CNN</title>
    <link href="http://maxliu245.github.io/2020/10/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB23%E3%80%91CLNN%E2%80%94%E2%80%94%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84%E8%B7%A8%E5%B1%82%E7%A5%9E%E7%BB%8F%E5%85%83-CNN/"/>
    <id>http://maxliu245.github.io/2020/10/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB23%E3%80%91CLNN%E2%80%94%E2%80%94%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%9A%84%E8%B7%A8%E5%B1%82%E7%A5%9E%E7%BB%8F%E5%85%83-CNN/</id>
    <published>2020-10-19T01:52:25.000Z</published>
    <updated>2020-10-19T03:45:37.921Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文是我对18年Information Sciences上一篇讲网络跨层文章CLNN的理解：</p><p><code>Convolutional networks with cross-layer neurons for image recognition</code></p></blockquote><a id="more"></a><img src="/2020/10/19/【论文阅读23】CLNN——用于图像分类的跨层神经元-CNN/CLNN-1.png" title="文献预览"><p>文献链接：<a href="https://www.sciencedirect.com/science/article/pii/S0020025517311659" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0020025517311659</a></p><p>这篇文章是18年的sci一区文章，引用量似乎惨淡…这篇文章在DenseNet，等文章之后。文章的一个操作是认为自己首先提出了cross-layer的思想，而之前的只能叫做cross-line，这个概念先码在这里。</p><h1 id="Why-跨层？——CLNN背景"><a href="#Why-跨层？——CLNN背景" class="headerlink" title="Why 跨层？——CLNN背景"></a>Why 跨层？——CLNN背景</h1><p>本文的标题很明确，是针对图像分类识别问题去的，文章的思想来源也和该问题有关，且idea很简单，只是后面操作联想到了不同的知识。</p><p>背景之一是深层CNN确实表现可以，在18年那个时候能良好完成各种图像任务，包括ImageNet等；背景之二是深层CNN的训练比较难，确实，堆叠卷积层太多了会出点问题也是正常的吧（我现在不知道除了参数多，训练可能有梯度上的问题之外还有啥显著缺点）。</p><p>针对图像任务的话，本文的idea顺着深层CNN出来了，以文中图2为例非常好理解，CNN的底层提取的多是图像上的直观纹理特征，比较基础，高层提取的是抽象的高级特征，但是很抽象。这些与人的视觉感官类似，但是人一眼看到一张图片，需要放大图像中的细节，还是依据图像中的纹理等特征来判断图像中到底是什么。因此<font color="#0000FF">深层CNN应当要好好利用这些底层的基础特征</font>。但是显然不行，CNN过深之后，前面浅层的特征（信息）很多其实被<strong>浪费</strong>或者说逐渐消散了。</p><p>这就是文章要<font color="#0000FF">考虑跨层的一个原因</font>。</p><h1 id="How-跨层？——CLNN实现方法"><a href="#How-跨层？——CLNN实现方法" class="headerlink" title="How 跨层？——CLNN实现方法"></a>How 跨层？——CLNN实现方法</h1><p>那么它提出的是什么样的网络结构呢？这个感觉真的很难写出来，所以下面还是要放文章的图。</p><p>首先，文章中提到了4个重要的概念：cross-line，cross-layer neuron（=cross-line neuron），cross-layer block和connection layer。由于我不知道怎么在Hexo平台上并排插入图片，所以只好分开介绍了。</p><h2 id="cross-line"><a href="#cross-line" class="headerlink" title="cross-line"></a>cross-line</h2><p>据本文阐述，之前的跨层文章都是cross-line的思想，即网络层层之间连接一下，只是指这么个连接的操作来传递信息，一般通过一个卷积就行。</p><p>注意不是相邻层的连接（本来就有的），而是至少中间隔两层的跨连接。具体的定义在文章的定义1，不过文章的定义稍有些晦涩，其实没那么复杂，只是定义起来要晦涩一点。</p><h2 id="cross-layer-neuron-amp-cross-layer-block"><a href="#cross-layer-neuron-amp-cross-layer-block" class="headerlink" title="cross-layer neuron &amp; cross-layer block"></a>cross-layer neuron &amp; cross-layer block</h2><img src="/2020/10/19/【论文阅读23】CLNN——用于图像分类的跨层神经元-CNN/CLNN-2.png" title="cross-layer neuron"><p>上图其实不是是cross-layer neuron的结构图，而是cross-layer block的结构图啊，后者作为一个模块，<font color="#0000FF">是这个跨连接一堆的整体</font>，目的是把底层的信息传到高层去，实现的手段是在普通的卷积层之间添加了cross-line，并把输入给merge一下。前者在图中只表现为一个小小的neuron，其实没啥，是指这个cross-layer的操作存在就可以了。具体的定义在文章的定义2。</p><p>这个merge的对象是cross-layer neuron的主（原）输入和各层跨连接得到的需要传递给顶（高）层的输入。方式有三种，保持维度后直接相加、保持维度后加权相加、跨连接的所有输出相加后再保持维度并与cross-layer neuron的主（原）输入直接合起来做维度扩充。文中为方便采用了第一种。</p><blockquote><p>我的一个疑惑，直接相加有用么，能保持底层信息么？举个例子，一堆底层的纹理加在一块是个啥？</p></blockquote><h2 id="connection-layer"><a href="#connection-layer" class="headerlink" title="connection-layer"></a>connection-layer</h2><img src="/2020/10/19/【论文阅读23】CLNN——用于图像分类的跨层神经元-CNN/CLNN-3.png" title="connection-layer"><p>上图是connection-layer，它的作用是连接两个cross-layer block，中间有两条向高层传递信息的通道，表示两条flow，这也是为什么我在tags中加了流模型的原因，文章还有有这么个流模型的考虑的。</p><blockquote><p>ps：我觉得这个connection只是表现在两条flow的连接，分开的话可以看成是两个block</p></blockquote><p>其中每一条flow都有两层卷积，包括一次stride操作来下采样。这样就导致了上图的三种结构。</p><p>而这个connection-layer其实你看啊，边上有个恒等映射作为cross-line，中间为两层，所以也是个cross-layer neuron，最后有个merge的操作，采用的是第一种。</p><h2 id="cross-layer-block和connection-layer的连接"><a href="#cross-layer-block和connection-layer的连接" class="headerlink" title="cross-layer block和connection-layer的连接"></a>cross-layer block和connection-layer的连接</h2><img src="/2020/10/19/【论文阅读23】CLNN——用于图像分类的跨层神经元-CNN/CLNN-4.png" title="cross-layer"><p>这个就是整体的网络模型了，把多个block和多个connection-layer组合起来，形成文章的最终模型<strong>CLNN</strong>！</p><p>连接的方式有两种，左边是直接顺序连接，先一堆（图中只有一个我觉得一堆也行）block再最后来个连接层；右边是调整了连接顺序，并不是直接一条路走到头了，把block中的neurons分别都连到最后的连接层上。</p><p>说实话我不明白为什么就可以这样做，道理只是这个信息merge传递的idea和实验验证么？</p><h1 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h1><p>写到这里总觉得文章哪里不太对劲，先这样吧，说不定用到的时候就明白了。</p><div class="table-container"><table><thead><tr><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>idea还是不错的，跨层的花样+++（模型名字CLNN也不错）</td><td>我个人觉得除了实验验证少了什么</td></tr><tr><td>把底层信息多次传到高层，缓解了底层特征的浪费（消散）问题✔</td><td>跨层操作还是不少的，这样的多次利用可不可以精简？</td></tr><tr><td>分类任务的收敛速度加快（如何通过梯度加速还没明白），通过实验验证</td><td>merge特征（信息）的方式有用么？见上文我的疑惑</td></tr><tr><td>某种程度上CLNN也是训练深度CNN的方法</td><td>TBD</td></tr><tr><td>首次提出cross-layer？不清楚，不过确实连接方式丰富了</td><td></td></tr><tr><td>文章说梯度消失也缓和了，暂时我没啥头绪…</td></tr></tbody></table></div><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>[1] Zeng Yu, Tianrui Li, Guangchun Luo, Hamido Fujita, Ning Yu, and Yi Pan. Convolutional networks with cross-layer neurons for image recognition. Information Sciences, 433-434:241 – 254, 2018.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是我对18年Information Sciences上一篇讲网络跨层文章CLNN的理解：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Convolutional networks with cross-layer neurons for image recognition&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="CNN" scheme="http://maxliu245.github.io/tags/CNN/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【NBA2K13】掘金重新制作</title>
    <link href="http://maxliu245.github.io/2020/10/01/%E3%80%90NBA2K13%E3%80%91%E6%8E%98%E9%87%91%E9%87%8D%E6%96%B0%E5%88%B6%E4%BD%9C/"/>
    <id>http://maxliu245.github.io/2020/10/01/%E3%80%90NBA2K13%E3%80%91%E6%8E%98%E9%87%91%E9%87%8D%E6%96%B0%E5%88%B6%E4%BD%9C/</id>
    <published>2020-10-01T03:02:41.000Z</published>
    <updated>2020-10-01T14:14:07.316Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>真正的大佬一看就知道我弄的东西很菜…</p><p>但是小白也不会看得懂我在干啥…</p><p>😂</p></blockquote><a id="more"></a><p>前几周其实学到了新的修改技术，目前已经能够在不破坏原来球员名字database的基础上添加新的名字了，也就是说，<strong>可以添加任意长度的球员名字啦</strong>！</p><p>另外，对个人来说，添加面补现在也能做到不替换原始球员的面补啦！</p><p>基于此，决定重新制作2020版的数据包~从掘金开始</p><h1 id="基本数据"><a href="#基本数据" class="headerlink" title="基本数据"></a>基本数据</h1><h2 id="年龄身高设置"><a href="#年龄身高设置" class="headerlink" title="年龄身高设置"></a>年龄身高设置</h2><div class="table-container"><table><thead><tr><th>年龄</th><th>20</th><th>21</th><th>22</th><th>23</th><th>24</th><th>25</th><th>26</th><th>27</th><th>28</th><th>29</th><th>30</th><th>31</th><th>32</th><th>33</th><th>34</th></tr></thead><tbody><tr><td></td><td>8b 7c</td><td>76 7c</td><td>62 7c</td><td>5c 7c</td><td>4b 7c</td><td>35 7c</td><td>28 7c</td><td>1d 7c</td><td></td><td>f6 7b</td><td>e2 7b</td><td></td><td>c9 7b</td><td>b9 7b</td><td>a3 7b</td></tr><tr><td>身高</td><td>6‘1’</td><td>6’2’</td><td>6’3’</td><td>6’4’</td><td>6’5’</td><td>6‘6’</td><td>6‘7’</td><td>6’8’</td><td>6’9’</td><td>6’10’</td><td>6’11’</td><td>7’0’</td><td>7‘1’</td><td>7’2’</td><td>7‘3’</td></tr><tr><td></td><td>187.96</td><td>188？</td><td>190.5</td><td>193.5</td><td>195.58</td><td>198.12</td><td>200.66</td><td>205.8</td><td>206</td><td>208.28</td><td>？</td><td>215.9</td><td>216?</td><td>218.44</td><td>221</td></tr></tbody></table></div><h2 id="上场时间设置"><a href="#上场时间设置" class="headerlink" title="上场时间设置"></a>上场时间设置</h2><p>优先按stat-nba网站提供的2019-2020赛季常规赛时间，未声明即是。</p><p>会适当根据季后赛上场时间数据调整。</p><h2 id="球员名单设置"><a href="#球员名单设置" class="headerlink" title="球员名单设置"></a>球员名单设置</h2><div class="table-container"><table><thead><tr><th>PG</th><th>SG</th><th>SF</th><th>PF</th><th>C</th></tr></thead><tbody><tr><td><a href="https://www.2kratings.com/jamal-murray" target="_blank" rel="noopener">Jamal Murray</a>/Ty Lawson（你没了）/SG</td><td><a href="https://www.2kratings.com/gary-harris" target="_blank" rel="noopener">Gary Harris</a></td><td><a href="http://www.espn.com/nba/player/_/id/4278104/michael-porter-jr" target="_blank" rel="noopener">Michael Porter Jr.</a>/Jordan Hamilton</td><td><a href="https://www.2kratings.com/paul-millsap" target="_blank" rel="noopener">Paul Millsap</a></td><td><a href="https://www.2kratings.com/nikola-jokic" target="_blank" rel="noopener">Nikola Jokic</a>/Timofey Mozgov</td></tr><tr><td><strong><a href="https://www.2kratings.com/monte-morris" target="_blank" rel="noopener">Monte Morris</a></strong>/Andre Miller</td><td><a href="https://www.2kratings.com/torrey-craig" target="_blank" rel="noopener">Torrey Craig</a></td><td><a href="https://www.2kratings.com/will-barton" target="_blank" rel="noopener">Will Barton</a></td><td><a href="https://www.2kratings.com/jerami-grant" target="_blank" rel="noopener">Jerami Grant</a>/Anthony Randolph</td><td><a href="https://www.2kratings.com/mason-plumlee" target="_blank" rel="noopener">Mason Plumlee</a>/Kosta Koufos</td></tr><tr><td></td><td></td><td></td><td></td><td><a href="https://www.2kratings.com/bol-bol" target="_blank" rel="noopener">Bol Bol</a></td></tr></tbody></table></div><h2 id="名字代码添加"><a href="#名字代码添加" class="headerlink" title="名字代码添加"></a>名字代码添加</h2><div class="table-container"><table><thead><tr><th>name</th><th>hex</th><th>address</th><th>dec</th></tr></thead><tbody><tr><td>Nikola</td><td>4e696b6f6c61</td><td>17a82e</td><td>1550382</td></tr><tr><td>Jokic</td><td>4a6f6b6963</td><td>1795f8</td><td>1545720</td></tr><tr><td>Jamal</td><td>4a616d616c</td><td>179e94</td><td>1547924</td></tr><tr><td>Murray</td><td>4d7572726179</td><td>182710</td><td>1582864</td></tr><tr><td>Michael</td><td>4d69636861656c</td><td>1797a6</td><td>1546150</td></tr><tr><td>Porter Jr.</td><td>506f72746572204a722e</td><td>1795e2</td><td>1545698</td></tr><tr><td>Monte</td><td>4d6f6e7465</td><td>18a314</td><td>1614612</td></tr><tr><td>Morris</td><td>4d6f72726973</td><td>17a750</td><td>1550160</td></tr><tr><td>Mason</td><td>4d61736f6e</td><td>17a354</td><td>1549140</td></tr><tr><td>Plumlee</td><td>506c756d6c6565</td><td>17ac5e</td><td>1551454</td></tr><tr><td>Gary</td><td>47617279</td><td>17af3e</td><td>1552190</td></tr><tr><td>Harris</td><td>486172726973</td><td>179a26</td><td>1546790</td></tr><tr><td>Bol</td><td>426f6c</td><td>1795da</td><td>1545690</td></tr><tr><td>Will</td><td>57696c6c</td><td>17ad2c</td><td>1551660</td></tr><tr><td>Barton</td><td>426172746f6e</td><td>1795cc</td><td>1545676</td></tr><tr><td>Jerami</td><td>4a6572616d69</td><td>1795be</td><td>1545662</td></tr><tr><td>Grant</td><td>4772616e74</td><td>179eaa</td><td>1547946</td></tr></tbody></table></div><h1 id="Nikola-Jokic"><a href="#Nikola-Jokic" class="headerlink" title="Nikola Jokic"></a>Nikola Jokic</h1><p>队内Timofey Mozgov</p><p>Nikola 1550382</p><p>Jokic 1545720</p><p>Timofey 17ab1c 1551132 和目标差-750</p><p>Mozgov 17ab0e 1551118 和目标差-5398</p><p>203e4位置有个2b a7 15 00 —双字15a72b—-1419051——-&gt;-5398——&gt;1413653—&gt;159215</p><p>203e8位置有个35 a7 15 00 —双字15a735—-1419061——-&gt;-750——&gt;1418311—&gt;15a447</p><p>原面补49 07=1865</p><p>新面补2901=55 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>7‘0’=215.8999</td><td>253</td><td>55 0b</td><td>C</td><td>05</td><td>2020季后赛36.5=146=92</td><td></td><td>15-&gt;30-&gt;1e</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>/</th><th>KM405</th><th>91—&gt;88</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td>20580</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  62</td><td>2 med  54</td><td>3 3pt  4f</td><td>4 ft 52</td><td>5 layup  46</td><td>6 dunk  55</td><td>28 stdnk  5b</td><td>23  sit 56</td><td>22 sod 56</td><td>25 hus  47</td></tr><tr><td>7 hndl  41</td><td>8  pass 50</td><td>32</td><td>40</td><td>9 opost  5f</td><td>10 dpost  58</td><td>11 block   3a</td><td>26 hnd  57</td><td>12 steal  36</td><td>15 speed  41</td><td>16 stam  61</td><td>4b</td><td>21 vert 60</td><td>13 oreb  4f</td><td>14 dreb  59</td><td>17 dur  50</td></tr><tr><td><strong>18 dawr</strong>  3c</td><td><strong>19  oawr</strong>  62</td><td>19</td><td>50</td><td>27 def 50</td><td>24 qui 5c</td><td>潜力 5c</td><td>20 str 40</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h1 id="Jamal-Murray"><a href="#Jamal-Murray" class="headerlink" title="Jamal Murray"></a>Jamal Murray</h1><p>Ty Lawson</p><p>Jamal 1547924</p><p>Murray 182710</p><p>Ty 17aaa0 1551008 和目标差-3084</p><p>Lawson 17aa92 1550994 和目标差+31870</p><p>1fc64位置有个2f ae 15 00 —双字15ae2f—-1420847——-&gt;+31870——&gt;1452717—&gt;162aad</p><p>1fc68位置有个39 ae 15 00 —双字15ae39—-1420857——-&gt;-3084——&gt;1417773—&gt;15a22d</p><p>原面补4f 06=1615，用2902=56 0b</p><p>原来405改出来是6‘3’和82，再想办法加强一点。三分改成84</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘4’=用193—&gt;193.5吧</td><td>207</td><td>56 0b</td><td>PG/SG</td><td>04</td><td>2020季后赛39.6=158.4=9e</td><td></td><td>27—&gt;54—&gt;36</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>/</th><th>KM405</th><th>84—&gt;82</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td>1fe00</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  5b</td><td>2 med  50—&gt;57</td><td>3 3pt  50—&gt;54</td><td>4 ft 5c</td><td>5 layup  52</td><td>6 dunk  3c</td><td>28 stdnk  3f</td><td>23  sit 3e</td><td>22 sod 3b</td><td>25 hus  42</td></tr><tr><td>7 hndl  58</td><td>8  pass 53</td><td>3c</td><td>32</td><td>9 opost  4b</td><td>10 dpost  46</td><td>11 block   3f</td><td>26 hnd  3c</td><td>12 steal  3b</td><td>15 speed  4f</td><td>16 stam  5a</td><td>3c</td><td>21 vert 3c</td><td>13 oreb  3d</td><td>14 dreb  3f</td><td>17 dur  3c</td></tr><tr><td><strong>18 dawr</strong>  4d</td><td><strong>19  oawr</strong>  53</td><td>46</td><td>5b</td><td>27 def 32</td><td>24 qui 4f</td><td>潜力 56</td><td>20 str 42</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><p>ps:26岁=28 7c，6‘1’=187.96</p><h1 id="Michael-Porter-Jr"><a href="#Michael-Porter-Jr" class="headerlink" title="Michael Porter Jr."></a>Michael Porter Jr.</h1><p>用本队Jordan Hamilton，两个名字都是继承的</p><p>Michael 1546150</p><p>Porter Jr. 1545698</p><p>Jordan 179e4a 1547850 实际上是179e4e 1547854 和目标差-1704 4a6f7264616e</p><p>Hamilton 179a5c 1546844 和目标差-1146 48616d696c746f6e</p><p>212e4位置有个79 87 15 00 —双字158779—-1410937——-&gt;-1146——&gt;1409791—&gt;1582ff</p><p>212e8位置有个67 8b 15 00 —双字158b67—-1411943——-&gt;-1704——&gt;1410239—&gt;1584bf</p><p>原面补6f 08=2159，用2903=57 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘10’用208.2799吧</td><td>209</td><td>2903=57 0b</td><td>SF/SG=02/01</td><td>04</td><td>2020季后赛23.7=94.8=5f</td><td></td><td>1—&gt;02</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>/</th><th>KM405</th><th>81</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td>21480</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  47</td><td>2 med  4f</td><td>3 3pt  57</td><td>4 ft 53</td><td>5 layup  54</td><td>6 dunk  4b</td><td>28 stdnk  3c</td><td>23  sit 48</td><td>22 sod 4c</td><td>25 hus  3e</td></tr><tr><td>7 hndl  4e</td><td>8  pass 41</td><td>32</td><td>32</td><td>9 opost  4b</td><td>10 dpost  4e</td><td>11 block   44</td><td>26 hnd  4f</td><td>12 steal  32</td><td>15 speed  52</td><td>16 stam  50</td><td>23</td><td>21 vert 58</td><td>13 oreb  42</td><td>14 dreb  54</td><td>17 dur  55</td></tr><tr><td><strong>18 dawr</strong>  42</td><td><strong>19  oawr</strong>  4d</td><td>28</td><td>50</td><td>27 def 47</td><td>24 qui 54</td><td>潜力 49</td><td>20 str 4f</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><p>26岁=22 7c，6‘7’=200.66</p><h1 id="米尔萨普"><a href="#米尔萨普" class="headerlink" title="米尔萨普"></a>米尔萨普</h1><p>63 05=1379</p><p>上场时间用stat的24.5=98=62，号码4-8</p><div class="table-container"><table><thead><tr><th>Jazz</th><th>KM405</th><th>82—&gt;</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td>15ae0</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  42</td><td>2 med  52</td><td>3 3pt  55</td><td>4 ft 59</td><td>5 layup  4f</td><td>6 dunk  49</td><td>28 stdnk  57</td><td>23  sit 51</td><td>22 sod 36</td><td>25 hus  52</td></tr><tr><td>7 hndl  3b</td><td>8  pass 3d</td><td>32</td><td>32</td><td>9 opost  55</td><td>10 dpost  52</td><td>11 block   40</td><td>26 hnd  48</td><td>12 steal  32</td><td>15 speed  3d</td><td>16 stam  59</td><td>19</td><td>21 vert 42</td><td>13 oreb  42</td><td>14 dreb  44</td><td>17 dur  5f</td></tr><tr><td><strong>18 dawr</strong>  50</td><td><strong>19  oawr</strong>  4e</td><td>50</td><td>37</td><td>27 def 38</td><td>24 qui 36</td><td>潜力 50</td><td>20 str 49</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h1 id="Monte-Morris"><a href="#Monte-Morris" class="headerlink" title="Monte Morris"></a>Monte Morris</h1><p>Andre Miller，又他喵是继承的名字。</p><p>Monte 1614612</p><p>Morris 1550160</p><p>Andre 17aab8 1551032 差+63580</p><p>Miller 17a266 1548902 差+1258</p><p>20984位置有个e3 98 15 00 —双字1598e3—-1415395——-&gt;+1258——&gt;1416653—&gt;159dcd</p><p>20988位置有个31 a1 15 00 —双字15a131—-1417521——-&gt;+63580——&gt;1481101—&gt;16998d</p><p>原面补55 02=，用2906=5a 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘4’=用193—&gt;193.5吧</td><td>207</td><td>2906=5a 0b</td><td>PG/05</td><td>03</td><td>stat 21.6=86.6=57</td><td></td><td>27—&gt;54—&gt;36</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>/</th><th>KM405</th><th>78</th><th></th><th>20b20</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  44</td><td>2 med  59</td><td>3 3pt  54</td><td>4 ft 4e</td><td>5 layup  4f</td><td>6 dunk  26</td><td>28 stdnk  1e</td><td>23  sit 43</td><td>22 sod 4c</td><td>25 hus  46</td></tr><tr><td>7 hndl  56</td><td>8  pass 5a</td><td>32</td><td>32</td><td>9 opost  36</td><td>10 dpost  40</td><td>11 block   1e</td><td>26 hnd  52</td><td>12 steal  32</td><td>15 speed  55</td><td>16 stam  5e</td><td>19</td><td>21 vert 58</td><td>13 oreb  31</td><td>14 dreb  28</td><td>17 dur  48</td></tr><tr><td><strong>18 dawr</strong>  46</td><td><strong>19  oawr</strong>  4b</td><td>4b</td><td>54</td><td>27 def 49</td><td>24 qui 61</td><td>潜力 55</td><td>20 str 2a</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h1 id="Torrey-Craig"><a href="#Torrey-Craig" class="headerlink" title="Torrey Craig"></a>Torrey Craig</h1><p>KM405没这人…</p><h1 id="Jerami-Grant"><a href="#Jerami-Grant" class="headerlink" title="Jerami Grant"></a>Jerami Grant</h1><p>Anthony Randolph，全他喵是继承来的名字</p><p>Jerami 1545662</p><p>Grant 1547946</p><p>Anthony 416e74686f6e79 17a0a6 1548454 和目标差-2792（用别的名字找不到，咋弄。硬干，两名字之间地址差了1414163-1414463=300，第一次就找到了哈哈哈）</p><p>Randolph 179f76 1548150 和目标只差-204</p><p>20b64位置有个13 94 15 00 —双字159413—-1414163——-&gt;-204——&gt;1413959—&gt;159347</p><p>20b68位置有个3f 95 15 00 —双字15953f—-1414463——-&gt;-2792——&gt;1411671—&gt;158a57</p><p>原面补f0 05=1520，用2904=58 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘8’=205.74</td><td>210</td><td>2904=58 0b</td><td>PF=03/05</td><td>02</td><td>2020季后赛34.4=137.6=8a</td><td></td><td>9—&gt;18—&gt;12</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>/</th><th>KM最新</th><th>77</th><th></th><th>20d00</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  48</td><td>2 med  46</td><td>3 3pt  53</td><td>4 ft 46</td><td>5 layup  55</td><td>6 dunk  50</td><td>28 stdnk  5a</td><td>23  sit 4d</td><td>22 sod 4e</td><td>25 hus  57</td></tr><tr><td>7 hndl  3c</td><td>8  pass 3c</td><td>32</td><td>32</td><td>9 opost  46</td><td>10 dpost  48</td><td>11 block   47</td><td>26 hnd  3d</td><td>12 steal  32</td><td>15 speed  49</td><td>16 stam  63</td><td>19</td><td>21 vert 50</td><td>13 oreb  4b</td><td>14 dreb  4c</td><td>17 dur  3e</td></tr><tr><td><strong>18 dawr</strong>  46</td><td><strong>19  oawr</strong>  45</td><td>2d</td><td>58</td><td>27 def 4a</td><td>24 qui 4c</td><td>潜力 55</td><td>20 str 38</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><p>ps:23岁=5b 7c，6‘7’=200.66</p><h1 id="Bol-Bol"><a href="#Bol-Bol" class="headerlink" title="Bol Bol"></a>Bol Bol</h1><p>Free Hamady N’diaye</p><p>Bol 1545690</p><p>Bol 1545690</p><p>Hamady 181f66 1580902 差-35212</p><p>N’diaye 181f56 1580886 差-35196</p><p>7b104位置有个53 6e 10 00 —双字106e53—-1076819——-&gt;-35196——&gt;1041623—&gt;0fe4d7</p><p>7b108位置有个5f 6e 10 00 —双字106e5f—-1076831——&gt;-35212——&gt;1041619—&gt;0fe4d3</p><p>原面补40 07=，用2909=5d 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>7‘2’=218.44</td><td>207</td><td>2909=5d 0b</td><td>C</td><td>00</td><td>2020季后赛5.3=21.2=15</td><td></td><td>10—&gt;20—&gt;14</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th></th><th>KM405</th><th>73</th><th></th><th>7b2a0</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  4e</td><td>2 med  4f</td><td>3 3pt  4d</td><td>4 ft 4b</td><td>5 layup  40</td><td>6 dunk  3c</td><td>28 stdnk  32</td><td>23  sit 44</td><td>22 sod 4a</td><td>25 hus  46</td></tr><tr><td>7 hndl  43</td><td>8  pass 1b</td><td>32</td><td>32</td><td>9 opost  3c</td><td>10 dpost  3d</td><td>11 block   56</td><td>26 hnd  54</td><td>12 steal  21</td><td>15 speed  46</td><td>16 stam  5f</td><td>19</td><td>21 vert 46</td><td>13 oreb  43</td><td>14 dreb  54</td><td>17 dur  55</td></tr><tr><td><strong>18 dawr</strong>  40</td><td><strong>19  oawr</strong>  46</td><td>19</td><td>50</td><td>27 def 4d</td><td>24 qui 57</td><td>潜力 3c</td><td>20 str 37</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h1 id="Will-Barton"><a href="#Will-Barton" class="headerlink" title="Will Barton"></a>Will Barton</h1><p>Free球员 Mickael Pietrus</p><p>Will 1551660</p><p>Barton 1545676</p><p>Mickael 182006 1581062 差-29402</p><p>Pietrus 181ff6 1581046 差-35370</p><p>7bc44位置有个b3 63 10 00 —双字1063b3—-1074099——-&gt;-35370——&gt;1038729—&gt;0fd989</p><p>7bc48位置有个bf 63 10 00 —双字1063bf—-1074111——-&gt;-29402——&gt;1044709—&gt;0ff0e5</p><p>原面补ff 03=，用2908=5c 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘5’用196吧</td><td>175</td><td>2908=5c 0b</td><td>SF=02</td><td>02</td><td>stat 33.1=132.4=84</td><td></td><td>5—&gt;10—&gt;0a</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>/</th><th>KM405</th><th>80</th><th></th><th>7bde0</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  46</td><td>2 med  5c</td><td>3 3pt  52</td><td>4 ft 4b</td><td>5 layup  4b</td><td>6 dunk  3f</td><td>28 stdnk  3e</td><td>23  sit 39</td><td>22 sod 47</td><td>25 hus  46</td></tr><tr><td>7 hndl  4f</td><td>8  pass 4b</td><td>32</td><td>32</td><td>9 opost  3c</td><td>10 dpost  3c</td><td>11 block   35</td><td>26 hnd  50</td><td>12 steal  30</td><td>15 speed  4b</td><td>16 stam  58</td><td>63</td><td>21 vert 36</td><td>13 oreb  3c</td><td>14 dreb  3f</td><td>17 dur  49</td></tr><tr><td><strong>18 dawr</strong>  4b</td><td><strong>19  oawr</strong>  55</td><td>3c</td><td>4c</td><td>27 def 44</td><td>24 qui 52</td><td>潜力 4f</td><td>20 str 32</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><p>24岁=4b 7c，6‘8’=205.74</p><h1 id="Gary-Harris"><a href="#Gary-Harris" class="headerlink" title="Gary Harris"></a>Gary Harris</h1><p>Free球员 Manny Harris</p><p>Gary 1552190</p><p>Harris</p><p>Manny 4d616e6e79 181d3e=1580350，差了-28160</p><p>Harris 不动</p><p>77c84位置有个a3 1d 10 00 —双字101da3—-1056163——-&gt;0——&gt;0—&gt;0</p><p>77c88位置有个b7 a0 10 00 —双字10a0b7—-1089719——-&gt;-28160——&gt;1061559—&gt;1032b7</p><p>原面补70 07=，用2905=59 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘4’=用193—&gt;193.5吧</td><td>210</td><td>2905=59 0b</td><td>SG/05</td><td>04</td><td>stat 31.8=127.2=7f</td><td></td><td>14—&gt;28—&gt;1c</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>Free</th><th>KM405</th><th>76</th><th></th><th>77e20</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  35</td><td>2 med  56</td><td>3 3pt  4a</td><td>4 ft 53</td><td>5 layup  52</td><td>6 dunk  3e</td><td>28 stdnk  28</td><td>23  sit 3d</td><td>22 sod 3c</td><td>25 hus  53</td></tr><tr><td>7 hndl  4c</td><td>8  pass 4b</td><td>32</td><td>32</td><td>9 opost  49</td><td>10 dpost  48</td><td>11 block   22</td><td>26 hnd  49</td><td>12 steal  3f</td><td>15 speed  48</td><td>16 stam  55</td><td>19</td><td>21 vert 48</td><td>13 oreb  4f</td><td>14 dreb  46</td><td>17 dur  46</td></tr><tr><td><strong>18 dawr</strong>  50</td><td><strong>19  oawr</strong>  3c</td><td>19</td><td>50</td><td>27 def 32</td><td>24 qui 49</td><td>潜力 45</td><td>20 str 3a</td><td>？</td><td>？</td><td>？</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><h1 id="Mason-Plumlee"><a href="#Mason-Plumlee" class="headerlink" title="Mason Plumlee"></a>Mason Plumlee</h1><p>Kosta Koufos</p><p>Mason 1549140</p><p>Plumlee 1551454</p><p>Kosta 17ab80 1551232 差-2092</p><p>Koufos 17ab72 1551218 差+236</p><p>21104位置有个6f 9a 15 00 —双字159a6f—-1415791——-&gt;+236——&gt;1416027—&gt;159b5b</p><p>21108位置有个79 9a 15 00 —双字159a79—-1415801——&gt;-2092——&gt;1413709—&gt;15924d</p><p>原面补f9 05=，用2907=5b 0b</p><div class="table-container"><table><thead><tr><th>身高</th><th>体重</th><th>面补</th><th>位置</th><th>肤色</th><th>上场时间</th><th>年龄</th><th>号码</th><th></th></tr></thead><tbody><tr><td>6‘11’=210试试</td><td>235</td><td>2907=5b 0b</td><td>C</td><td>05</td><td>stat 17.0=68=44</td><td></td><td>7—&gt;14—&gt;e</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th></th><th>KM405</th><th>79</th><th></th><th>212a0</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>姓名地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>数据地址</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>00</strong></td><td><strong>01</strong></td><td><strong>02</strong></td><td><strong>03</strong></td><td><strong>04</strong></td><td><strong>05</strong></td><td><strong>06</strong></td><td><strong>07</strong></td><td><strong>08</strong></td><td><strong>09</strong></td><td><strong>0a</strong></td><td><strong>0b</strong></td><td><strong>0c</strong></td><td><strong>0d</strong></td><td><strong>0e</strong></td><td><strong>0f</strong></td></tr><tr><td><strong>0</strong></td><td>0</td><td>0</td><td>0</td><td>0</td><td>?</td><td>1 close  3c</td><td>2 med  4b</td><td>3 3pt  3a</td><td>4 ft 38</td><td>5 layup  4f</td><td>6 dunk  4c</td><td>28 stdnk  60</td><td>23  sit 4a</td><td>22 sod 37</td><td>25 hus  3a</td></tr><tr><td>7 hndl  33</td><td>8  pass 3b</td><td>32</td><td>32</td><td>9 opost  4b</td><td>10 dpost  4b</td><td>11 block   48</td><td>26 hnd  57</td><td>12 steal  38</td><td>15 speed  3b</td><td>16 stam  5b</td><td>19</td><td>21 vert 19</td><td>13 oreb  4d</td><td>14 dreb  54</td><td>17 dur  46</td></tr><tr><td><strong>18 dawr</strong>  4b</td><td><strong>19  oawr</strong>  50</td><td>19</td><td>48</td><td>27 def 26</td><td>24 qui 1c</td><td>潜力 3e</td><td>20 str 43</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;真正的大佬一看就知道我弄的东西很菜…&lt;/p&gt;
&lt;p&gt;但是小白也不会看得懂我在干啥…&lt;/p&gt;
&lt;p&gt;😂&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="NBA2K13" scheme="http://maxliu245.github.io/tags/NBA2K13/"/>
    
      <category term="DIY" scheme="http://maxliu245.github.io/tags/DIY/"/>
    
  </entry>
  
  <entry>
    <title>【Hexo3】博客置顶与搜索功能</title>
    <link href="http://maxliu245.github.io/2020/09/30/%E3%80%90Hexo3%E3%80%91%E5%8D%9A%E5%AE%A2%E7%BD%AE%E9%A1%B6%E4%B8%8E%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD/"/>
    <id>http://maxliu245.github.io/2020/09/30/%E3%80%90Hexo3%E3%80%91%E5%8D%9A%E5%AE%A2%E7%BD%AE%E9%A1%B6%E4%B8%8E%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD/</id>
    <published>2020-09-30T01:30:34.000Z</published>
    <updated>2020-09-30T01:52:43.059Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>记录一下添加功能的代码</p></blockquote><a id="more"></a><p>其实这些没啥干货，参考前端大佬们的分享即可，列出参考链接供以后不时之需</p><p>这次给自己的博客加了两个功能，置顶和站内搜索，均试验成功~</p><p>置顶代码包括包的安装和<code>post.swig</code>的代码添加（不过我的似乎自己加上了qwq），其中另外把置顶文字的颜色从紫色改成了深天蓝色🤭（颜色代码<code>00BFFF</code>）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-generator-index --save</span><br><span class="line">npm install hexo-generator-index-pin-top --save</span><br></pre></td></tr></table></figure><p>搜索的功能一样，注意要去<code>./themes/next/_config.yml</code>文件下开启搜索功能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure><p>参考链接：</p><ul><li><p><a href="http://wangwlj.com/about/" target="_blank" rel="noopener">王立杰</a>的博客<a href="http://wangwlj.com/2018/01/09/blog_pin_post/" target="_blank" rel="noopener">Hexo博客彻底解决置顶问题</a></p></li><li><p><a href="https://www.zhihu.com/people/huang-piao-72" target="_blank" rel="noopener">黄飘</a>的知乎文章<a href="https://zhuanlan.zhihu.com/p/55796365" target="_blank" rel="noopener">Hexo博客优化之Next主题功能强化</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;记录一下添加功能的代码&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Hexo" scheme="http://maxliu245.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读1】</title>
    <link href="http://maxliu245.github.io/2020/09/30/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB1%E3%80%91/"/>
    <id>http://maxliu245.github.io/2020/09/30/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB1%E3%80%91/</id>
    <published>2020-09-30T00:13:28.000Z</published>
    <updated>2020-12-12T07:06:51.030Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>此博客略读文献列表：</p><ol><li><p>Densely Connected Convolutional Networks（写完笔记之后觉得略读个🔨…）</p></li><li><p>Augmented Neural ODEs</p></li><li><p>Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs</p><blockquote><p>updated on 12th, Oct</p></blockquote></li><li><p>DelugeNets: Deep Networks with Efficient and Flexible Cross-layer Information Inflows（读得不太懂…）</p><blockquote><p>updated on 12th, Oct</p></blockquote></li><li><p>IDENT: Identifying Differential Equations with Numerical Time Evolution</p><blockquote><p>updated on 20th, Oct</p></blockquote></li></ol></blockquote><a id="more"></a><p>最近读文章有两个比较大的困惑，一个是速度很慢，因为读得相对还是有点细的，很多细节没怎么放过；另一个是效率的问题，即使做了一堆堆的笔记，也未必能把重点都表现出来，甚至还会混淆文章重点。</p><p>因此考虑锻炼自己的略读能力，不过略读论文毕竟不是读网络小说，看过不能随随便便丢掉。而觉得单开博客记录略读笔记有些浪费空间，所以决定开一些略读博客，把略读的笔记集中起来，方便日后查阅。</p><h1 id="Densely-Connected-Convolutional-Networks"><a href="#Densely-Connected-Convolutional-Networks" class="headerlink" title="Densely Connected Convolutional Networks"></a>Densely Connected Convolutional Networks</h1><p>读这篇文章是因为我希望了解一些网络跨层连接的知识。感觉这个文章关系很大也比较基础，就拿来了</p><img src="/2020/09/30/【论文略读1】/DenseNet-1.png" title="DenseNet"><h2 id="Why-DenseNet"><a href="#Why-DenseNet" class="headerlink" title="Why DenseNet?"></a>Why DenseNet?</h2><p>该网络跨层模型的背景是<code>CNN</code>若在输入输出两端之间有更短的连接时效果一般更好（没去找这个结论的出处），基于此，本文的初始目的应当是减小<code>CNN</code>网络中层与层之间的连接长度。</p><h2 id="What’s-and-How-DenseNet"><a href="#What’s-and-How-DenseNet" class="headerlink" title="What’s and How DenseNet?"></a>What’s and How DenseNet?</h2><p>这个<code>DenseNet</code>名称的来源是因为给<code>CNN</code>网络加了跨层连接，使得网络更加“<strong>密集连结</strong>”，因此就称为<code>DenseNet</code>了。注意这里<code>DenseNet</code>还是一个<code>CNN</code>的结构</p><p>而它的跨层也是<strong>真的</strong>进行了完全跨层，假设网络一共 $L$ 层，比如原文的图 $1$ 就是5层，输入和输出也各算一层。那么所有层与层之间的连接数（正向）有 $\displaystyle 1+2+\cdots+L = \dfrac{L(L+1)}{2}$，画个图自己连一下就推出来了</p><p>由于跨层连接是forward的，它并没有考虑反传，<code>DenseNet</code>考虑每个layer的输入都是前面所有layer输出的特征图的<strong>concatenating</strong>（这隐含了靠后layer输入可能维度大的问题），也就是说把前面所有的特征图都通通用上了😄</p><h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><p>这个是文章直接列的，我觉得都差不多，比较有道理，就也通通列出来：</p><ul><li><p>保持了CNN的结构，可以堆砌到一般网络中，好像有个Dense层的命令就是干这个的</p></li><li><p>真的是跨层连接啊，都是forward方向的，有加强特征前向传播的意思</p></li><li><p>跨层的方式是特征图的充（全）分（部）重复使用，这进一步有一些优点：</p><ul><li><p>特征图的充分利用，其实是保持了数据信息流的完整性</p></li><li><p>不用像其它模型每次训练都重新学习大量特征图导致网络的参数量减小，计算消耗减小</p><blockquote><p>Why？特征图该有还是有啊，网络还是那么多层，哪里参数不用学习了？</p></blockquote></li><li><p>特征图充分利用，可以看成是良好的特征提取器，方式包括特征图的reuse，恒等映射的使用，深度监督（最后的loss在每一层都对之前的特征图有梯度？我猜是这个意思）的使用，多样化的深度（我觉得是指跨层变相加深网络深度？）</p></li></ul></li><li><p>实验效果SOTA啊，且实验发现<code>DenseNet</code>参数量增加时，模型性能保持增加，没有出现明显的过拟合</p></li><li><p>缓解了梯度消失问题</p><blockquote><p>暂时没看出来在哪里…</p></blockquote></li></ul><p>最后ps一下，之前提到“靠后layer输入可能维度大”的问题，原文对此似乎有个操作，精心设计了一些结构，应该是通过每次下采样（原图图2）减小了特征图的深度，以及有一些 $1\times 1$ 卷积和pooling的操作，等等</p><h2 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h2><ul><li>堆叠特征图是不是有些冗余的感觉呢❓</li><li>有没有反向的跨层？不知道会不会有什么意义🙄</li><li>“保持了数据信息流的完整性”这个说法与流模型的建模有关联么🙊</li><li>直接通通跨层有些暴力，有没有后续工作做部分跨层的选择呢🤔</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">DenseNet</a>，<a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="noopener">Identity mappings</a></p><p>[1] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2261–2269, Los Alamitos, CA, USA, jul 2017. IEEE Computer Society.</p><p>[2] Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. ArXiv, abs/1603.05027, 2016.</p><h1 id="Augmented-Neural-ODEs"><a href="#Augmented-Neural-ODEs" class="headerlink" title="Augmented Neural ODEs"></a>Augmented Neural ODEs</h1><p><strong>这篇文章本来打算列为精读</strong>，但是一方面读了很久了，另一方面我能写的其实不多，所（偷）以（懒）就列为略读了。</p><p>文献链接：<a href="https://arxiv.org/abs/1904.01681v2" target="_blank" rel="noopener">https://arxiv.org/abs/1904.01681v2</a> 或 <a href="http://papers.nips.cc/paper/8577-augmented-neural-odes" target="_blank" rel="noopener">http://papers.nips.cc/paper/8577-augmented-neural-odes</a></p><img src="/2020/09/30/【论文略读1】/ANODE.png" title="ANODE"><h2 id="My-Marvelous-Confusion-solved"><a href="#My-Marvelous-Confusion-solved" class="headerlink" title="My Marvelous Confusion (solved)"></a>My Marvelous Confusion (solved)</h2><p>已经读了很久了，是因为有一个问题一直想不通，直到今天上午开始写总结才反应过来是怎么一回事😭。就是文章的<code>proposition 1</code>提出ODE的流，即原来的NODE函数不能描述这样的一个函数：</p><script type="math/tex; mode=display">\displaystyle \begin{equation} g(x)=\left\{ \begin{aligned} 1,\ x=-1\\ -1,\ x=1. \end{aligned} \right. \end{equation},\ where\ g(x):\mathbb{R}\rightarrow \mathbb{R}.</script><blockquote><p>ps: 这样的一个流函数希望把ODE $\displaystyle \dfrac{h(t)}{dt} = f(h(t), t),\ h(t_0) =h(0) \triangleq x_0$ 中的初始状态 $x_0$ 映射到某一固定时刻 $t_1$ 的状态 $h(t_1)$，即 $g(x):h(t_0)\mapsto h(t_1)$。但是我想了很长时间，暂时都没有举出一个这样的例子😭…后来才反应过来，这他🐱是举不出例子的啊，这样的轨线不存在啊啊啊啊啊啊啊啊啊</p></blockquote><p>但是我之前想，为什么要去要求NODE描述这样的一个表示轨线相交的函数呢？不是已经证明了这样的函数不能成为一个ODE的流函数么？这样的 $g(x)$ 作为所谓的“流函数”应该是不存在的，那你去学习个🔨❓</p><p>后来又想了想，如果能采用<strong>增广维度</strong>的方式，确实，在子空间中其实就不存在轨线相交的情形了，所以ANODE其实是<span style="border-bottom:1px solid black;">通过维度的增广扩宽了NODE能学到的函数空间</span>吧，这样就解决了我的困惑了…</p><h2 id="Why-ANODE"><a href="#Why-ANODE" class="headerlink" title="Why ANODE"></a>Why ANODE</h2><p>为什么读这个文章呢？</p><ul><li>人家是NIPS2019</li><li>最近顺着ODE看这个，挺有意思</li></ul><p>这个文章是核心思想是在NODE的基础上进行数据（状态）的维度增广，通过增广的那部分维度拓宽了可以学习到的函数空间，i.e. 学到了一些原来NODE在原空间中学习不到的函数</p><h2 id="How-ANODE"><a href="#How-ANODE" class="headerlink" title="How ANODE"></a>How ANODE</h2><p>没啥可说的了，原来NODE是考虑ODE方程（不要求自治）</p><script type="math/tex; mode=display">\displaystyle \dfrac{h(t)}{dt} = f(h(t), t),\ h(t_0) =h(0) \triangleq x_0</script><p>但是现在增广维度，可以克服原空间中轨线相交型流函数的学习：</p><script type="math/tex; mode=display">\displaystyle \dfrac{d}{dt}\begin{bmatrix} \textbf{h}(t) \\ \textbf{a}(t) \end{bmatrix} = f(\begin{bmatrix} \textbf{h}(t) \\ \textbf{a}(t) \end{bmatrix}, t),\ \begin{bmatrix} \textbf{h}(t_0) \\ \textbf{a}(t_0) \end{bmatrix} = \begin{bmatrix} \textbf{h}(0) \\ \textbf{a}(0) \end{bmatrix} \triangleq \begin{bmatrix} \textbf{x} \\ \textbf{0} \end{bmatrix}</script><p>我看到这个式子就全明白轨线相交、NODE学习不了的函数这些东西都是在干啥了~</p><h2 id="Advantages-1"><a href="#Advantages-1" class="headerlink" title="Advantages"></a>Advantages</h2><p>直接列举：</p><ul><li>从思想出发，基础的NODE学习不了有的流函数，增广维度可以克服这一点</li><li>所提ANODE表达能力🚀，稳定性🚀，泛化🚀，计算量➖🚀（均未确认）</li><li>保留了NODE的一个优点，保持了原始输入空间的拓扑（阿巴阿巴…）</li></ul><h2 id="Thinking-1"><a href="#Thinking-1" class="headerlink" title="Thinking"></a>Thinking</h2><p>有个固有的想法是：</p><ul><li>维度的增广<strong>本来就是</strong>在拓宽模型的函数空间的，从这角度提出ANODE的话，就是inductive的</li><li>而从这个角度——NODE不能学习的函数，来引入维度增广的思想，这样就是deductive的</li></ul><p>这样一想，这篇ANODE真的就是个idea啊，顶会密码🔞get嗷嗷嗷嗷嗷嗷嗷🤣</p><h2 id="References-1"><a href="#References-1" class="headerlink" title="References"></a>References</h2><p>[1] Emilien Dupont, Arnaud Doucet, and Yee Whye Teh. Augmented neural odes. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3140–3150. Curran Associates, Inc., 2019.</p><h1 id="Model-based-Reinforcement-Learning-for-Semi-Markov-Decision-Processes-with-Neural-ODEs"><a href="#Model-based-Reinforcement-Learning-for-Semi-Markov-Decision-Processes-with-Neural-ODEs" class="headerlink" title="Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs"></a>Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs</h1><p>这篇文章是NODE在RL上进行应用的例子，2020/06/29挂在了ArXiv上，文献地址<a href="https://arxiv.org/abs/2006.16210" target="_blank" rel="noopener">链接</a></p><img src="/2020/09/30/【论文略读1】/RL-NODE.png" title="RL with NODE"><h2 id="RL-Concepts"><a href="#RL-Concepts" class="headerlink" title="RL Concepts"></a>RL Concepts</h2><p>这篇文章涉及到了很多RL，但是我没怎么细看过，所以需要先补一些文中出现的概念。</p><ul><li><p>RL中的model-free方法，指的是啥？懒得总结，引用<a href="https://www.zhihu.com/people/Mr.Zh" target="_blank" rel="noopener">奶油花诶</a>在知乎问题<a href="https://www.zhihu.com/question/64369408" target="_blank" rel="noopener">model-based和model-free，on-policy和off-policy区别？</a>中的解释：</p><blockquote><p>“<strong>model-free</strong>, 是agent和environment进行实时的交互；而<strong>model-based</strong>，从名字上我们就能感受到的到，是先根据真实的情况先学得一个model，即比model-free多了一个对真实世界建模的过程罢了”</p></blockquote><p>由于直接由agent和环境交互学习，这里应当在训练中用到大量训练数据</p></li></ul><h2 id="Why-RL-Framework-for-SMDPs-with-NODE？"><a href="#Why-RL-Framework-for-SMDPs-with-NODE？" class="headerlink" title="Why RL Framework for SMDPs with NODE？"></a>Why RL Framework for SMDPs with NODE？</h2><p>本文针对的问题还是对连续的ODE动力系统进行建模。一个背景需求就是现实中很多数据都是连续化的。</p><p>过去是怎么做的呢？文中Intro部分第二段开头2-4段给出了过去的方法列表，缺点一是统一的，使用了简单的线性函数估计器；缺点二是这些方法基本上是model-free的，似乎需要在训练中用到大量训练数据；缺点三是它们似乎都是启发式的方法，把连续的系统离散化成离散动力系统，再用标准RL方法，自然，离散话若是粗糙了会丢失信息，离散太细了又太耗时。</p><blockquote><p>ps：对缺点1，那为啥不用复杂点的呢❓</p></blockquote><h2 id="What’s-RL-Framework-for-SMDPs-with-NODE"><a href="#What’s-RL-Framework-for-SMDPs-with-NODE" class="headerlink" title="What’s RL Framework for SMDPs with NODE"></a>What’s RL Framework for SMDPs with NODE</h2><p>该文所提方法是<span style="border-bottom:1px solid black;">利用NODE建立对SMDPs的基于模型的RL框架</span>，其中<code>SMDPs</code>是本文针对的基本模型，全名<code>semi-Markov decision processes</code>。</p><blockquote><p>说实话，RL我真的一下子看不下去…</p></blockquote><p>这个<code>SMDPs</code>的数学表达大概是：</p><script type="math/tex; mode=display">\displaystyle \max_{tuple\ (\mathcal{S}, \mathcal{P}, \mathcal{A}, \mathcal{R}, \mathcal{T}, \gamma)} \mathbb{E}\left[\sum_{i=1}^L \gamma^{t_i}r_i\right]</script><p>其中元组 $(\mathcal{S}, \mathcal{A}, \mathcal{R}, \mathcal{T}, \gamma)$ 中，$\mathcal{S}$ 是状态空间，$\mathcal{A}$ 是行动空间，$\mathcal{R}$ 代表行动的奖励函数，即 $r = R(s, a, s^\prime)$ ，其中奖励函数也可以有不（改）同（进）的表达形式，$\mathcal{T}$ 是采取每次行动的时间间隔设置，$\gamma \in (0,1]$ 是每一步奖励的衰减因子（RL中的一般要求）。最后说一下状态转移规则 $\mathcal{P}$，具体的意义就是给定当前状态和行动给出下一次状态，也可以给出一些附加的辅助变量，一般的形式是 $P(s^\prime|s,a)$。</p><p>以上是一般强化学习对<code>SMDPs</code>过程的设置，现在考虑了NODE的应用，具体的方式是对状态变量 $s$ 进行处理。我们把 $s$ 看作像图像一类的原始特征，对它进行编码得到隐空间中的隐变量 $z$，形成编码的过程。按照原文的说法，这就是压缩了原始的状态 $s$。</p><p>对于隐空间变量 $z$，我们把它看作NODE模拟的状态，这样的状态维度是可控的，而且暗含了模拟状态变量 $s$ 在低维空间中显示出的流模型，流的变化规律，这一点我很喜欢！</p><h2 id="Omitted-Details"><a href="#Omitted-Details" class="headerlink" title="Omitted Details"></a>Omitted Details</h2><p>略读，很多细节没有再去深入了。部分为：</p><ul><li>原文其实还有一个辅助模型，应该是针对RL学习的过程的，用来优化训练过程</li><li>作者表示这是<strong>首篇</strong>结合RL和NODE的文章，思想可借鉴</li></ul><h2 id="Pros-and-Cons"><a href="#Pros-and-Cons" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h2><div class="table-container"><table><thead><tr><th>Pros</th><th>Cons</th></tr></thead><tbody><tr><td>首次结合RL和NODE</td><td>broader impact中提到应用的时候要小心（必须啊）</td></tr><tr><td>在隐空间中完成模拟连续动力系统背后状态的流模型</td><td>TBD</td></tr></tbody></table></div><h2 id="References-2"><a href="#References-2" class="headerlink" title="References"></a>References</h2><p>[1] Jianzhun Du, Joseph Futoma, and Finale Doshi-Velez. Model-based reinforcement learning for semi-markov decision processes with neural odes, 2020.</p><h1 id="DelugeNets-Deep-Networks-with-Efficient-and-Flexible-Cross-layer-Information-Inflows"><a href="#DelugeNets-Deep-Networks-with-Efficient-and-Flexible-Cross-layer-Information-Inflows" class="headerlink" title="DelugeNets: Deep Networks with Efficient and Flexible Cross-layer Information Inflows"></a>DelugeNets: Deep Networks with Efficient and Flexible Cross-layer Information Inflows</h1><p>这篇文章是2017CVPR的文章，作者来自新加坡南洋理工，和阿里巴巴，2020/10/12在百度学术上查到的引用量为10。文献地址可以有<a href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/w18/html/Kuen_DelugeNets_Deep_Networks_ICCV_2017_paper.html" target="_blank" rel="noopener">ICCV 2017 Open Access Repository</a>和<a href="https://arxiv.org/abs/1611.05552?context=cs.CV" target="_blank" rel="noopener">ArXiv: 1611.05552</a>。</p><p>说实话这篇文章没有太看明白，既然是略读，就把已经读得的思考写下来吧。</p><img src="/2020/09/30/【论文略读1】/DelugeNets-1.png" title="DelugeNets"><h2 id="卷积概念回顾"><a href="#卷积概念回顾" class="headerlink" title="卷积概念回顾"></a>卷积概念回顾</h2><p>这篇文章中有个关键的卷积操作，叫<span style="border-bottom:1px solid black;">cross-layer depthwise convolution</span>。</p><blockquote><p>这个卷积操作其实还是一种<span style="border-bottom:1px solid black;">separable convolution</span>，本文在Intro部分提到这是本文的<strong>思想来源</strong>。后者操作则相当于把一般的卷积进行分块，分解为<span style="border-bottom:1px solid black;">depthwise convolution</span>与<span style="border-bottom:1px solid black;">pointwise convolution</span>两部分 $^{[3]}$ </p></blockquote><h2 id="Why-and-What’s-DelugeNets"><a href="#Why-and-What’s-DelugeNets" class="headerlink" title="Why and What’s DelugeNets?"></a>Why and What’s DelugeNets?</h2><p>这个概念看起来很有意思，但是这个所谓的洪（什）水（么）网络是啥呢，我也不知道。所以按顺序慢慢来，先讲怎么来的，再概括这是啥。</p><p>首先声明DelugeNets基于DenseNet $^{[5]}$ ，并由<span style="border-bottom:1px solid black;">separable convolution</span>启发得到，但我们先从ResNet讲起。</p><p>ResNet的一大特点是信息流毫无障碍，通过残差的形式一层接一层，梯度传播的时候用链式法则非常轻松。但是这样一溜烟传播过去有个缺点，就是后面隐层可能难以突出前面特定隐层的信息，进而阻碍ResNet学习网络跨层连接的信息。</p><p>而DenseNet作者在Intro部分介绍了一大堆DenseNet的缺点，然后，提出了DelugeNets。</p><p>DenseNet具体的缺点有：</p><p><a href="https://blog.csdn.net/qq_19329785/article/details/84677841" target="_blank" rel="noopener">https://blog.csdn.net/qq_19329785/article/details/84677841</a></p><p><a href="https://www.cnblogs.com/Alliswell-WP/p/Deeplearning_CNN_Review001.html" target="_blank" rel="noopener">https://www.cnblogs.com/Alliswell-WP/p/Deeplearning_CNN_Review001.html</a></p><h2 id="References-3"><a href="#References-3" class="headerlink" title="References"></a>References</h2><p>[1] Jason Kuen, Xiangfei Kong, Gang Wang, and Yap-Peng Tan. Delugenets: Deep networks with efficient and flexible cross-layer information inflows. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshops, Oct 2017.</p><p>[2] Wei Ji. 使用Relu的原因及好处[EB/OL]. <a href="https://blog.csdn.net/qq_19329785/article/details/84677841" target="_blank" rel="noopener">https://blog.csdn.net/qq_19329785/article/details/84677841</a>, 2018-12-01.</p><p>[3] YIN GUOBING. 卷积神经网络中的Separable Convolution[EB/OL]. <a href="https://yinguobing.com/separable-convolution/#fnref2" target="_blank" rel="noopener">https://yinguobing.com/separable-convolution/#fnref2</a>, 2018-02-27.</p><p>[4] 干巴他爹. Depthwise卷积与Pointwise卷积[EB/OL]. <a href="https://blog.csdn.net/tintinetmilou/article/details/81607721" target="_blank" rel="noopener">https://blog.csdn.net/tintinetmilou/article/details/81607721</a>, 2018-08-12.</p><p>[5] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2261–2269, Los Alamitos, CA, USA, jul 2017. IEEE Computer Society.</p><h1 id="IDENT-Identifying-Differential-Equations-with-Numerical-Time-Evolution"><a href="#IDENT-Identifying-Differential-Equations-with-Numerical-Time-Evolution" class="headerlink" title="IDENT: Identifying Differential Equations with Numerical Time Evolution"></a>IDENT: Identifying Differential Equations with Numerical Time Evolution</h1><img src="/2020/09/30/【论文略读1】/IDENT.png" title="IDENT"><p>文献链接： <a href="http://people.math.gatech.edu/~wliao60/Research/papers/IDENT.pdf" target="_blank" rel="noopener">http://people.math.gatech.edu/~wliao60/Research/papers/IDENT.pdf</a> 或 <a href="https://arxiv.org/abs/1904.03538" target="_blank" rel="noopener">https://arxiv.org/abs/1904.03538</a></p><p>这个文章很长，所以<strong>不总结</strong>了，走翻译的老路子。而且这里<strong>只把算法的思路</strong>搞明白，看看大家是怎么做的，具体证明的细节都略掉。</p><h2 id="摘要——姑且算是文献简介"><a href="#摘要——姑且算是文献简介" class="headerlink" title="摘要——姑且算是文献简介"></a>摘要——姑且算是文献简介</h2><p>背景问题是如何由离散的时间序列数据来<strong>识别DE的模式</strong>，其难处是noise即便小也会炸，且非线性性非常复杂，容易<strong>存在多成分</strong>。这个问题的一些偏执归纳是<strong>背后的流模型</strong>——PDE是一系列成分的线性组合，因此主要的问题抽象为<strong>找DE多成分的系数</strong>。</p><p>对此问题，提出<strong>IDENT</strong>（Identifying Differential Equations with Numerical Time Evolution）方法，其训练的约束用到了是Time Evolution Error (TEE)，顺便提出噪声等级的度量Noise-to-Signal ratio。后面一堆方法就不管了。</p><h2 id="文献思路翻译"><a href="#文献思路翻译" class="headerlink" title="文献思路翻译"></a>文献思路翻译</h2><p>$2.1$ 节全是记号，没问题。 $2.2$ 定义问题：</p><p>假设数据背后的PDE模型为分量的线性组合：</p><script type="math/tex; mode=display">\mathcal{F}(x,u,u_x,u_{xx}).</script><p>一共 $10=4+3+2+1$ 个分量： $1, u, u^2, u<em>x, u_x^2, uu_x, u</em>{xx}, u<em>{xx}^2, uu</em>{xx}, u<em>xu</em>{xx}$。其中<strong>记</strong></p><script type="math/tex; mode=display">u_t = \mathcal{F}(x,u,u_x,u_{xx}) = Linear(10\ items)</script><p>其中每个单项式是一个特征，特征数 $N_3 = 10$ ，RHS的线性组合可以看成 $\mathcal{F}$ 的泰勒展开。</p><p>已有的时间数据（注意还有个已知条件是非周期的边界条件）是函数值 $u_i^n = u(x_i, t_n)$ ，以及时空间的分割方式， $(x_i, t_n), i = 1, \cdots, N_1, n = 1, \cdots, N_2$ ，网格式的数据。离散数据可以写成矩阵的形式：</p><script type="math/tex; mode=display">\begin{aligned} \mathbf{b} &\triangleq \begin{pmatrix} u_t(x_1, t_1), \cdots, u_t(x_i, t_n), \cdots, u_t(x_{N_1}, t_{N_2})\end{pmatrix}_{\in \mathbb{R}^{N_1N_2\times 1}}\\ &= \begin{pmatrix} 1& u(x_1, t_1)& u^2(x_1, t_1)& u_x(x_1, t_1)& u_x^2(x_1, t_1)& uu_x(x_1, t_1)& u_{xx}(x_1, t_1)& u_{xx}^2(x_1, t_1)& uu_{xx}(x_1, t_1)& u_xu_{xx}(x_1, t_1)\\\vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots \\ 1& u(x_i, t_n)& u^2(x_i, t_n)& u_x(x_i, t_n)& u_x^2(x_i, t_n)& uu_x(x_i, t_n)& u_{xx}(x_i, t_n)& u_{xx}^2(x_i, t_n)& uu_{xx}(x_i, t_n)& u_xu_{xx}(x_i, t_n)\\ \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots \\ 1& u(x_{N_1}, t_{N_2})& u^2(x_{N_1}, t_{N_2})& u_x(x_{N_1}, t_{N_2})& u_x^2(x_{N_1}, t_{N_2})& uu_x(x_{N_1}, t_{N_2})& u_{xx}(x_{N_1}, t_{N_2})& u_{xx}^2(x_{N_1}, t_{N_2})& uu_{xx}(x_{N_1}, t_{N_2})& u_xu_{xx}(x_{N_1}, t_{N_2})\end{pmatrix}_{\in \mathbb{R}^{N_1N_2\times N_3}} \begin{pmatrix} a_1\\ a_2\\ a_3\\ \vdots\\ a_{N_3-2}\\ a_{N_3-1}\\ a_{N_3}\\ \end{pmatrix}_{\in \mathbb{R}^{N_3\times 1}} \\ &\triangleq \begin{pmatrix} F[1], \cdots, F[j], \cdots, F[N_3]\end{pmatrix}\mathbf{a}\\ &\triangleq \mathbf{Fa}\end{aligned}</script><p>啊这，这排版功力绝了~🍗你阿巴阿巴了么💯</p><p>目标问题就是求解系数 $\mathbf{a}$ ，而普通的实际问题中，RHS的形式不一定有这么多项，所以系数 $\mathbf{a}$ 的形式很可能是稀疏的。进一步，系数 $\mathbf{a}$ 可能是和 $x$ 相关的，所有的分量都可以写成 $x$ 的函数的形式；再进一步，系数 $\mathbf{a}(x)$ 可以用基函数的形式表出，如分段线性连续（设分 $L$ 段）基函数。那么目标函数可以考虑为泛函 $L^p$ 范数（应该是这样）：</p><script type="math/tex; mode=display">\displaystyle ||a_j - \sum_{l=1}^L a_{j,l}\phi_l||_{L^p}\leqslant O(\frac{1}{L}), p\in (0, \infty)</script><p>在基函数的分解形式下， $\mathbf{F}$ 可以把每一列（特征）的基都写开，那么维度变成 $\mathbb{R}^{N_1N_2\times N_3L}$ ，同理， $\mathbf{a}$ 和 $\mathbf{b}$ 的维度也相应改变。</p><p>此时由于系数 $\mathbf{a}(x)$ 成为真实  $\mathbf{a}$ 的近似表出，那么离散数据对应的矩阵方程可以分离出残差项，即</p><script type="math/tex; mode=display">\mathbf{Fa} = \mathbf{b} + \mathbf{\eta}</script><p>上式需要注意维度已经被基函数扩大了，那么目标函数也变成</p><script type="math/tex; mode=display">\displaystyle ||\eta||_{L^p}\leqslant O(\frac{1}{L}), p\in (0, \infty)</script><p>$2.3$ 节正式提出IDENT算法：</p><p>首先要由函数值导出对时间 $t$ 的导数，即方程中的 $\mathbf{b}$ ，直接用差分近似（文章这个地方好像打错了个下标）：</p><script type="math/tex; mode=display">\hat{u_t}(x_i, t_n) = u_t(x_i, t_n) + O(\Delta t) \triangleq \dfrac{u(x_i, t_n) - u(x_i, t_{n-1})}{\Delta t}</script><p>这就作为 $\mathbf{b}$ 的近似 $\mathbf{\hat{b}}$ 的分量。</p><p>其它的特征，包括 $u<em>x, u</em>{xx}$ 等不直接用一阶差分近似，引用别人的方法，叫做<code>5点ENO</code>，哎，这样一顿操作，大矩阵 $\mathbf{F}$ 的近似出来了，记作 $\hat{\mathbf{F}}$ 。这样近似基本上都弄好了。原先的矩阵方程成为：</p><script type="math/tex; mode=display">\begin{aligned} \hat{\mathbf{F}}\mathbf{a} &= (\hat{\mathbf{F}} + \mathbf{F} - \mathbf{F})\mathbf{a} = \mathbf{b} + \mathbf{\eta} + (\hat{\mathbf{F}} - \mathbf{F})\mathbf{a}\\ &= (\mathbf{b} + \hat{\mathbf{b}} - \hat{\mathbf{b}}) + \mathbf{\eta} + (\hat{\mathbf{F}} - \mathbf{F})\mathbf{a}\\ &= \hat{\mathbf{b}} + (\mathbf{b} - \hat{\mathbf{b}}) + \mathbf{\eta} + (\hat{\mathbf{F}} - \mathbf{F})\mathbf{a}\\ &\triangleq \hat{\mathbf{b}} + \mathbf{e} \end{aligned}</script><p>总的近似误差 $\mathbf{e}$ 满足（应该是后面证明的）</p><script type="math/tex; mode=display">\displaystyle ||\mathbf{e}||_{L^2}\leqslant \varepsilon\ s.t.\ \varepsilon = O(\Delta t + \Delta x^3 + \frac{1}{L}), p\in (0, \infty)</script><p>第二步似乎就是求解了？不，不是求解！第二步是用LASSO筛选出稀疏的成分，判断哪些特征对应的系数是比较重要的，方法是使用了LASSO并构造了带 $L_1$ 稀疏正则的能量函数。</p><p>第三步则是根据已经知道了方程中含有哪些重要的成分（特征），再用TEE方法（Time Evolution Error）最小二乘进行拟合，得到最后的稀疏系数。</p><p>这篇文章后面其实还有很多内容，但是感觉不太能看得下去了，先码在这里，把后面的一些重点列在这里：</p><ol><li>Why LASSO 选取稀疏特征</li><li>TEE效果不错</li><li>噪声水平指标NSR：Noise-to-Signal Ratio</li><li>对噪声稳健性及采样方法</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Sung Ha Kang, Wenjing Liao, and Yingjie Liu. Ident: Identifying differential equations with numerical time evolution, 2019.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;此博客略读文献列表：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Densely Connected Convolutional Networks（写完笔记之后觉得略读个🔨…）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Augmented Neural ODEs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;updated on 12th, Oct&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DelugeNets: Deep Networks with Efficient and Flexible Cross-layer Information Inflows（读得不太懂…）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;updated on 12th, Oct&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IDENT: Identifying Differential Equations with Numerical Time Evolution&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;updated on 20th, Oct&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="CNN" scheme="http://maxliu245.github.io/tags/CNN/"/>
    
      <category term="paper reading" scheme="http://maxliu245.github.io/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读22】ODE2VAE——2阶ODE模拟+BNN引入不确定性</title>
    <link href="http://maxliu245.github.io/2020/09/25/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB22%E3%80%91ODE2VAE%E2%80%94%E2%80%942%E9%98%B6ODE%E6%A8%A1%E6%8B%9F-BNN%E5%BC%95%E5%85%A5%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7/"/>
    <id>http://maxliu245.github.io/2020/09/25/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB22%E3%80%91ODE2VAE%E2%80%94%E2%80%942%E9%98%B6ODE%E6%A8%A1%E6%8B%9F-BNN%E5%BC%95%E5%85%A5%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7/</id>
    <published>2020-09-25T13:44:02.000Z</published>
    <updated>2020-09-26T08:43:43.272Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文笔记主要是我对19年NIPS的文章ODE2VAE：</p><p><code>ODE2VAE: Deep generative second order ODEs with Bayesian neural networks</code></p><p>其模型的生成方式和模型结构的理解，具体概率公式的推导和实验的细节都略掉了，如果需要的话以后再看</p></blockquote><a id="more"></a><img src="/2020/09/25/【论文阅读22】ODE2VAE——2阶ODE模拟-BNN引入不确定性/ODE2VAE-1.png" title="文献预览"><h1 id="开门见山——文献总结"><a href="#开门见山——文献总结" class="headerlink" title="开门见山——文献总结"></a>开门见山——文献总结</h1><p>这篇文章是19年的NIPS文章，与ANODE是同一次会议产出的。而在我看来，这两篇文章很多<strong>内容是有类似的地方</strong>的，但是在<strong>思想上又大不相同</strong>：</p><ul><li>前者的目标主要是做生成模型，希望设计学习更好的连续流数据（模型）的建模，方式是在NODE基础上考虑了二阶导的模拟和不确定性的引入，这两个是用一个模块同时完成的，即采用BNN学习二阶导，同时就可以引入不确定性。最后考虑到生成的效果需要保障，因此用VAE的形式进行了对抗</li><li>后者的目标主要是对NODE直接做改进，从NODE的一个缺点入手，利用手动添加增广维度，在高维空间中克服了对低维空间中不连续情形的模拟，从而完成了NODE的增广，据说提高了表达能力、稳定性、泛化性，降低了计算消耗。这个缺点即有一大类函数是NODE学习不了的，但是目前对这个我真的还不是很理解，因此后续再进行阅读</li></ul><p>上面的介绍已经表明了目前我对ODE2VAE模型的认识（<strong>当我自己写到这里的时候，我认为这个ODE2VAE中对二阶导的建模本质上可以看成ANODE在维度上进行增广的一个特例~</strong>）。下面我们回顾一下该模型的前因后果吧。</p><h1 id="前因后果——ODE2VAE的前生今世"><a href="#前因后果——ODE2VAE的前生今世" class="headerlink" title="前因后果——ODE2VAE的前生今世"></a>前因后果——ODE2VAE的前生今世</h1><p>故事要从流模型开始讲，流模型在干什么？一个简单的解释是流模型本身是ODE领域的延伸概念，把ODE初值问题中不同时刻的状态变化过程称为一个流。这个概念其实很有意思，后面我会<font color="#0000FF">单开一文</font>来介绍它。</p><p>流模型由于其本身脱胎于ODE系统的性质，对很多实际情况的模拟应该是比较适合的，但是与神经网络结合的话，此前只有NODE简单地以ResNet中残差的形式对应到了差分，因此完成了一阶导的模拟。举个应用的例子，连续视频流文件的每一帧都可以看成一个中间状态，其背后是很可能有隐含的流模型的，这时如果能学习出其流模型，那么就可以完成视频补帧，甚至短期预测等重要任务。</p><h1 id="模型机理——ODE-amp-VAE"><a href="#模型机理——ODE-amp-VAE" class="headerlink" title="模型机理——ODE&amp;VAE"></a>模型机理——ODE&amp;VAE</h1><p>回顾一下，ODE2VAE的一个目标是学习生成模型，突破NODE1阶导的限制，进行更细的二阶导建模。那么它对二阶导的做法是用BNN来学习一个对应的函数，同时BNN可以引入不确定性。另外，既然是生成模型，那么既要编码也要解码，因此其中又使用了VAE的对抗模式保证数据恢复的质量。下面先上图，再康康这个生成模型是怎么假设的：</p><img src="/2020/09/25/【论文阅读22】ODE2VAE——2阶ODE模拟-BNN引入不确定性/ODE2VAE-2.png" title="模型结构"><p>流模型的生成结构为：</p><script type="math/tex; mode=display">\displaystyle \begin{align} s_0 & \sim p(s_0) \tag{1}\\  v_0 &\sim p(v_0) \tag{2}\\  s_t &= s_0 + \int_{0}^{t} v_{\tau} d\tau \tag{3}\\  v_t &= v_0 + \int_{0}^{t} f_{true} (s_{\tau}, v_{\tau})d\tau \tag{4} \\  x_i &\sim p(x_i | s_i), i\in [0, N] \tag{5}\end{align}</script><p><strong>注意</strong>，这里的变量 $s$ 是把原始的流数据经过编码器转换到隐空间中的变量！即在隐空间中假设存在了流模型！</p><p>这里前两个式子 $(1, 2)$ 表示流的初始状态：</p><div class="table-container"><table><thead><tr><th>符号</th><th>流上的意义</th><th>形象的意义</th></tr></thead><tbody><tr><td>$s_0$</td><td>初始状态（state）的值</td><td>初始时刻0时，点的位置</td></tr><tr><td>$v_0$</td><td>初始状态（state）的一阶导</td><td>初始时刻0时，点的速度</td></tr></tbody></table></div><p>接下来的 $(3, 4)$ 式则是流的变化过程，一阶导 $v$ 的积分可以描述状态 $s$ 的变化，即 $(3)$ 式；而二阶导 $v^\prime$ 的积分可以描述一阶导 $v$ 的变化，即 $(4)$ 式。其中二阶导就用贝叶斯神经网络BNN来暴力模拟，记这个BNN的整体函数表达式为 $f_{true}$，$(4)$ 式表明它的输入是先前所有状态和一阶导，不过模型结构图表示输入是当前状态的值和一阶导。由于目前我没有研究代码，我<font color="#0000FF">个人认为</font>这两种输入都可以，但我猜在当前的架构下，<span style="border-bottom:1px solid black;">采用前一段时间内的流数据建模</span>比较好，这个想法是比较合理的。前者输入太多，虽然利用的信息多，但是计算的消耗也会很大，而且可能需要用到RNN等处理序列数据的方法作为子模型；后者输入比较少，指利用当前状态的信息，这其实也不太稳，毕竟二阶导自身的变化也应当被正确建模。</p><p>最后的 $(5)$ 式就是图中的解码器了，把学习到的流的变化特征重构成流数据。不过这个 $p(x_i | s_i)$ 具体是怎么解码回去的我就不清楚了，我猜是参数共享，直接把编码器给倒过来，从隐空间恢复原始的流数据。</p><hr><p>以上，本文的出发点，以生成模型建模流数据的过程就弄得差不多了。这里再补充一个小细节，一阶导 $s$ 的生成，是利用原始流数据 $x$ 的前 $m$ 维完成的，举个例子，这个前 $m$ 维就是视频流数据的前 $m$ 帧，这种近似的思想也与前面我所提到的“<span style="border-bottom:1px solid black;">采用前一段时间内的流数据建模</span>”一致~</p><h1 id="优缺点——扶摇直上亿万里"><a href="#优缺点——扶摇直上亿万里" class="headerlink" title="优缺点——扶摇直上亿万里"></a>优缺点——扶摇直上亿万里</h1><p>最后回到总结吧~</p><p>前面提到ODE2VAE的目标主要是做生成模型，对流数据建模，引入BNN暴力学习二阶导，顺便引入了不确定性。这些都是文章出彩的思想，也是卖点所在。</p><p>而这些<strong>应当</strong>是增广NODE模型的一个维度增广特例，只不过是增广了二阶导。那么ANODE又能增广到什么程度呢？我还需要继续阅读，如果能直接暴力增广学习高阶导，那也不错，在此基础上一定有更加有意思的地方。</p><p>Can u get me?</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>不太好整，这<code>markdown</code>上不能整<code>bibtex</code>实在是太难受，给个文献链接直接了事~</p><p><a href="http://papers.nips.cc/paper/9497-ode2vae-deep-generative-second-order-odes-with-bayesian-neural-networks" target="_blank" rel="noopener">ODE2VAE: Deep generative second order ODEs with Bayesian neural networks</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文笔记主要是我对19年NIPS的文章ODE2VAE：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ODE2VAE: Deep generative second order ODEs with Bayesian neural networks&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;其模型的生成方式和模型结构的理解，具体概率公式的推导和实验的细节都略掉了，如果需要的话以后再看&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【Jupyter Notebook 1】创建不了文件以及保存文件失败的问题</title>
    <link href="http://maxliu245.github.io/2020/09/25/%E3%80%90Jupyter-Notebook-1%E3%80%91%E5%88%9B%E5%BB%BA%E4%B8%8D%E4%BA%86%E6%96%87%E4%BB%B6%E4%BB%A5%E5%8F%8A%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://maxliu245.github.io/2020/09/25/%E3%80%90Jupyter-Notebook-1%E3%80%91%E5%88%9B%E5%BB%BA%E4%B8%8D%E4%BA%86%E6%96%87%E4%BB%B6%E4%BB%A5%E5%8F%8A%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2020-09-25T12:38:51.000Z</published>
    <updated>2020-09-25T13:25:24.429Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>具体的错误包括：</p><ol><li><p>在notebook交互界面一点击保存按钮就会报错</p><p><code>[Error 2] No such file or directory: C:\\...\\...\\....ipynb</code></p></li><li><p>在文件目录界面一创建新文件就会报错</p><p><code>An error occurred while creating a new notebook. No such directory: ...</code></p></li></ol></blockquote><a id="more"></a><h1 id="Bug产生背景"><a href="#Bug产生背景" class="headerlink" title="Bug产生背景"></a>Bug产生背景</h1><p>这次bug的出现是莫名其妙的，白天的时候都好好的，晚上一开电脑就遇到了这个简介中提到cai的两个问题。下面是我的<strong>美丽</strong>截图🤭</p><img src="/2020/09/25/【Jupyter-Notebook-1】创建不了文件以及保存文件失败的问题/JN-1.png" title="保存文件失败——美丽的静香打码"><img src="/2020/09/25/【Jupyter-Notebook-1】创建不了文件以及保存文件失败的问题/JN-2.png" title="创建新文件失败——美丽的静香再打码"><blockquote><p>ps: 本人打码实属打🐎👻才，静香图来源于B站撸大师木源，嗯，好像是这个奇妙的名字…</p></blockquote><h1 id="探索解决方法"><a href="#探索解决方法" class="headerlink" title="探索解决方法"></a>探索解决方法</h1><p>起初我以为是以往遇到的一个问题，就是notebook的容量太大了，超过5M可能读取起来就会出错，所以我先手动清除了其中的大部分输出，但是点击保存仍然是这个情况。</p><p>然后在网上搜了一通也没有找到适合我这种情况的解决方法。</p><p>最后注意到一个相关性比较高的回答，它表示路径名称中有特殊字符，好像是中文，不过我忘了具体怎么说的了。虽然以前我都用的中文，但是这次确实是出毛病了啊。我看着一大串的报错信息，觉得这个路径实在是太长了，毕竟我嵌套了很多文件夹…</p><p>于是！我在靠近根目录的地方复制了原来的文件，🆗</p><p><strong>所以，我这里上述两个bug出现是因为当前文件路径过长…</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;具体的错误包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在notebook交互界面一点击保存按钮就会报错&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[Error 2] No such file or directory: C:\\...\\...\\....ipynb&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在文件目录界面一创建新文件就会报错&lt;/p&gt;
&lt;p&gt;&lt;code&gt;An error occurred while creating a new notebook. No such directory: ...&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Programming" scheme="http://maxliu245.github.io/tags/Programming/"/>
    
      <category term="Bug" scheme="http://maxliu245.github.io/tags/Bug/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读21】DSN——域分离网络</title>
    <link href="http://maxliu245.github.io/2020/09/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB21%E3%80%91DSN%E2%80%94%E2%80%94%E5%9F%9F%E5%88%86%E7%A6%BB%E7%BD%91%E7%BB%9C/"/>
    <id>http://maxliu245.github.io/2020/09/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB21%E3%80%91DSN%E2%80%94%E2%80%94%E5%9F%9F%E5%88%86%E7%A6%BB%E7%BD%91%E7%BB%9C/</id>
    <published>2020-09-19T10:37:00.000Z</published>
    <updated>2020-09-19T12:19:44.574Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>DSN全称Domain Separation Network，是我看的第二篇域迁移的文章，这篇文章在DANN之后，思想上的一大亮点是对特征进行了分离，这样潜在地扩大了域迁移的范围~</p><p>补充一点，具体实现上的一大亮点是loss的选择，实验表明<span style="border-bottom:1px solid black;">scale-invariant的MSE损失</span>的效果确实很棒~</p></blockquote><a id="more"></a><img src="/2020/09/19/【论文阅读21】DSN——域分离网络/DSN-1.png" title="文献预览"><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>读这篇文章的时候觉得自己的写作水平有了变化，但是说不清楚是好是坏。因为DSN这篇文章相比DANN有了理论上的改进，但是在写作DANN的时候却漏掉了一些关键的总结，比如这样的模型优缺点分析。</p><p>虽然DANN的博客似乎有了点味儿，但是还是要把关键的地方点出来啊💪</p><h1 id="为什么读"><a href="#为什么读" class="headerlink" title="为什么读"></a>为什么读</h1><ul><li>同DANN一样，IID-CSS上听来的，而且时间在DANN之后，似乎（的确）有了更多（一些）改进的地方</li><li>人家虽然不是JMLR，但却是2016年NIPS上的一篇poster啊🙈</li><li>在阅读的时候觉得其中可能有个地方有些问题，所以把感受记录下来</li></ul><p>这次的文献及相关参考链接似乎有点多，在这里列出几个主要的，其它放在文末。</p><ol><li>DSN文献原文：<a href="http://papers.nips.cc/paper/6254-domain-separation-networks.pdf" target="_blank" rel="noopener">DSN</a></li><li>DSN种一个重要损失项——<span style="border-bottom:1px solid black;">scale-invariant的MSE损失</span> 的来源：<a href="http://papers.nips.cc/paper/5539-depth-map-prediction-from-a-single-image-using-a-multi-scale-deep-network.pdf" target="_blank" rel="noopener">Depth Map Prediction from a Single Image using a Multi-Scale Deep Network</a></li><li>知乎用户<a href="https://www.zhihu.com/people/ben-ben-18-78" target="_blank" rel="noopener">笨笨</a>的文章<a href="https://zhuanlan.zhihu.com/p/49479734" target="_blank" rel="noopener"><eyd与机器学习>迁移学习：Domain Separation Networks</eyd与机器学习></a>，在我看来这个讲得很干净，内容也都讲到了</li><li>CSDN用户<a href="https://blog.csdn.net/hjimce" target="_blank" rel="noopener">hjimce</a>的文章<a href="https://blog.csdn.net/hjimce/article/details/50569474" target="_blank" rel="noopener">深度学习（二十八）基于多尺度深度网络的单幅图像深度估计</a>，该文种的代码让我走出迷雾，弄懂了部分loss的具体实现方式</li></ol><h1 id="对文章的整体理解"><a href="#对文章的整体理解" class="headerlink" title="对文章的整体理解"></a>对文章的整体理解</h1><p>其实上面所述参考链接中的知乎文章已经够用了。现在大致重新总结一下，让我们从DANN的一个缺点过渡到本文的思路。</p><p>DANN在做域迁移的时候，<del>直接</del>将源域和目标域的样本转化到某一特征空间中并混淆它们，达到迁移的效果。</p><p>但是这样做，其实有一些问题，即域迁移本身是难以做到全部特征迁移的，因为不同的域对应的特征、特征分布的确是不同的。那么<strong>新的思路</strong>就来了，不同的域之间<span style="border-bottom:1px solid black;">有联系性，也有差异性</span>，那么联系性可以简单描述为特征空间中有一些维度是不同域共享的，称为<strong>共有（common）特征</strong>；反之差异性可以简单描述为特征空间中有另一些维度不是共享的，是域本身的特征，所以称为<strong>私有（private）特征</strong>。</p><p>因此，基于这个新思路，我们希望基于DANN的结构，把共有的特征和私有的特征分离开来，期望能够更好地描述不同域之间的关系，达到更好的效果。到这里，文章标题<em>Domain Separation Network</em>的思路就完全确定了，下面就是怎么去实现了。</p><h1 id="DSN模型结构"><a href="#DSN模型结构" class="headerlink" title="DSN模型结构"></a>DSN模型结构</h1><p>👴话不多说，直接暴力上结构！</p><img src="/2020/09/19/【论文阅读21】DSN——域分离网络/DSN-2.png" title="DSN结构"><p>结构还是比较清晰的，咱们直接点明该结构是在哪一（几）块完成公、私有特征分离的操作的。就是除了右下角分类外的全部结构，但是<strong>别慌</strong>，别看框框多，其实都是高度对称的结构。类比DANN，输入从全部样本 $x$ 分离为有标记的两域样本 $x_s$ 和 $x_t$，下标自然是源域source和目标域target了；同时输出也从全部特征空间的 $f$ 转化为了公有特征 $h_c$ 和私有特征 $h_p$。</p><p>成功分离的保证是暹罗网络。啥？暹罗网络？想到了吧哈哈，哥我曾经看过一篇语音生成的文章<a href="https://arxiv.org/abs/1910.03713?context=eess.AS" target="_blank" rel="noopener">MelGAN-VC</a>，现在看看这个特征分离的操作和这篇文章不是有点像，而是完全一致！都是利用Siamese Network，中文译为暹罗网络或者孪生网络，使用的是特征分离对抗➕样本恢复的形式。具体懒得说了，反正我早学过了🤭，这里就列一篇介绍暹罗网络的博客吧<a href="https://blog.csdn.net/weixin_41866216/article/details/90643068" target="_blank" rel="noopener">Siamese Network：孪生网络 简单理解</a>。</p><p>好了，上面把文章的核心对抗方法直接跳过了，那么模型的结构其实就讲完了😄</p><h1 id="Loss组成"><a href="#Loss组成" class="headerlink" title="Loss组成"></a>Loss组成</h1><p>讲到这里，忘了说，文章的两大亮点，一是利用暹罗网络分离了公私有特征；二是loss的具体形式了，先点明，就是<span style="border-bottom:1px solid black;">scale-invariant的MSE损失</span>的使用。loss的具体组成请参阅参考链接中的知乎文章<a href="https://zhuanlan.zhihu.com/p/49479734" target="_blank" rel="noopener"><eyd与机器学习>迁移学习：Domain Separation Networks</eyd与机器学习></a>，这里不再赘述。但是其中很多细节还需要研究研究。</p><p>其实在阅读这部分的时候，我遇到了很多障碍，这里我主要对<span style="border-bottom:1px solid black;">scale-invariant的MSE损失</span>有以下疑问，该loss似乎在全局图像恢复上的效果比一般的MSE好，效果好的理由是文章中的实验验证：</p><ol><li><p>但为什么是这种形式呢？（下文解答）</p></li><li><p>对于图像恢复的颜色和色彩强度没有要求，为什么？（<strong>待求证！</strong>）</p></li><li><p>这个loss的定义很奇怪，原文中的形式是 $(4)$ 式，前一项记为MSE，后一项记为SIMSE。而我在 <a href="https://github.com/fungtion/DSN" target="_blank" rel="noopener">https://github.com/fungtion/DSN</a> 找到的代码中看别人复现的loss用的是此MSE+SIMSE而不是减？（下文解答）</p></li><li><p>此loss中前者MSE的计算并不是什么矩阵 $A^TA$ 特征值绝对值最大值（参考 <a href="https://www.zhihu.com/question/50557667" target="_blank" rel="noopener">https://www.zhihu.com/question/50557667</a> ）而是普通的矩阵元素差值平方和？那这里矩阵的 $L_2$ 范数究竟是什么？</p></li></ol><p>针对问题 $1、3、4$，我先后查阅了这种<span style="border-bottom:1px solid black;">scale-invariant的MSE损失</span>的原文，2014NIPS的<em>Depth Map Prediction from a Single Image using a Multi-Scale Deep Network</em>，以及CSDN博客<a href="https://blog.csdn.net/hjimce/article/details/50569474" target="_blank" rel="noopener">深度学习（二十八）基于多尺度深度网络的单幅图像深度估计</a>，和G站上他人的代码 <a href="https://github.com/fungtion/DSN" target="_blank" rel="noopener">https://github.com/fungtion/DSN</a> 。从这三处，我将给出我的分析过程。</p><p><strong>首先</strong>，G站上的代码是本文的<code>PyTorch</code>实现，loss函数的定义在 <a href="https://github.com/fungtion/DSN/blob/master/functions.py" target="_blank" rel="noopener">https://github.com/fungtion/DSN/blob/master/functions.py</a> ，训练的过程在 <a href="https://github.com/fungtion/DSN/blob/master/train.py" target="_blank" rel="noopener">https://github.com/fungtion/DSN/blob/master/train.py</a> ，由于把源域和目标域损失都分开算了，所以目标域上没标签，就没有分类损失，源域上则有。其中的MSE项和SIMSE项分别是（引用他人代码啦注明出处应该可以…）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MSE</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(MSE, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, pred, real)</span>:</span></span><br><span class="line">        diffs = torch.add(real, -pred)</span><br><span class="line">        n = torch.numel(diffs.data)</span><br><span class="line">        mse = torch.sum(diffs.pow(<span class="number">2</span>)) / n</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mse</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SIMSE</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(SIMSE, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, pred, real)</span>:</span></span><br><span class="line">        diffs = torch.add(real, - pred)</span><br><span class="line">        n = torch.numel(diffs.data)</span><br><span class="line">        simse = torch.sum(diffs).pow(<span class="number">2</span>) / (n ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> simse</span><br></pre></td></tr></table></figure><p>这些就是代码实现中的具体loss计算方式，而我觉得原文的 $(4)$ 式右边第一项写成矩阵的 $L_2$ 范数是<strong>不合适</strong>的。毕竟 <code>mse = torch.sum(diffs.pow(2)) / n​</code> 说明了这不是正规的矩阵 $L_2$ 范数。这样<strong>问题 $4$ 就解决了</strong>。</p><p><strong>其次</strong>，在CSDN博客中，作者有一段该loss的代码，不过是TF，我不太熟悉，但是写得很棒。关键是代码的注释里有一句</p><blockquote><p>文献中公式４，参数$\lambda$取值为0.5。公式采用的是简化为（ｎ×sum(d^2)-λ*(sum(d))^2）/(n^2)</p></blockquote><p>这提示，是不是代码实现简化了特征根的计算，用代码中的形式来代替计算呢？确实看了<em>Depth Map Prediction from a Single Image using a Multi-Scale Deep Network</em> $(4)$ 式，形式上是一致的。那么是不是替代品呢？是的，原文是在log空间计算的，所以度量其实是 $\displaystyle \alpha(x, \hat{x}) = \dfrac{1}{n}\sum_i \left(\log x_i - \log \hat{x}_i\right)$ ，所以现在本文用正常的原空间有 $\displaystyle \alpha(x, \hat{x}) = \dfrac{1}{n}\sum_i \left(x_i - \hat{x}_i\right)$，所以带入参考文献<em>Depth Map Prediction from a Single Image using a Multi-Scale Deep Network</em>的 $(1)$ 式有</p><script type="math/tex; mode=display">\begin{align} \displaystyle D(x, \hat{x}) &= \dfrac{1}{2n}\sum_{i=1}^n \left(x_i - \hat{x}_i + \dfrac{1}{n}\sum_i \left(x_i - \hat{x}_i\right)\right)^2 \\ &= \dfrac{1}{2n^2}\sum_{i, j} \left(\left(x_i - x_j\right) - \left(\hat{x}_i - \hat{x}_j\right)\right)^2 \\ &\triangleq \dfrac{1}{n}\sum_i d_i^2 - \dfrac{1}{n^2}\sum_{i, j} d_i d_j \\ &= \dfrac{1}{n}\sum_i d_i^2 - \dfrac{1}{n^2}\left(\sum_i d_i\right)^2 \end{align}</script><p>这的确就是代码实现中的具体计算方式，这进一步说明代码种的形式确实是SIMSE的形式，说明原文的 $(4)$ 式右边第一项写成矩阵的 $L_2$ 范数是不合适的。这样<strong>问题 $1$ 就被推导出来了</strong>。</p><p><strong>最后</strong>，针对问题 $3$，我觉得这位兄弟的代码不小心写错了，好了<strong>问题 $3$ 也解决了</strong>~</p><hr><p>综上，这篇文章我基本上都看完了，还剩一些小问题藏在加粗字中，待办了~</p><h1 id="其它小细节"><a href="#其它小细节" class="headerlink" title="其它小细节"></a>其它小细节</h1><ul><li><p>学到一个新函数：<a href="https://pytorch.org/docs/master/generated/torch.numel.html" target="_blank" rel="noopener"><strong>torch.numel</strong></a>，输入是tensor，输出是全部元素的个数，感觉就是张量的size</p></li><li><p><strong>MMD损失是什么</strong>我看不懂，需要再去具体学习！</p></li><li><p>文章的其它部分，尤其是对比实验、其它loss都可以参考<a href="https://zhuanlan.zhihu.com/p/49479734" target="_blank" rel="noopener">迁移学习：Domain Separation Networks</a>，讲得挺好</p></li><li><p>文章原文中说代码在这<a href="https://github.com/tensorflow/models/domain_adaptation，但👴没找着" target="_blank" rel="noopener">https://github.com/tensorflow/models/domain_adaptation，但👴没找着</a>…</p></li><li><p>difference loss用矩阵乘积的形式超过了DANN loss的效果！说明这种分离公共、私有特征的度量是有效的！</p></li><li><p>上面反复说的知乎文章下面有个评论：</p><blockquote><p>您好，请问在输入公有特征提取器的时候，是把两个域的样本整体用两个矩阵输入进去，还是从每次从目标域和源域各选取一个成为一对输入进去呢</p></blockquote><p>从文章原文 $(3)$ 式的loss看应该是全部数据喂进去了，从代码看也是这样，不过多了点细节，是分源域样本和目标域样本分别通通喂进去的</p></li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>文章主要的4篇参考文献在<code>为什么读</code>章节中已经给出。</p><p>[5] 黑猫紧张. PN-35: Domain Separation Networks (NIPS 2016)[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/82403668" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/82403668</a>, 2019-09-13.</p><p>[6] gdtop818. Domain Separation Networks[EB/OL]. <a href="https://blog.csdn.net/weixin_37993251/article/details/91472097" target="_blank" rel="noopener">https://blog.csdn.net/weixin_37993251/article/details/91472097</a>, 2019-06-11.</p><p>[7] PoemK. Domain Separation Networks (NIPS 2016)[EB/OL]. <a href="https://blog.csdn.net/yskyskyer123/article/details/95664755" target="_blank" rel="noopener">https://blog.csdn.net/yskyskyer123/article/details/95664755</a>, 2019-07-12.</p><p>[8] 究竟灰. 论文阅读：Depth Map Prediction from a Single Image using a Multi-Scale Deep Network[EB/OL]. <a href="https://zhuanlan.zhihu.com/p/29312227" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29312227</a>, 2019-09-18.</p><p>[9] Xuefeng_BUPT. Depth Map Prediction from a Single Image using a Multi-Scale Deep Network（NIPS2014）论文阅读[EB/OL]. <a href="https://blog.csdn.net/chishuideyu/article/details/83573174" target="_blank" rel="noopener">https://blog.csdn.net/chishuideyu/article/details/83573174</a>, 2018-10-31.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;DSN全称Domain Separation Network，是我看的第二篇域迁移的文章，这篇文章在DANN之后，思想上的一大亮点是对特征进行了分离，这样潜在地扩大了域迁移的范围~&lt;/p&gt;
&lt;p&gt;补充一点，具体实现上的一大亮点是loss的选择，实验表明&lt;span style=&quot;border-bottom:1px solid black;&quot;&gt;scale-invariant的MSE损失&lt;/span&gt;的效果确实很棒~&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="Domain Adaptation" scheme="http://maxliu245.github.io/tags/Domain-Adaptation/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读20】DANN——利用域对抗进行简单的域迁移</title>
    <link href="http://maxliu245.github.io/2020/09/17/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB20%E3%80%91DANN%E2%80%94%E2%80%94%E5%88%A9%E7%94%A8%E5%9F%9F%E5%AF%B9%E6%8A%97%E8%BF%9B%E8%A1%8C%E7%AE%80%E5%8D%95%E7%9A%84%E5%9F%9F%E8%BF%81%E7%A7%BB/"/>
    <id>http://maxliu245.github.io/2020/09/17/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB20%E3%80%91DANN%E2%80%94%E2%80%94%E5%88%A9%E7%94%A8%E5%9F%9F%E5%AF%B9%E6%8A%97%E8%BF%9B%E8%A1%8C%E7%AE%80%E5%8D%95%E7%9A%84%E5%9F%9F%E8%BF%81%E7%A7%BB/</id>
    <published>2020-09-17T14:05:42.000Z</published>
    <updated>2020-09-17T14:25:52.921Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>第一次看领域迁移的文章~</p></blockquote><a id="more"></a><img src="/2020/09/17/【论文阅读20】DANN——利用域对抗进行简单的域迁移/DANN-1.png" title="文献预览"><h1 id="为什么读"><a href="#为什么读" class="headerlink" title="为什么读"></a>为什么读</h1><ul><li>IID组会上听来的，好像很炫酷</li><li>人家是JMLR啊，而且似乎是相关工作的开山作？好像是，日后再证</li><li>下面的参考博客中把该文章的模型结构都说的很清楚，但是感觉对loss的描述不够精确细节，我第一遍看没法get到模型的实现机理，因此单独细看了loss，并记录于此博客</li></ul><p>文献及相关参考链接：</p><ol><li><p><a href="https://www.jmlr.org/papers/volume17/15-239/15-239.pdf" target="_blank" rel="noopener">https://www.jmlr.org/papers/volume17/15-239/15-239.pdf</a> 或者 <a href="https://arxiv.org/abs/1505.07818" target="_blank" rel="noopener">https://arxiv.org/abs/1505.07818</a></p></li><li><p><a href="https://blog.csdn.net/weixin_37993251" target="_blank" rel="noopener">gdtop818</a>的CSDN博客<a href="https://blog.csdn.net/weixin_37993251/article/details/89398433" target="_blank" rel="noopener">Domain-Adversarial Training of Neural Networks</a></p></li><li><p><a href="https://www.zhihu.com/people/sabrina-65-94" target="_blank" rel="noopener">我的猫爱睡觉</a>的知乎文章<a href="https://zhuanlan.zhihu.com/p/199514982" target="_blank" rel="noopener">Domain-Adversarial Training of NN(DANNs)</a>，包括了几个有用的链接</p></li></ol><h1 id="DANN及其loss构造"><a href="#DANN及其loss构造" class="headerlink" title="DANN及其loss构造"></a>DANN及其loss构造</h1><p>首先还是介绍一下<strong>DANN——Domain-Adversarial Training of Neural Networks</strong>，在我理解是一篇利用了对抗网络来进行简单的领域迁移的文章。这篇文章除了迁移、对抗，还有表示学习的内容，因为具体操作是通过特征的转换完成的。文章思想<strong>核心</strong>是通过让源域和目标域的样本特征不能被很好地辨识，同时源域上的分类效果很好，达到<strong>混淆样本的特征表示</strong>，使分类器在此特征表示上能够完成域迁移的效果。</p><p>话不多说，直接开干原文中第4章的模型结构图，如下图所示：</p><img src="/2020/09/17/【论文阅读20】DANN——利用域对抗进行简单的域迁移/DANN-2.png" title="DANN"><p>那么DANN分3个部分：</p><ol><li><p>左上角是特征提取器 $G_f$，feature的提取器。输入 $x$ 包括源域和目标域的样本，输出转化后的特征。其目的一方面是特征提取，另一方面是在特征空间中混淆源域和目标域的样本，即两个域的样本对齐，以便迁移；</p></li><li><p>右上角是分类器 $G_y$，对标签 $y$ 分类没得说。输入 $f$ 只有源域的样本特征了，因为目标域没有标签，监督不了的。只要保证源域上的分类效果良好，由于两类特征被特征提取器  $G_f$ 混淆，所以源域上效果好，目标域上也便于迁移（不知道有没有证明，应该是实验验证）</p></li><li><p>右下角是域分类器 $G_d$，domain的分类器，这个要做对抗的。输入则是源域和目标域的特征，目标是在特征空间上分离两个域的样本，这一点可以和特征提取器 $G_f$ 形成对抗。注意 $G_d$ 和 $G_f$ 中甲有个<strong>梯度反传层（GRL）</strong>，它的结构是</p><blockquote><p>leaves the input unchanged during forward propagation and reverses the gradient by multiplying it by a negative scalar during the backpropagation</p></blockquote></li></ol><p>现在对抗就在这里，因为 $G_f$ 要求两类样本在特征空间中分不开，而 $G_d$ 则反之，所以两部分的loss符号是相反的（可以再加个系数），即 $G_d$ 正常训练，loss符号不变，但是反传梯度的时候，希望 $G_f$ 分离不了样本，梯度是反过来的。</p><p>反应在BP的过程中就是，梯度从最后 $G_d$ 的输出 $L_d$ 开始计算，先正常反传 $G_d$ 上的梯度 $\dfrac{\partial L_d}{\partial \theta_d}$，经过GRL时加个负号（与正系数 $\lambda$），所以在 $G_f$ 上的梯度就是 $\dfrac{\partial L_d}{\partial \theta_f}$。</p><p>进一步地，反应在损失函数中，让我们康康原文 $(18)$ 式：</p><script type="math/tex; mode=display">\displaystyle E = \dfrac{1}{n}\sum_{i=1}^n \mathcal{L}_y (G_y (G_f (x_i; \theta_f); \theta_y), y_i) - \lambda \left(\dfrac{1}{n}\sum_{i=1}^n \mathcal{L}_d (G_d (GRL(G_f (x_i; \theta_f)); \theta_d), d_i) + \dfrac{1}{n^\prime}\sum_{i=n+1}^N \mathcal{L}_d (G_d (GRL(G_f (x_i; \theta_f)); \theta_d), d_i)\right).</script><p>这样 $E$ 就和上面的DANN的三部分分析对上了，$E$ 右端第一项就是分类器 $G_y$ 的分类误差，梯度是正常反传的，所以loss也是正常的形式。$E$ 右端第二项是域分类器的分类误差，但是分为了两部分，括号里第一项中index为从 $1$ 到 $n$ 的求和是源域的样本分类误差，第二项中index为从 $n+1$ 到 $N$ 的求和是目标域的样本分类误差，其中都经过了GRL的作用，此时要求特征提取器 $G_f$性能不行，因此该误差反传时前面是负数。</p><p>现在loss的组成分析完了，但是<strong>对抗体现在loss的哪里</strong>呢？我想了好一会儿…哎呀还是我菜了，对抗体现在 $E$ 的左右两项啊，第一项是正常的，第二项的反过来的嘛，<strong>对抗就是体现在中间那个负号</strong>上~</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;第一次看领域迁移的文章~&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Meta Learning" scheme="http://maxliu245.github.io/tags/Meta-Learning/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="Domain Adaptation" scheme="http://maxliu245.github.io/tags/Domain-Adaptation/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读19】Do We Need Zero Training Loss After Achieving Zero Training Error</title>
    <link href="http://maxliu245.github.io/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB19%E3%80%91Do-We-Need-Zero-Training-Loss-After-Achieving-Zero-Training-Error/"/>
    <id>http://maxliu245.github.io/2020/09/16/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB19%E3%80%91Do-We-Need-Zero-Training-Loss-After-Achieving-Zero-Training-Error/</id>
    <published>2020-09-16T11:05:40.000Z</published>
    <updated>2020-09-16T11:28:45.888Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>一种新的正则方法flooding，相比以往直接考虑控制模型复杂度，flooding考虑的是控制训练loss的水平</p></blockquote><a id="more"></a><img src="/2020/09/16/【论文阅读19】Do-We-Need-Zero-Training-Loss-After-Achieving-Zero-Training-Error/Zero_Training_Loss_No_1.png" title="Title"><h2 id="为什么读"><a href="#为什么读" class="headerlink" title="为什么读"></a>为什么读</h2><p>文献及相关介绍的链接：</p><ol><li><p><a href="https://arxiv.org/abs/2002.08709" target="_blank" rel="noopener">https://arxiv.org/abs/2002.08709</a></p></li><li><p><a href="https://blog.csdn.net/oYeZhou" target="_blank" rel="noopener">叶舟</a>的CSDN博客<a href="https://blog.csdn.net/oYeZhou/article/details/107667317" target="_blank" rel="noopener">一种新的正则化方法——flooding，只需一行代码即可使用</a></p></li><li><p>新智元的知乎文章<a href="https://zhuanlan.zhihu.com/p/203417649" target="_blank" rel="noopener">【论文】一行代码发一篇ICML？</a></p></li></ol><p>至于为什么读这篇文章？🤭，因为看起来简单啊，一行代码写出来的，思想上一定是很有意思的，事实也是如此。只是这个有关训练loss和训练error的讨论让我有点迷糊，放在这里，若干纪元以后再来探访~</p><h2 id="从标题到文章主题"><a href="#从标题到文章主题" class="headerlink" title="从标题到文章主题"></a>从标题到文章主题</h2><p>标题点明了文章讨论的两个概念：<strong>训练loss</strong>和<strong>训练error</strong>之间的关系</p><p>为什么会注意到这两个概念呢？从我个人的观点，<strong>前者有一点泛化</strong>的意思在里面，因为loss大了可能欠拟合，小了可能过拟合，合适的loss水平确实对各种训练方法有点影响（个人经验）；后者其实也有一点泛化的味道，但我更喜欢说它<strong>代表拟合</strong>，理由差不多，error太小了，说明模型把训练数据给背下来了，是大概率过拟合的，毕竟极其强大的网络可以拟合数据，甚至“记住”所有训练数据，达到<strong>训练error=0</strong>，但这显然有点问题，大概率会过拟合。</p><blockquote><p>文章里有一句是别人工作的结论，我觉得不太对劲：</p><p>“learning until zero training error is meaningful to achieve a lower generalization error”</p><p>对此我保留意见，文章略过了这一点，直接开始思考🤔…</p></blockquote><p>这就引出了文章标题的思考：</p><blockquote><p>Q: Do we need zero training loss after achieving zero training error?</p></blockquote><h2 id="从传统正则到针对loss水平"><a href="#从传统正则到针对loss水平" class="headerlink" title="从传统正则到针对loss水平"></a>从传统正则到针对loss水平</h2><p>一般我们会用正则控制模型复杂度（但不是完全控制loss，只是加了一项），但它的出发点不是避免0<strong>训练loss</strong>，所以它其实也控制不了<strong>训练loss</strong>的水平，即往往最后的<strong>训练loss</strong>也会有偏大或偏小的现象，达不到合适的水平。</p><p>另外，一般来说<strong>训练error</strong> $\rightarrow$ 0是可以的，但是当前者达到时，<strong>训练loss</strong>还需要继续下降么，还需要继续训练模型么？</p><blockquote><p>even if we add fooding, we can still memorize the training data</p><p>flooding剑指当<strong>训练error</strong>-&gt;0时，<strong>训练loss</strong>维持在比较小的值而不是0</p><p>假设之前希望<strong>训练error</strong>-&gt;0的那句结论的说法是对的，那么控制<strong>训练loss</strong>的水平确实有点意思，但还要确定这个水平是多少</p></blockquote><h2 id="Flooding正则"><a href="#Flooding正则" class="headerlink" title="Flooding正则"></a>Flooding正则</h2><img src="/2020/09/16/【论文阅读19】Do-We-Need-Zero-Training-Loss-After-Achieving-Zero-Training-Error/Zero_Training_Loss_No_2.png" title="形象的模型描述"><p>针对这一点，提出flooding的方法，如上图很直观啦，这个洪水的水面高度就相当于最终<strong>训练loss</strong>的水平，称为fooding level。思想很简单，就是控制<strong>训练loss</strong>的水平，当loss较高就正常SGD，loss偏低就<strong>反向进行梯度上升</strong>。思路简单的结果是实现极其简单，如下式，变量flood就是新的loss，变量b就是fooding level。一行代码即可且可应用于<strong>一切</strong>以往基于loss梯度下降的方法。</p><script type="math/tex; mode=display">flood = (loss-b).abs()+b</script><p>这样就有个麻烦，这个fooding level<strong>到底是多少</strong>？我们把<strong>训练loss</strong>控制到这个level<strong>为什么能有效</strong>？</p><blockquote><p>In Appendix F, we show that during this period of random walk, there is an increase in fatness of the loss function</p><p>附录F并没有提及理论上为何有效，似乎在附录A有定理证明</p><p>附录F的图看了几遍也没有看明白，可能需要阅读flatness的相关知识吧</p><p>附录A的证明很清晰，表明这种操作是有效的√</p></blockquote><p>那么现在只差fooding level<strong>到底是多少</strong>这个问题了。文章里表示这个可以手动设置，也可以设置验证（文中的实验就是这么做的），或者当作超参数进行超参优化；个人以为还是最后的舒服。</p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>这篇文章有个<strong>有意思的知识点</strong>表一，是许多正则方法的比较，以后需要的话可以看看 √</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;一种新的正则方法flooding，相比以往直接考虑控制模型复杂度，flooding考虑的是控制训练loss的水平&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="Regularization" scheme="http://maxliu245.github.io/tags/Regularization/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读18】Meta-Learning Symmetries by Reparameterization——利用元学习学习保持运算等变性的结构</title>
    <link href="http://maxliu245.github.io/2020/08/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB18%E3%80%91Meta-Learning-Symmetries-by-Reparameterization%E2%80%94%E2%80%94%E5%88%A9%E7%94%A8%E5%85%83%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E4%BF%9D%E6%8C%81%E8%BF%90%E7%AE%97%E7%AD%89%E5%8F%98%E6%80%A7%E7%9A%84%E7%BB%93%E6%9E%84/"/>
    <id>http://maxliu245.github.io/2020/08/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB18%E3%80%91Meta-Learning-Symmetries-by-Reparameterization%E2%80%94%E2%80%94%E5%88%A9%E7%94%A8%E5%85%83%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E4%BF%9D%E6%8C%81%E8%BF%90%E7%AE%97%E7%AD%89%E5%8F%98%E6%80%A7%E7%9A%84%E7%BB%93%E6%9E%84/</id>
    <published>2020-08-31T15:25:27.000Z</published>
    <updated>2020-08-31T16:28:29.773Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>这个文章可是难到我了，谁让年轻的时候抽🐘代数学得菜呢？</p><p>好在可以举例子明白其中的道理┭┮﹏┭┮</p></blockquote><a id="more"></a><img src="/2020/08/31/【论文阅读18】Meta-Learning-Symmetries-by-Reparameterization——利用元学习学习保持运算等变性的结构/MSR.png" title="MSR"><h1 id="为什么读"><a href="#为什么读" class="headerlink" title="为什么读"></a>为什么读</h1><ul><li>元学习新作</li><li>作者之一是Finn啊doge</li></ul><p>文献链接：<a href="https://arxiv.org/abs/2007.02933" target="_blank" rel="noopener">Meta-Learning Symmetries by Reparameterization</a>，原作者提交于2020/07，挂出来了。</p><h1 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h1><p>用强大的神经网络去学习一些参数，它们表示某种变换（如卷积），能对特定的任务（如图像相关）满足某种等变性。</p><p>其实就是<font color="#0000FF">重参数化网络的隐层，学习像卷积这样的运算的模式pattern，可以满足像对图像平移变换的等变性，并利用元学习进一步学习此pattern</font></p><h1 id="文献内容"><a href="#文献内容" class="headerlink" title="文献内容"></a>文献内容</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>和文献总结一致！</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>背景一方面是CNN，可以认为卷积满足对图像平移变换的等变性，如果像卷积这样的运算可以推广，并满足各种特定运算的等变性，那一定是很🐂🍺。</p><p>另一方面是文章里的related work，不过我暂时不感兴趣没看。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>说实话我感觉不好总结，姑且分两个部分，一部分讲等变性对应的代数基础，另一部分讲网络参数设置的形式（以使用元学习训练）。</p><h3 id="等变性的代数理论"><a href="#等变性的代数理论" class="headerlink" title="等变性的代数理论"></a>等变性的代数理论</h3><p>3.2节提到了群卷积是什么，我不（代）太（数）明（太）白（差），举个例子吧。</p><p>网络隐层的输入输出都是空间 $X$ 的函数。比如是 $R^n$ 中一个向量，它相当于一个映射，从指标集 $X={1, \cdots, n}$ 映射到对应的 $n$ 个实数。</p><p>$X$ 上的实值函数集合定义为 $F_X$ ，群 $G$ 作用在 $F_X$ 上，通过 $\pi:G\rightarrow GL(F_X)$，这个 $\pi$ 称为representation，把群 $G$ 中的元素 $g$ 映为 $F_X$ 中的一个可逆线性变换。</p><p>注意 $G$ 对 $X$ 的作用是一个 $g\rightarrow F_X$ 的映射，</p><p>即 $F_X$ 中的可逆线性变换 $f$，当然 $f$ 作用的元素是 $X$ 中的元素 $x$ ，因为 $f$ 是 $X$ 上的实值函数嘛，现在 $\pi(g)$ 是一个可逆线性变换，假设就是 $f$ 的逆变换，所以 $\pi(g)$ 复合 $f$ 是一个函数且是恒等映射，即 $(\pi(g)f)(x) = I(x) = x$</p><p>文章写的符号我没看懂，但是看例子懂了， $G=X$ 时，定义作用为 $R^2$ 上的加法平移，则 $g^{-1}x$ 是 $x-g$ ， $gx$ 是 $x+g$ ，</p><img src="/2020/08/31/【论文阅读18】Meta-Learning-Symmetries-by-Reparameterization——利用元学习学习保持运算等变性的结构/MSR2.png" title="举个例子我就懂啦！"><p>3.3节表示，定义网络隐层为一个函数 $\phi:F_X\rightarrow F_Y$， $G$ 有等变性，举个简单例子， $X$ ， $Y$ 是输入图片网格和输出特征图的网格，所以， $F_X$ 中的元素就是网格大小的图片， $F_Y$ 中的元素就是特征图大小的图片；3式左边就是先对隐层输入做一个平移变换，再输出特征图，右边相当于先输出特征图，再做输出空间上对应的平移变换。</p><p>一个特例是，如果 $\pi$ 是id恒等映射，即 $X$ 、 $Y$ 空间上平移是一致，一样的，那么就叫不变性，先平移再映射和先映射再平移是一样的；注意这里的两个平移现在是数值上相等，但空间是其实分别是 $X$ 和 $Y$ 。</p><p>由于等变性对于函数复合可以保持，那么如果所有隐层都有等变性，那么整个网络也有。</p><p>线性层是基本的层，希望用它学习参数的共同pattern，达到使之有等变性（像群卷积）。</p><p>最后重述一下MSR方法吧，即学习和编码等变性，这个学习就是学习隐层参数的共享pattern，编码是指在代数上找到上文所述的一个灵活的representation。</p><h3 id="网络参数形式"><a href="#网络参数形式" class="headerlink" title="网络参数形式"></a>网络参数形式</h3><p>其实具体的例子参考文中的图1即可。</p><p>4.1节表示，隐层权重矩阵是图1那样形式叠加的矩阵，这就是一种constraint，就是一种pattern，结果是对平移有等变性。现在希望推广到其它的变换，旋转，镜像什么的，但是咱们没有思路怎么去做，所以就用简单的FC层模拟，设置 $y=\phi(x)=Wx, W\in \mathbb{R}^{m\times n}$ ，然后学习 $W$ 就是在学习这个pattern了。</p><p>接着阐释了这个pattern不是直接去学习 $W$ ，这样也看不出有什么pattern。我猜是参考了矩阵分解的概念， $vec(W)=Uv, v\in\mathbb{R}^k, U\in\mathbb{R}^{mn\times k}$ ， $W$ 分解为伪对称矩阵 $U$ 和滤波参数向量 $v$ 的积， $U$ 的维度就是 $W$ 完全展开，再复制个 $k$ 份， $k$ 就是参量 $v$ 的维度，应该可以自行设置。所以pattern实际上就是 $U$ ， $U$ 可以限制最后 $W$ 的形式，滤波参数 $v$也要根据实际任务训练。</p><blockquote><p>For example, the sharing pattern of standard convolution guarantees that the weight matrix is constant along any diagonal, reducing the number of per-task parameters</p></blockquote><p>显然 $U$ 的维度会很高，怎么办？Kronecker factorization，就是参数化的方式，和我之前看的文章和做的实验都是<strong>一致</strong>的想法！</p><p>4.2节继续，那么 $U$ 具体怎么设置呢？和输入的形式有一些关系…举例子吧，从基本的网格空间 $X$ 上选位置，得到输入 $f$ ，即 $f:X\rightarrow R^c$ ，这个输入是向量（矩阵或者矩阵展开应该也行）。假定 $f$ 是 $s$ 维的， $\bar{f}\in\mathbb{R}^s$ ，其中 $\bar{f}_i=f(x_i)$  。引理就是保证了可以由这个 $U$ 保持群的作用，即保持某种运算的等变性；引理分两部分，一部分是给定群后，群的作用就定了，即运算定了，该运算的等变性存在 $U$ 来保持；第二部分是此 $U$ 存在时，任何 $G$ 卷积都可以由 $vec(W)$ 表示出来。所以 $U$ 就设置成一个固定长度的参数向量，把它参数化为矩阵或者向量本身都可以，进一步得到pattern的形式，这样就是能训练的。证明估计我也看不懂了…</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p><ul><li>优点：学习保持等变量性质的参数pattern—&gt;泛化，减少参数用量，适用小样本</li><li>从卷积的应用开始，等变性很重要—&gt;是未来发展的方向之一</li><li>未来自动寻找潜在的特殊结构的算子？像卷积这样的带有等变性的</li><li>quickly discovering symmetries的应用</li></ul><p>缺点：</p><ul><li>我也不知道，可能要根据等变性做监督，训练得到 $U$ 具体的形式，这算不算一种手动设置呢。好吧我其实在杠，还是暂时挑不出毛病</li></ul><h1 id="附录——“快乐”的阅读体验"><a href="#附录——“快乐”的阅读体验" class="headerlink" title="附录——“快乐”的阅读体验"></a>附录——“快乐”的阅读体验</h1><p>我的阅读历程😭😥😪😵，仅个人记录于此，不建议看官阅读…应该看不懂的，只是一些个人阅读思路。<strong>和上文基（是）本（水）重（字）叠（数）</strong>。</p><ul><li><p>标题中什么叫元学习的对称性？</p><p>这里应该<strong>不是</strong>指“元学习有对称性”，而是一个广泛的概念，是要学习<strong>某种</strong>对称性，包括数据本身性质、任务之间关联性，以及某些对数据运算的性质（如旋转镜像这样的运算算子）</p></li><li><p>摘要中：</p><ul><li><p>等变量equivariances是什么意思？</p><p>参考链接<a href="https://zhuanlan.zhihu.com/p/34288976" target="_blank" rel="noopener">CNN 中等变性（equivariant）与不变性（invariant）的关系</a>即可，确实是，经过某些特定运算，特定的输入<strong>模式</strong>能够保持不变</p></li><li><p>感觉文章的<strong>卖点</strong>是从数据（含某种对称性）中（元）学习这个所谓的等变量，学习的方式是用网络<strong>学习等变量对应的parameter sharing patterns</strong>，用参数化形式学习表达出这种模式！</p></li></ul></li><li><p>引言中：</p><ul><li><strong>等变量的起源——CNN</strong>，利用等变量做了某种对称变换，来保护参数，提高泛化能力。什么意思？大概就是卷积（层）这个操作，这个变换允许输入输出的对应变化（平移）有不变性，叫做translation equivariant，即输入（图像）经过特定的平移变换后输出也会经过类似的变换。</li><li>第一段提到了translation equivariant，这是个名词，专指<strong>平移不变性</strong>，不是混淆为广泛的变化！知乎<a href="https://zhuanlan.zhihu.com/p/34288976" target="_blank" rel="noopener">CNN 中等变性（equivariant）与不变性（invariant）的关系</a>讲得很好！</li><li>上面的指CNN利用的卷积，其本身有这种平移不变性，因此在特定任务上（图像相关）表现很好。现在本文试图找其它的内在的等变量。</li><li><strong>目的</strong>出现！引言第3段，在神经网络中<strong>自动学习等变量</strong>。有利于迁移，不需手动设计像卷积这样有平移等变性的算子，直接去寻找等变量。怎么自动学习？<font color="#0000FF">重参数化网络的隐层，以学习表示共享的pattern，并利用元学习进一步学习共同的pattern</font>。</li><li>引言最后一段讲的什么？网络怎么等价于有限对称群？这对称性和拓扑怎么关系上了？抽🐘代数🐕表示很淦…</li></ul></li><li><p>相关工作看不懂，现在懒得看</p></li><li><p>先修知识章节表示3.2、3.3节会给出等变量和群卷积的定义…<strong>早说啊</strong></p><ul><li><p>3.1回顾MAML，这是典型的元学习，MAML也是这样么，和我记的不太一样啊？我要回去重看MAML了，我就记得它是学一个好的初始参数，具体怎么学的忘了</p></li><li><p>3.2，对称性和等变性是群对集合作用的性质…复习一堆拓扑代数知识hahaha…群的定义，加法群…同态，从群 $G$ 映到 $X$ 的自同构群…自同构群，是群 $X$ 到自己的同构变换，且双射…</p></li><li><p>3.2，群卷积是什么，隐层的输入输出都是空间 $X$ 的函数。比如说 $R^n$ 中一个向量相当于一个映射，从指标集 $X={1, \cdots, n}$ 映射到对应的 $n$ 个实数。</p><img src="/2020/08/31/【论文阅读18】Meta-Learning-Symmetries-by-Reparameterization——利用元学习学习保持运算等变性的结构/MSR2.png" title="举个例子我就懂啦！"><p>$X$ 上的实值函数集合定义为 $F_X$ ，群 $G$ 作用在 $F_X$ 上，通过 $\pi:G\rightarrow GL(F_X)$，这个 $\pi$ 称为representation，把群 $G$ 中的元素 $g$ 映为 $F_X$ 中的一个可逆线性变换。</p><p>注意 $G$ 对 $X$ 的作用是一个 $g\rightarrow F_X$ 的映射，</p><p>即 $F_X$ 中的可逆线性变换 $f$，当然 $f$ 作用的元素是 $X$ 中的元素 $x$ ，因为 $f$ 是 $X$ 上的实值函数嘛，现在 $\pi(g)$ 是一个可逆线性变换，假设就是 $f$ 的逆变换，所以 $\pi(g)$ 复合 $f$ 是一个函数且是恒等映射，即 $(\pi(g)f)(x) = I(x) = x$</p><p>文章写的符号我没看懂，但是看例子懂了， $G=X$ 时，定义作用为 $R^2$ 上的加法平移，则 $g^{-1}x$ 是 $x-g$ ， $gx$ 是 $x+g$ ，</p></li><li><p>3.3，定义网络隐层为一个函数 $\phi:F_X\rightarrow F_Y$， $G$ 等变性，举个简单例子， $X$ ， $Y$ 是输入图片网格和输出特征图的网格，所以， $F_X$ 中的元素就是网格大小的图片， $F_Y$ 中的元素就是特征图大小的图片；3式左边就是先对隐层输入做一个平移变换，再输出特征图，右边相当于先输出特征图，再做输出空间上对应的平移变换。</p><p>如果pi_2是id恒等映射，即 $X$ 、 $Y$ 空间上平移是一致一样的，那么就叫不变性，先平移再映射和先映射再平移是一样的；注意这里的两个平移现在是数值上相等，但空间是其实分别是 $X$ 和 $Y$ 。</p></li><li><p>3.3，等变性对于函数复合可以保持，所以如果所有隐层都有等变性，那么整个网络也有。</p></li><li><p>3.3，线性层，研究基本的层，怎么学习参数的共同pattern，达到使之有等变性（群卷积）。</p></li><li><p>3.3，4式什么意思？没细看了，和之前写的3.2的式子应该是一致的</p></li><li><p>MSR方法干什么的：学习和编码等变性，这个学习就是学习隐层参数的共享pattern，编码是指在代数上找到一个灵活的representation</p></li></ul></li><li><p>讲方法了：</p><ul><li><p>4.1，FC层，权重矩阵是那样叠加的矩阵，这就是一种constraint，就是一种pattern，结果是对平移有等变性。现在希望推广到其它的变换，旋转，镜像什么的，但是咱们没有思路怎么去做，所以就用FC层模拟，设置 $y=\phi(x)=Wx, W\in \mathbb{R}^{m\times n}$ ，然后学习 $W$ 就是在学习这个pattern了。</p></li><li><p>接着阐释了这个pattern不是直接去学习 $W$ ，这样也看不出有什么pattern，我猜是参考矩阵分解的概念， $vec(W)=Uv, v\in\mathbb{R}^k, U\in\mathbb{R}^{mn\times k}$ ， $W$ 分解为伪对称矩阵 $U$ 和滤波参数向量 $v$ 的积， $U$ 的维度就是 $W$ 完全展开，再复制个 $k$ 份， $k$ 就是参量 $v$ 的维度，应该可以自行设置。所以pattern实际上就是 $U$ ， $U$ 可以限制最后 $W$ 的形式，滤波参数 $v$也要根据实际任务训练。</p><blockquote><p>For example, the sharing pattern of standard convolution guarantees that the weight matrix is constant along any diagonal, reducing the number of per-task parameters</p></blockquote></li><li><p>显然 $U$ 的维度会很高，怎么办？Kronecker factorization，就是参数化的方式，和之前看的文章和做的实验都是<strong>一致</strong>的想法！</p></li><li><p>4.2，那么 $U$ 具体怎么设置呢？输入的形式…举例子吧，从基本的网格空间 $X$ 上选位置，得到输入 $f$ ，即 $f:X\rightarrow R^c$ ，这个输入是向量（矩阵或者矩阵展开应该也行）。假定 $f$ 是 $s$ 维的， $\bar{f}\in\mathbb{R}^s$ ，其中 $\bar{f}_i=f(x_i)$  。引理就是保证了可以由这个 $U$ 保持群的作用，即保持某种运算的等变性；引理分两部分，一部分是给定群后，群的作用就定了，即运算定了，该运算的等变性存在 $U$ 来保持；第二部分是此 $U$ 存在时，任何 $G$ 卷积都可以由 $vec(W)$ 表示出来。反正就是能训练的。证明估计我也看不懂</p></li></ul></li><li><p>实验日常不想看，但是说实话还是得康康代码的</p></li><li><p>结论：</p><ul><li>优点：学习保持等变量性质的参数pattern—&gt;泛化，减少参数用量，适用小样本</li><li>从卷积的应用开始，等变性很重要—&gt;是未来发展的方向之一</li><li>未来自动寻找潜在的特殊结构的算子？像卷积这样的带有等变性的</li><li>quickly discovering symmetries的应用</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这个文章可是难到我了，谁让年轻的时候抽🐘代数学得菜呢？&lt;/p&gt;
&lt;p&gt;好在可以举例子明白其中的道理┭┮﹏┭┮&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Meta Learning" scheme="http://maxliu245.github.io/tags/Meta-Learning/"/>
    
  </entry>
  
  <entry>
    <title>【NBA2K13】暑期修改历程暂结</title>
    <link href="http://maxliu245.github.io/2020/08/30/%E3%80%90NBA2K13%E3%80%91%E6%9A%91%E6%9C%9F%E4%BF%AE%E6%94%B9%E5%8E%86%E7%A8%8B%E6%9A%82%E7%BB%93/"/>
    <id>http://maxliu245.github.io/2020/08/30/%E3%80%90NBA2K13%E3%80%91%E6%9A%91%E6%9C%9F%E4%BF%AE%E6%94%B9%E5%8E%86%E7%A8%8B%E6%9A%82%E7%BB%93/</id>
    <published>2020-08-30T02:28:33.000Z</published>
    <updated>2020-08-30T02:31:09.169Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>暑期真的花了很多时间在整理更新数据上，修改的过程真的快乐，但也不能老是沉迷其中啦😂</p></blockquote><a id="more"></a><h1 id="个人感想"><a href="#个人感想" class="headerlink" title="个人感想"></a>个人感想</h1><p>最近相当长的一段时间内，我很癫狂地玩起了NBA2K13（Android），并大量修改其中的球员数据。不得不说，这款老游戏深得我的喜爱，大概是单纯由于我喜欢模拟类、角色扮演类的游戏，以及这款游戏的引擎恰巧很符合我的口味吧。临近开学季，我恐怕不能再抽出这么多时间来体验<font color="#0000FF">修改</font>（其实是无root移植）的乐趣了，因此打算稍微总结这近2个月来的游戏体验。</p><p>总的来说，这2个月以来，基于KM2BY的2.20数据包和4.05存档，在无root条件下，我先后一共完成了独行侠、鹰、鹈鹕、太阳、掘金、篮网、76人、快船、湖人、森林狼和猛龙共11支球队绝大多数球员的更新修改，以及魔术和开拓者24球队少部分核心球员的数据更新。</p><p>修改完每支球队后，我都会自己开一个赛季模式动手打几场比赛（均为全明星难度），来测试修改后的可玩性（不包括模拟的真实性），然而直到现在，只有5支球队的游戏体验良好，分别是76人、独行侠、湖人、开拓者和猛龙，这其中，76人和开拓者完全是核心球员刷数据带飞；独行侠和湖人由于角色球员较强，相对来说可玩性还是稍强一些；最后单独拎出猛龙是因为目前我只上手玩了一把，这个球队防守强度太高了，导致游戏比较轻松😂，有点“兄弟篮球，人人🐂🐸”那味儿了，后续我会多测试几次来确认可玩性。</p><p>一般来说，修改后的阵容有这样的优缺点（对比）：</p><div class="table-container"><table><thead><tr><th>自己操作</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td></td><td>核心球员在自己家比较给力，一般能稳住局势</td><td>对面球队有且存在不只1个核心并无限单人打爆自己…手段包括但不限于无限轻松上篮得分（或造犯规）、高频率抢断+盖帽…</td></tr><tr><td></td><td>拥有极强核心的强队游戏难度低</td><td>这样强队玩几局就腻了</td></tr><tr><td></td><td>有3分强球员的球队为所欲为</td><td>这些球员在自己手里容易n中0，在对面容易超神</td></tr><tr><td></td><td>大量角色球员会增强真实感</td><td>角色球员在自己家大部分都拉跨，在对面就很无敌…</td></tr><tr><td>模拟</td><td>真实性可以大大增强</td><td>需要手动调整球员倾向，比较麻烦</td></tr></tbody></table></div><p>一时间只想出来这么些体验方面的对比，就先放在这里。玩几个强队的时候都还行，只要雪球滚起来，分差拉开，后面就会轻松，但也经常会被对面打出各种小高潮以及末节究极被追分；玩弱队的时候体验极差，各种无限被抢被掏被帽被造犯规被轻松突破，自己进攻总是进攻犯规或者常常强打被按下来，或者干脆就攻不进去。玩了好几个这样的球队，甚至包括部分所谓的强队也有这样的感受，我觉得重要的原因是这些球队球员修改的进攻防守意识数值都不够，另外是普遍移动速度太慢，最后是没有稳定射手或稳定内线大闸。没有第一点，玩起来就总是核心刷数据；没有第二点，玩起来就是根本突不进去，尤其包括快攻的进攻效率低下；没有第三点，进攻端或者防守端必有一端拉跨，降低游戏体验。</p><h1 id="实战演示"><a href="#实战演示" class="headerlink" title="实战演示"></a>实战演示</h1><p>由于测试的次数不多且时间间隔有点长了，所以只列两个最近修改的球队，森林狼（弱队代表）和猛龙（强队代表）的比赛感受。</p><p>首先是森林狼，核心包括唐斯、拉塞尔、马利克比斯利和詹姆斯约翰逊，其他人要拉跨很多；主要弱点有2，一是射手太少，只有比斯利能顶一下，二是球队球员移动速度普遍较低（掘金、鹰、太阳也是这样）。自己上手比赛，和13年的球队比较，目前只赢过一把，其它全部头被🔨爆…</p><img src="/2020/08/30/【NBA2K13】暑期修改历程暂结/1.jpg" title="13版尼克斯VS20版森林狼——尼克斯数据"><img src="/2020/08/30/【NBA2K13】暑期修改历程暂结/2.jpg" title="13版尼克斯VS20版森林狼——森林狼数据"><p>只有这一把打赢了，赢的因素（对比后来输的比赛可以看看被打得多惨😭）主要在于：</p><ul><li>自己的球队因素：<ul><li>绝对核心唐斯在攻防两端表现稳定，拉塞尔没有受到犯规困扰，组织上没有被频繁断球</li><li>角色球员有所发挥，前期约翰逊强打内线稳住了比分，中后期比斯利抓住了几次快攻机会没有被帽</li><li>底层的替补竟然得分能超过5分了😱（气抖冷doge！我替补板凳何时在游戏里站起来！）</li></ul></li><li>对面球队因素：<ul><li>甜瓜由于在开拓者，能力值已经根据存档削弱，这次得分不算很高了</li><li>基德前期犯了好几次规，第一节让我滚了点雪球</li><li>其它球员都算是角色球员，没有那么恐怖…</li></ul></li></ul><p>输的局反正就是要么被对面n核心直接🔨爆，要么就是被无限突破+抢断+盖帽…被玩坏了…</p><p>———————————————- 手动分割线 ———————————————-</p><p>最后是刚弄的猛龙，虽然核心球员的能力值都不算顶尖，但是有不少能高于80了；角色球员的防守能力、意识都相对很不错，球队整体防守目前来看非常好；球队有一堆射手啦，虽然实战投射前期雪崩，后面才慢慢能投一些…</p><img src="/2020/08/30/【NBA2K13】暑期修改历程暂结/3.jpg" title="20版开拓者（只有利拉德）VS20版猛龙——前3节猛龙部分数据"><img src="/2020/08/30/【NBA2K13】暑期修改历程暂结/4.jpg" title="20版开拓者（只有利拉德）VS20版猛龙——前3节猛龙射手数据"><img src="/2020/08/30/【NBA2K13】暑期修改历程暂结/4.jpg" title="20版开拓者（只有利拉德）VS20版猛龙——全场统计"><p>这场测试比赛的感受就是，哇塞，防守太舒服了！球队的篮板球实在是舒服，从半场的篮板看就…是不是猛得过头了…当然前几节射手的效率实在是…有空位竟然也投不进…可能是和身高有点关系吧，游戏里范弗里特的这三分是惊到我了…</p><p>哎呀呀，总之就是修改游戏的过程很快乐，但是手打的体验没有那么好😂。接下来要收手了，再着迷在这上面就没有工作学习的时间啦🤾‍♂️</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;暑期真的花了很多时间在整理更新数据上，修改的过程真的快乐，但也不能老是沉迷其中啦😂&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="NBA2K13" scheme="http://maxliu245.github.io/tags/NBA2K13/"/>
    
      <category term="DIY" scheme="http://maxliu245.github.io/tags/DIY/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读17】ODE-Net——从离散化的ResNet到连续化ODE的模拟</title>
    <link href="http://maxliu245.github.io/2020/08/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB17%E3%80%91ODE-Net%E2%80%94%E2%80%94%E4%BB%8E%E7%A6%BB%E6%95%A3%E5%8C%96%E7%9A%84ResNet%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%8C%96ODE%E7%9A%84%E6%A8%A1%E6%8B%9F/"/>
    <id>http://maxliu245.github.io/2020/08/21/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB17%E3%80%91ODE-Net%E2%80%94%E2%80%94%E4%BB%8E%E7%A6%BB%E6%95%A3%E5%8C%96%E7%9A%84ResNet%E5%88%B0%E8%BF%9E%E7%BB%AD%E5%8C%96ODE%E7%9A%84%E6%A8%A1%E6%8B%9F/</id>
    <published>2020-08-21T11:12:27.000Z</published>
    <updated>2020-08-21T11:16:21.590Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>读不懂PDE-Net，所以想先操作下ODE-Net</p><p>结果是瞎读文章真心难读也读不明白😭😭😭</p></blockquote><a id="more"></a><img src="/2020/08/21/【论文阅读17】ODE-Net——从离散化的ResNet到连续化ODE的模拟/ODE-Net.png" title="ODE-Net"><h1 id="为什么读"><a href="#为什么读" class="headerlink" title="为什么读"></a>为什么读</h1><ul><li>在阅读PDE-Net的时候被卡了，读得比较不明白，在搜资料的时候发现了知乎上ODE-Net的<a href="https://www.zhihu.com/question/313064079" target="_blank" rel="noopener">讨论</a>，好介绍哇，觉得现在先看ODE-Net是个不错的选择</li><li>搜资料的时候才发现这是NIP2018最佳论文</li></ul><p>文献链接：<a href="https://arxiv.org/abs/1806.07366" target="_blank" rel="noopener">Neural Ordinary Differential Equations</a>，原作者提交于2018/01，最后修改于2019/12，可见打磨的功夫还是下了不少的。</p><h1 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h1><p>将ODE与神经网络结合，用神经网络来模拟ODE的动态性质。</p><p>思想很简单，联想神经网络的隐层嵌套性，联系ResNet的残差（差分）形式并推广，就得到了利用ResNet模拟ODE的思想。细节就麻烦多了看不动看不动…</p><h1 id="文献内容"><a href="#文献内容" class="headerlink" title="文献内容"></a>文献内容</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>将ODE与神经网络结合，用神经网络来模拟ODE的动态性质，和总结一致。</p><p>另外如果能有办法用网络模拟ODE系统，那一定是应用超级友好的！</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>好像没啥背景，我理解的背景就是这个思想的来源，就够了。文章里的related work我暂时不感兴趣。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>这要从ODE与神经网络的一个共性讲起：</p><p>神经网络的嵌套隐层结构可以表示为$h<em>{t+1} = f(h_t, \theta_t)$，每一层都由前一层前向传播得到，现在用ResNet的结构则有意思起来了：$h</em>{t+1} = h_t + f(h_t, \theta_t)$，这种残差的形式与ODE的差分形式很“相似”：</p><script type="math/tex; mode=display">\Delta h(t) = h_{t+1} - h_t = f(h(t), t, \theta) \approx \dfrac{dh(t)}{dt}</script><p>这样ResNet的每一层$f$都相当于当前时刻$t$的一个差分，如果这个$t$不再离散，而是连续化，那么就可以近似为导数，残差神经网络也可以近似为ODE了。当然<strong>前提</strong>是（1）连续化可行；（2）连续化后能保持ODE的基本衍化性质；（3）不知道能不能证明其它性质诸如求解等等。</p><p>那么现在基本的模型其实已经构思好了，下面是实现的技术细节。要使得ResNet成为ODE的近似，首先要考虑可训练的性质，其监督信息由已知的ODEsolver求解，这些solver目前一般都是精度可控的，网络本身作为一个黑箱ODEsolver来训练；前向传播应该比较容易，关键是反向传播会比较麻烦，因为损失的回传需要对参数求导，这些势必要涉及大量参数，会引起高昂的计算代价。</p><p>那么该文怎么进行反向传播的呢，直接算？不是，它绕过去了。</p><p>先看看损失函数，直接定义为：</p><script type="math/tex; mode=display">L(z(t_1)) \approx L\left(z(t_0) + \int_{t_0}^{t_1} f(z(t), t, \theta)dt \right) = L(ODESolve(z(t_0), f, t_0, t_1, \theta))</script><p>其中把ODE最后的target函数记为$z(t)$，ODE初值记为$z(t_0)$，待预测的时刻$t_1$时的值为$z(t_1)$。左边相当于监督信息，用标准的值，右边两个式子都用黑箱网络来近似就可以了。</p><p>由于现在考虑把ResNet变成连续化的模型，因此此时不好用差分的形式，而要采用积分的形式，所以现在预测值是和时刻$t_0$和$t_1$中每个值都要有关系，这提示我们采用链式法则寻找这些值之间的关系。当然这些值太多乃至无穷，我们也只能尽可能多地进行离散近似，其实就是网络的深度（层数），有几层，就意味着我们考虑了时刻$t_0$和$t_1$之间几个中间状态。</p><p>这种近似考虑的方式称为<strong>adjoint sensitivity method</strong>（1962老文章🐂🍺+🐂🐸！），如下的原文图2所示，这里为了表示方便，记号与上文不同，图中的$z(t_N)$相当于上文的$z(t_1)$，意思大家一定能明白，就是多考虑上文中的中间时刻状态。</p><img src="/2020/08/21/【论文阅读17】ODE-Net——从离散化的ResNet到连续化ODE的模拟/ODE-Net2.png" title="Adjoint Sensitivity Method"><p>感觉是这样推导的，我们想要的目标是损失$L$对网络参数$\theta$的导数：</p><script type="math/tex; mode=display">\dfrac{dL}{d\theta} = \dfrac{dL}{dz(t_i)}\dfrac{dz(t_i)}{d\theta} = \dfrac{dL}{dz(t_i)}\dfrac{df(z(t_i), t_i, \theta)}{d\theta} \triangleq a(t_i)\dfrac{df(z(t_i), t_i, \theta)}{d\theta}</script><p>其中第一个等号用链式法则和爱因斯坦求和约定表示；第二个等号是因为$z(t<em>i) \approx z(t_0) + \int</em>{t_0}^{t_i} f(z(t), t, \theta)dt$，然后直接求导就得了，其中积分从哪里开始都可以，不一定要$t_0$；第三个等号搞了新定义，把$a(t)$叫做伴随adjoint，它怎么求呢，文章给了$\dfrac{da(t)}{dt} = -a(t)^T\dfrac{\partial f(z(t), t, \theta)}{\partial z}$，但我没看懂，我猜是1962那篇文章的结论。</p><p>上面分析了主要的思路，应该还可以了，下面开始水😂，日常写烂尾文章/(ㄒoㄒ)/~~</p><p>上面的推导就是原文的(5)式，具体计算不是直接BP，因为考虑连续性，和中间状态都有关系了，中间层现在是可以很多的，BP压力很大。现在直接看完整版的算法2，直接想办法计一个积分算梯度（参考了机器之心的文章加深理解），不过很可惜我<strong>没太看明白</strong>具体计算的过程，可能是直接自动求导，只是不再一层一层计算梯度了？这样真的能减少计算量么？</p><p>后面的流模型和生成式模型没有看了，留着看苏剑林的博客吧，感觉和那个关系比较大。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>我理解的优点：</p><ul><li>应用必定是真正有用的应用，且范围很广，涉及ODE的领域实在是太多啦</li><li>思路很棒！从ResNet的差分形式过渡到ODE的模拟，我很喜欢</li><li>文章提到的内存占用小的优点，不过有人杠这一点，我目前没看明白算法2，只好持保留态度了</li></ul><p>缺点：</p><ul><li>有人杠他们的代码和文章不一致（知乎），我先吃瓜瓜</li><li>算法写的有一点不明白，起码我看了几遍没明白具体是怎么算法（不考虑伪代码）</li><li>原作者之一自己提的缺点，见参考资料<a href="https://www.sohu.com/a/405309910_129720" target="_blank" rel="noopener">「神经常微分方程」提出者之一David Duvenaud：如何利用深度微分方程模型处理连续时间动态</a></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>看不动，和参考资料里的是一样的啊，而且有评论说作者放出来的代码和文章不一致，那么轻松复现是不存在的了…</p><p>扫了一眼，文章的实验主要是模拟了一些不那么复杂，但也不是很简单的ODE系统。</p><h1 id="补充资料——参考链接阅读"><a href="#补充资料——参考链接阅读" class="headerlink" title="补充资料——参考链接阅读"></a>补充资料——参考链接阅读</h1><p>在略读了文章第一遍之后有些疑惑，因此搜了一些相关的网页看一看，觉得其中大部分讲的都不错，因此记录于此。</p><ul><li>看了一遍作者<a href="https://www.jiqizhixin.com/users/b0254ca0-165f-4fd3-a041-232d39a848d2" target="_blank" rel="noopener">思源</a>发布在机器之心的文章<a href="https://www.jiqizhixin.com/articles/122302" target="_blank" rel="noopener">硬核NeruIPS 2018最佳论文，一个神经了的常微分方程</a>，前面的解释比较足，有了大致的了解，还有不少细节是不太明白的</li><li>看了知乎上的<a href="https://www.zhihu.com/question/306937011/answer/561576636" target="_blank" rel="noopener">如何评价ODENet？</a>，反对的意见要注意，我看文章的时候觉得它说避免了存储中间计算的值，减少内存使用，而算法中反向计算的时候其实还要算一遍，这个说法很奇怪。目前我感觉确实是代码中，这部分计算没有交给网络，而是交给scipy了。</li><li>看了机器之心在搜狐上的文章<a href="https://www.sohu.com/a/405309910_129720" target="_blank" rel="noopener">「神经常微分方程」提出者之一David Duvenaud：如何利用深度微分方程模型处理连续时间动态</a>，了解了一些该团队最新进展，包括可逆残差网络、设计廉价的可微算子计算梯度、随机微分方程的应用；并看到了有趣的“内幕”哈哈，担心侵权问题就不放原文了，大概意思是他们这篇文章动机很现实，而且有一些数学上比较严肃的问题：</li><li><a href="https://www.toutiao.com/a6703302712311677452/" target="_blank" rel="noopener">一个深度学习突破的方向：神经常微分方程ODE</a>这个文章<strong>内容很多</strong>啊，有不少自己尝试的实验，只简单介绍了ODE-Net的思想，然后自己做了不少拟合的实验，最后给了自己的结论太棒了！它的结论是目前该方法只在小任务上表现良好，实际应用或者稍复杂的例子就会gg😀</li><li>本来想读<a href="https://blog.csdn.net/hanss2/article/details/81301343" target="_blank" rel="noopener">【随感】ODE的欧拉解法实际上就是RNN的一个特例</a>这篇文章，结果发现是转载苏剑林的博客<a href="https://kexue.fm/archives/5643" target="_blank" rel="noopener">貌离神合的RNN与ODE：花式RNN简介</a>，除了开头的时候提了一小句来源，其它是一模一样的，不过我发现这个作者其它内容写得很有趣，很有想法啊👍。<strong>这个RNN的很有意思，有空要读一读在这里做个笔记</strong>。</li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt and David Duvenaud. Neural Ordinary Differential Equations[EB/OL]. <a href="https://arxiv.org/abs/1806.07366" target="_blank" rel="noopener">https://arxiv.org/abs/1806.07366</a>, 2018.</p><p>[2] 思源.硬核NeruIPS 2018最佳论文，一个神经了的常微分方程[EB/OL]. <a href="https://www.jiqizhixin.com/articles/122302" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/122302</a>, 2018/12/23.</p><p>[3] 匿名用户. 如何评价ODENet？[EB/OL]. <a href="https://www.zhihu.com/question/306937011/answer/561576636" target="_blank" rel="noopener">https://www.zhihu.com/question/306937011/answer/561576636</a>, 2018-12-30.</p><p>[4] 机器之心Pro. 「神经常微分方程」提出者之一David Duvenaud：如何利用深度微分方程模型处理连续时间动态[EB/OL]. <a href="https://www.sohu.com/a/405309910_129720" target="_blank" rel="noopener">https://www.sohu.com/a/405309910_129720</a>, 2020-07-02.</p><p>[5] AI火箭营. 一个深度学习突破的方向：神经常微分方程ODE[EB/OL]. <a href="https://www.toutiao.com/a6703302712311677452/" target="_blank" rel="noopener">https://www.toutiao.com/a6703302712311677452/</a>, 2019-06-17.</p><p>[6] 苏剑林. (2018, Jun 23). 《貌离神合的RNN与ODE：花式RNN简介 》[Blog post]. Retrieved from <a href="https://kexue.fm/archives/5643" target="_blank" rel="noopener">https://kexue.fm/archives/5643</a></p><p>最后一条按照原文提供的参考文献格式了~</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;读不懂PDE-Net，所以想先操作下ODE-Net&lt;/p&gt;
&lt;p&gt;结果是瞎读文章真心难读也读不明白😭😭😭&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读16】Isolation Forest——孤立的异常检测方式</title>
    <link href="http://maxliu245.github.io/2020/08/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB16%E3%80%91Isolation-Forest%E2%80%94%E2%80%94%E5%AD%A4%E7%AB%8B%E7%9A%84%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%96%B9%E5%BC%8F/"/>
    <id>http://maxliu245.github.io/2020/08/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB16%E3%80%91Isolation-Forest%E2%80%94%E2%80%94%E5%AD%A4%E7%AB%8B%E7%9A%84%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%96%B9%E5%BC%8F/</id>
    <published>2020-08-19T01:55:26.000Z</published>
    <updated>2020-08-19T02:07:45.693Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>这次在网上学习别人记笔记的方式，感觉很有意思，不知道我能从中学到多少。可惜markdown做富文本表格太麻烦了…但是用别的，比如word、pdf，都不方便即时打开。。。算了吧，选择了markdown还是按标题目录来整理笔记</p></blockquote><a id="more"></a><img src="/2020/08/19/【论文阅读16】Isolation-Forest——孤立的异常检测方式/1.png" title="文章简介"><h1 id="为什么读此文章"><a href="#为什么读此文章" class="headerlink" title="为什么读此文章"></a>为什么读此文章</h1><p>原因有二：</p><ul><li>是我最早接触的论文之一，当年没看，现在拿来读一下，本来想略读，然后就忍不住多看了几遍…</li><li>周志华是作者之一，应该很顶</li></ul><p>文献链接：<a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf?q=isolation-forest" target="_blank" rel="noopener">Isolation Forest</a></p><h1 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h1><p>孤立森林是一种异常检测方法，侧重以孤立的方式直接寻找异常而非比对正常样本。</p><p>这个孤立的思想很棒，少了很多计算的步骤，但同时有很棒的准确性，毕竟基于的是异常本身的重要性质。</p><h1 id="文献内容"><a href="#文献内容" class="headerlink" title="文献内容"></a>文献内容</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>给异常检测领域提供一种新方法——孤立森林。</p><p>该方法来源于以往没人用过的孤立的思想来做异常检测，且可以发现由此提出的孤立森林有诸多优点。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul><li>大方向是<strong>异常检测</strong>，看着就知道很重要</li><li>传统的（模型驱动的）异常检测方法把测试样本与已知正常样本对比，不符即为异常。这个想法很基础很实在√</li><li>上面方法的缺点有2，1是<strong>泛化不好</strong>，因为方法效果与正常样本库相关；2是<strong>计算代价大</strong>，往往只能用于低维小规模数据，因为这些方法常常用到距离等度量方式</li><li>在此提出并使用<strong>孤立</strong>的概念，把异常点孤立于其它正常样本。思想是利用了异常的2个性质，1是它们真的只是少数；2是特征与正常样本必是不同的。由此思想，用树来孤立异常数据，异常数据会在树根部被孤立，正常样本只会在深处被孤立。</li></ul><h2 id="方法——从孤立树到孤立森林"><a href="#方法——从孤立树到孤立森林" class="headerlink" title="方法——从孤立树到孤立森林"></a>方法——从孤立树到孤立森林</h2><ul><li>孤立森林是什么：<ul><li>背景提到了孤立树的概念，集成起来就是孤立森林。孤立森林方法只有2个变量，1是树的个数，2是sub-sampling size，一开始我猜这个size翻译为二次采样的size，做一次全分割用的样本数；后来我发现我猜错了，在文章第3章中说明了这个是可以设置多个树，相当于多个异常检测专家，分别随机取一部分数据来检测异常，这些数据的size叫sub-sampling size，至于为什么将在优缺点部分介绍。</li><li>异常的2个性质体现在孤立分割上就是，异常越少，所需分割次数就越少；以及异常会早早被割出来，即异常的平均路径长度average path lengths短，图1很形象。</li></ul></li><li>孤立树是什么：<ul><li>先给出基本数据假设：数据集$X={x_1, \cdots, x_n}$，$n$个样本，每个样本是$d$维的，有$d$个分量。</li><li>首先是一棵树，然后在这里，是特定的一种树。用节点来描述，它的节点$T$只有两种，一种是外部节点，就是接下来没有分支了；第二种是内部节点，且分支有且只有两个子节点$(T_l, T_r)$，即左右子节点。</li><li>那么数据集X的孤立方式是，每次随机孤立一个分量，如第$q$个，孤立的分割阈值是$p$，这样把数据分为两部分。多次孤立的停止条件有：<ul><li>树达到临界高度</li><li>最后只有一个点了，即$|X|=1$</li><li>所有数据都只有一个值，没法孤立</li></ul></li></ul></li><li><p>异常的判定——异常score：</p><ul><li>有了方法的概念和方法的构成单元，下面说方法的度量，即怎么样算是异常。基本的想法是path（路径）长度：样本$x$的路径长度记为$h(x)$，在树上，$x$被孤立出来需要的分割次数。但是这个$h(x)$不好，因为这个$h(x)$算不算异常也要看整个树的深度、样本量什么的；因此需要一般性的异常score作为度量。</li><li>这个score来源于BST，二元搜索树，因为发现孤立树和BST有相似的性质。借BST文章的结论，其不成功搜索的路径长度$c(n)$与这里的$h(x)$类似，于是采用(1, 2)式的形式计算了此异常score $s(x, n)$。个人感觉就是$h(x)$不general，引用$c(n)$给它做了某种标准化。图2和图3解释得非常好，一目了然，分别介绍了定性的$s(x, n)$合理性和类似等高线的异常判断方式。</li></ul></li></ul><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li>孤立森林与已有方法主要区别：<ul><li>它可以利用sub-sampling，<strong>这个sub-sampling指什么？</strong>，是只用一部分数据就可以了，体现在孤立森林的局部：孤立树的使用上；如果数据多，往往树越深，正常样本也多，往往难以检测出异常。具体有两种情形——swamping and masking，分别指错把正常样本识别为异常，和异常点太多，比如扎堆出现，一看还以为都是正常的，其异常性被数量掩盖了。针对它们，只要取一部分数据就可以得到更好的效果，文章第3章画了两张图，非常形象地阐述了机理👍！</li><li>不需要计算什么距离、密度，大大降低计算复杂度</li><li>由集成的优点，大的森林可以处理大量数据了，包括高维情形</li></ul></li><li>孤立森林的优点：<ul><li>线性时间的复杂度，对运算内存的要求为很低的常数。1个原因是不需要计算什么距离、密度，<strong>另一个原因</strong>是按照方法中孤立的方式，即使树是完全树，最多（每次只孤立1个点）的内部节点有$n-1$个。最多的全部节点有$n-1+n=2n-1$个（自己画个图就知道了），所以对变量的内存要求是有界的，与样本量呈线性关系。</li><li>首次把孤立应用于异常检测，似乎用了二次采样，其它已有方法不行</li><li>它的2个变量都比较小，就可以表现优异</li></ul></li></ul><h2 id="实验——如何训练孤立森林"><a href="#实验——如何训练孤立森林" class="headerlink" title="实验——如何训练孤立森林"></a>实验——如何训练孤立森林</h2><p>和一般的机器学习方法类似，先训练出一个孤立森林模型，再拿测试数据测试。</p><ul><li><p>训练总体的算法是孤立树的集成——孤立森林，为算法1，递归式地分割数据集</p><ul><li>算法1中包括算法2，单颗孤立树的训练，这些都已经说过了。</li><li>算法1、2中有3个参数要提前设置：子采样数、树的最大深度和树的棵树，这些都根据实验经验确定，子采样数默认$\psi=256$，深度默认$l=ceiling(\log_2 \psi)$，棵树默认$t=100$。</li></ul></li><li><p>最后测试的时候计算的score要一直到被孤立出去，且使用递归的方式一点点计算。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这次在网上学习别人记笔记的方式，感觉很有意思，不知道我能从中学到多少。可惜markdown做富文本表格太麻烦了…但是用别的，比如word、pdf，都不方便即时打开。。。算了吧，选择了markdown还是按标题目录来整理笔记&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="Abnormality Detection" scheme="http://maxliu245.github.io/tags/Abnormality-Detection/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读15】Dual-Adversarial-Network-Toward-Real-world-Noise-Removal-and-Noise-Generation</title>
    <link href="http://maxliu245.github.io/2020/07/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB15%E3%80%91Dual-Adversarial-Network-Toward-Real-world-Noise-Removal-and-Noise-Generation/"/>
    <id>http://maxliu245.github.io/2020/07/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB15%E3%80%91Dual-Adversarial-Network-Toward-Real-world-Noise-Removal-and-Noise-Generation/</id>
    <published>2020-07-31T10:01:04.000Z</published>
    <updated>2020-08-02T17:01:16.804Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>论文阅读</p></blockquote><a id="more"></a><h2 id="文章简介"><a href="#文章简介" class="headerlink" title="文章简介"></a>文章简介</h2><p>这篇文章[3]是在ECCV2020的日程[1, 2]中发现的，拿来一读。</p><p>原作者的部分讲解视频在B站BAAI发布的<a href="https://www.bilibili.com/video/BV1wZ4y1M7qw?p=4" target="_blank" rel="noopener">ECCV 2020中国预会议回放丨计算机视觉、目标检测、图像分类、特征提取…55场前沿学术报告集萃</a>P4的181:40-192:00。</p><p>从标题上看是提出了一个对抗网络的变种，<font color="#0000FF">双重对抗网络DANet</font>，针对真实场景，<strong>同时建模（生成）噪声以及去噪</strong>。</p><img src="/2020/07/31/【论文阅读15】Dual-Adversarial-Network-Toward-Real-world-Noise-Removal-and-Noise-Generation/1.png" title="文章简介"><h2 id="主要内容——DANet"><a href="#主要内容——DANet" class="headerlink" title="主要内容——DANet"></a>主要内容——DANet</h2><p>ps:</p><blockquote><p>主要内容直接参考B站视频或者原文即可。</p><p>个人不太想看相关工作的部分，只看了噪声生成的介绍，模拟噪声分布的目的之一是解决数据对的成本问题。其中传统方法GAN的难度在于如何找到好的噪声生成器。</p></blockquote><h3 id="模型提出"><a href="#模型提出" class="headerlink" title="模型提出"></a>模型提出</h3><p>本文的主要思想与之前的<a href="[https://maxliu245.github.io/2020/06/27/10-VDN-Variational-Denoising-Network-%E9%98%85%E8%AF%BB/#more](https://maxliu245.github.io/2020/06/27/10-VDN-Variational-Denoising-Network-阅读/#more">VDN</a>)[4]如出一辙，感觉是顺着VDN在贝叶斯框架下同时进行图像噪声估计和图像降噪的思路继续做的。主要内容是提出了双重对抗网络<strong>DANet</strong>，下面具体介绍一下。</p><p>相比VDN直接贝叶斯框架完成两种噪声相关任务，这次是间接地、从另一个角度地对干净图$x$和带噪图$y$的联合分布$p(x,y)$进行估计，并分两种分解形式。因此从两个方面分别建模，从$y$开始建模，生成$x$的过程就是训练了降噪器$R$，反之就是训练了噪声生成器$G$；两种方式逼近联合分布后通过判别器$D$做监督。这种方式称为标题的“双重对抗”，$R$和$G$相互影响，共同逼近联合分布。</p><p>$x$，$y$联合分布的两种分解很自然，从联合分布定义即可，实际意义参考视频中的图即可理解：</p><img src="/2020/07/31/【论文阅读15】Dual-Adversarial-Network-Toward-Real-world-Noise-Removal-and-Noise-Generation/2.png" title="联合分布$p(x,y)$的两种分解意义"><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>接下来确定对抗网络的结构：</p><img src="/2020/07/31/【论文阅读15】Dual-Adversarial-Network-Toward-Real-world-Noise-Removal-and-Noise-Generation/3.png" title="网络结构"><p>其中降噪器denoiser记为$R$，噪声生成器generator记为$G$，都用UNet，并加了残差策略；最后判别器discriminator记为$D$，采用5个卷积层和一个FC。</p><h3 id="部分训练细节"><a href="#部分训练细节" class="headerlink" title="部分训练细节"></a>部分训练细节</h3><p>训练的目标函数是Triple-GAN中提出的损失，加上两个正则项（对应于两种分解）。前者是干净图的$L_1$损失，可以优化$R$；后者由于噪声随机性，采用高斯滤波后的某种$L_1$，优化$G$，具体形式参考原文(6)式。</p><p>网络训练的过程参考原文算法1即可，其训练的思路在于向后传播分两步，交替优化$R$和$G$。</p><h3 id="部分亮点"><a href="#部分亮点" class="headerlink" title="部分亮点"></a>部分亮点</h3><p>首先是继承VDN的思路，同时完成两个噪声相关任务。</p><p>其次是在概率框架下从两种联合分布分解形式的角度设计了DANet。</p><p>再者是设计了两种噪声生成质量的度量，比较了真实带噪图和生成带噪图的相似性：</p><ul><li><p><strong>PGap </strong>(PSNR Gap)：借用降噪指标PSNR设计。已知训练集$\mathcal{D}$和测试集$\mathcal{T}$，分别是一堆成对干净图和带噪图，用准备好的噪声生成器$G$，对训练集进行加噪，得到生成的新训练集$\mathcal{D}_G$，准备原始训练数据上训练得到的降噪器$R_1$和在新训练集$\mathcal{D}_G$上得到的降噪器$R_2$，分别计算测试集上的PSNR，其差值小，代表噪声生成得越好，越接近真是噪声分布。</p><script type="math/tex; mode=display">PGap = PSNR(R_1(\mathcal{T})) - PSNR(R_2(\mathcal{T}))</script></li><li><p><strong>AKLD</strong> (Average KL Divergence)：这个比较直接，希望生成噪声的分布与其真实分布接近。真实的分布用了VDN的结论，然后采样；这里的分布是由生成器$G$对应的新分布，都通过采样近似。</p></li></ul><h2 id="DANet-V-S-VDN"><a href="#DANet-V-S-VDN" class="headerlink" title="DANet V.S. VDN"></a>DANet V.S. VDN</h2><p>与VDN的区别？难道是VDN传统贝叶斯框架条件后验，这个直接联合分布？主要区别好像是的耶~</p><blockquote><p> 参考摘要</p><p>Instead of only inferring the posteriori distribution of the latent clean image conditioned on the observed noisy image in traditional MAP framework, our proposed method learns the joint distribution of the clean-noisy image pairs.</p></blockquote><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>[1] BAAIBeijing. 计算机视觉顶会ECCV 2020中国预会议：日程公开，注册有奖[EB/OL]. <a href="https://blog.csdn.net/BAAIBeijing/article/details/107588080" target="_blank" rel="noopener">https://blog.csdn.net/BAAIBeijing/article/details/107588080</a>, 2020-07-25.</p><p>[2] 智源社区. 智源社区活动[EB/OL]. <a href="https://event.baai.ac.cn/event/53#section-four" target="_blank" rel="noopener">https://event.baai.ac.cn/event/53#section-four</a>, 2020.</p><p>[3] Zongsheng Yue, Qian Zhao, Lei Zhang, and Deyu Meng. Dual adversarial network: Toward real-world noise removal and noise generation, 2020.</p><p>[4] Yue, Zongsheng, et al. Variational denoising network: Toward blind noise modeling and removal, <em>Advances in neural information processing systems</em>, 2019.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;论文阅读&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Denoising" scheme="http://maxliu245.github.io/tags/Denoising/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
  </entry>
  
</feed>
