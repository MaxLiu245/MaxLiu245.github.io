<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Max Liu&#39;s Blog</title>
  
  <subtitle>Earlier birds eat more worms</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://maxliu245.github.io/"/>
  <updated>2021-04-01T03:23:37.285Z</updated>
  <id>http://maxliu245.github.io/</id>
  
  <author>
    <name>Max Liu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【论文阅读47】ResNet+步长控制器</title>
    <link href="http://maxliu245.github.io/2021/03/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB47%E3%80%91ResNet-%E6%AD%A5%E9%95%BF%E6%8E%A7%E5%88%B6%E5%99%A8/"/>
    <id>http://maxliu245.github.io/2021/03/31/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB47%E3%80%91ResNet-%E6%AD%A5%E9%95%BF%E6%8E%A7%E5%88%B6%E5%99%A8/</id>
    <published>2021-03-31T11:51:33.000Z</published>
    <updated>2021-04-01T03:23:37.285Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文名字<em>Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families</em>，是林老师等在AAAI2020上的工作，干的啥看标题能知道个大概，这个工作就是对网络方程离散化形式的优化取了步长可变的策略，而这个步长控制器TSC正是一个元学习器！</p><p>本文引了NODE、FOCNet，网络和方程结合的一部分思想可以说是从这里来的</p></blockquote><a id="more"></a><div style="width:80%;margin:auto"><img src="/2021/03/31/【论文阅读47】ResNet-步长控制器/TSC_1.png" title="Time Stepping Controller"></div><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><p><font color="#0000CD">作者</font>有北大有山大的，包括北大的<font color="#0000CD">林宙辰</font>老师，发表在AAAI2020</p><p>文献链接<a href="https://ojs.aaai.org//index.php/AAAI/article/view/6141" target="_blank" rel="noopener">AAAI</a>或者<a href="https://arxiv.org/abs/1911.10305v1" target="_blank" rel="noopener">ArXiv</a>，建议参考ArXiv，因为有附录</p><h2 id="背景方法"><a href="#背景方法" class="headerlink" title="背景方法"></a>背景方法</h2><p><font color="#0000CD">背景</font>是结合神经网络和方程迭代机制的方法，历史思路有</p><ul><li>1个思路是基于欧拉前向法，改进方向是多步、高阶方程、分数阶方程（比如FOCNet）；</li><li>另一个思路是基于ResNet/NODE的稳定性改进</li></ul><p>本文主要参考的<font color="#0000CD">背景方法</font>是<font color="#0000CD">ResNet的离散化</font>形式，其实和NODE应该是一致的。这个离散化形式刚开始我没看明白，是因为没搞清楚它的符号，看下图即可。里面的式$(7,8)$刚开始我不会推，看了附录1可以手推一遍了，其中式$(8)$用$\displaystyle \dfrac{\partial L}{\partial y_n}=\dfrac{\partial L}{\partial y_D}\dfrac{\partial y_D}{\partial y_n}$即可</p><div style="width:70%;margin:auto"><img src="/2021/03/31/【论文阅读47】ResNet-步长控制器/TSC_2.png" title="我用这个辅助理解式子"></div><h2 id="动机-idea"><a href="#动机-idea" class="headerlink" title="动机/idea"></a>动机/idea</h2><p>整体的大<font color="#0000CD">动机</font>是理解深度网络的行为behaviors，小动机可以从文章给的例子看出来，就是<font color="#0000CD">自适应地调节方程步长</font>以增强稳定性和表达能力</p><div style="width:50%;margin:auto"><img src="/2021/03/31/【论文阅读47】ResNet-步长控制器/TSC_3.png" title="本文调节步长动机的具体例子"></div><p>具体的动机主要是：</p><ol><li><p>ResNet和动力系统之间的一致性，unravel残差网络</p></li><li><p>由Runge-Kutta-Fehlberg自适应步长的思路，希望把此迭代机制设置到网络中，平衡稳定性和有效性</p><blockquote><p>RKF说明：</p><ul><li>这个博客是代码，留在这里自取：<a href="http://blog.sciencenet.cn/blog-398465-326487.html" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-398465-326487.html</a></li><li>这个ppt介绍龙格库塔法比较全面：<a href="https://wenku.baidu.com/view/4e3b3068ddccda38376baf25.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/4e3b3068ddccda38376baf25.html</a></li></ul></blockquote></li></ol><h2 id="模型TSC"><a href="#模型TSC" class="headerlink" title="模型TSC"></a>模型TSC</h2><p>研究ResNet和欧拉前向法的联系，但不太同NODE，本文主要考虑时间步长的影响</p><p><font color="#0000CD">模型</font>本身就简记为TSC好了，全称time stepping controller</p><p>具体方案是设计<font color="#0000CD">时间步长控制器</font>，与当前状态参数无关，与先前的信息有关，它与主网络的训练是交替优化的。其实模型本身没什么，看原文第3页的式$(9)$即可：</p><script type="math/tex; mode=display">\displaystyle  \begin{aligned} \min_{\mathbf{W},\theta} &\ J=\dfrac{1}{S}\sum_{s=1}^S\Phi (y_s(T),y_s^*)+\sum_{d=1}^{D-1}R(\mathbf{w}(t_d),\theta (t_d)) \\ s.t. &\left\{ \begin{aligned} y_s(t_{d+1})=y_s(t_d)+\mathcal{F}(y_s(t_d),w(t_d))\Delta t_d\\ \Delta t_d=\Theta(w(t_d);\Delta t_1,\cdots,\Delta t_{d-1};\theta (t_d)) \\ t_0=0,\ t_{d+1}=t_d+\Delta t_d,\ y_s(0)=y_s \\ T=t_D=\sum_{d=0}^{D-1}\Delta t_d,\ d=0,1,\cdots,D-1 \end{aligned}\right. \end{aligned} \tag{1}</script><p>这个式子看起来吓人，其实比较简单，就是<font color="#0000CD">带ODE约束的能量泛函优化</font>问题：</p><p>（1）优化的目标$J$其实就是数据项➕正则项，$\Phi$是损失函数，两个输入是图像$y_s$经主网络演化到时刻$T$（就是算到最后）的值和监督标签$y_s^*$；正则项和每层的主网络参数$w$和TSC副网络参数$\theta$有关，其引入与观察到基本模型，ResNet的残差形式中，数值稳定性与卷积参数$w$的<a href="https://www.bilibili.com/video/av839997910/" target="_blank" rel="noopener">核范数</a>等有关，因此加了正则；</p><p>（2）约束条件还是ODE，即第一行就是主网络ResNet的离散形式；</p><p>（3）其中的步长$\Delta t_d$是交替优化来的，见条件第二行，即副网络TSC$\Theta$的形式，它包括自己的网络参数$\theta$，当前状态的主网络参数$w$和之前全部历史步长信息；</p><p>（4）后面的就是初值条件什么的了，没啥好说的</p><p>这样解读的话，这个副网络TSC$\Theta$其实就是一个<font color="#0000CD">元学习器</font>！</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>在三个数据集ImageNet和CIFAR-10、CIFAR-100上进行了实验</p><p>在实验中，作者尝试了三种TSC元学习器，分别是LSTM、2层FC和一个只和历史步长信息有关的函数，显然LSTM是🐂🐂一点的，虽然推断的时候大家计算复杂度一样（原文表$(1)$），训练的时候LSTM计算稍有复杂，但是人家效果更好啊</p><p>网络结构如下，基本上是元学习，只是其中有些操作special一点</p><div style="width:60%;margin:auto"><img src="/2021/03/31/【论文阅读47】ResNet-步长控制器/TSC_4.png" title="TSC网络结构"></div><p>训练的策略具体有：</p><ol><li>式$(1)$中的主网络参数$w_d$指的是每个残差block的参数，有几个卷积层，就把它们平均平均再concatenate作为$w_d$，若超过两个就只concatenate首尾的两个卷积参数</li><li>实验包括了对TSC策略的有效性和稳定性验证，有效就是性能好，稳定性就是收敛得快、稳定啥的</li><li>实验也包括对三种元学习器的比较</li><li>实验还包括对非残差网络的实验，这说明<ol><li>把约束中的离散化形式换了，这个框架也是work的</li><li>元学习器其实可以<strong>泛化</strong>到不同网络对应的方程</li></ol></li></ol><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p><ol><li>结合方程的联系，研究了步长对ResNet稳定性的影响</li><li>自适应步长控制器和主网络的交替优化可视为元学习器，且验证了有泛化能力</li><li>元学习器的概念使推断/测试过程中没有引入额外的计算消耗（只有元学习器确定步长）</li></ol><h2 id="思考小结"><a href="#思考小结" class="headerlink" title="思考小结"></a>思考小结</h2><p>本文其实，总结的话就是网络用方程的离散化解释，引入迭代优化机制，且只考虑欧拉前向法。把对于步长的自适应改进方法做成了一个交替优化的网络，即元学习器</p><p>思路棒棒，不过原文似乎没有意识到这个概念</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Yang, Y., Wu, J., Li, H., Li, X., Shen, T., &amp; Lin, Z. (2020). Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families. Proceedings of the AAAI Conference on Artificial Intelligence, 34(04), 6648-6655. <a href="https://doi.org/10.1609/aaai.v34i04.6141" target="_blank" rel="noopener">https://doi.org/10.1609/aaai.v34i04.6141</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文名字&lt;em&gt;Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families&lt;/em&gt;，是林老师等在AAAI2020上的工作，干的啥看标题能知道个大概，这个工作就是对网络方程离散化形式的优化取了步长可变的策略，而这个步长控制器TSC正是一个元学习器！&lt;/p&gt;
&lt;p&gt;本文引了NODE、FOCNet，网络和方程结合的一部分思想可以说是从这里来的&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Optimization" scheme="http://maxliu245.github.io/tags/Optimization/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Meta Learner" scheme="http://maxliu245.github.io/tags/Meta-Learner/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读46】另一篇分数阶网络</title>
    <link href="http://maxliu245.github.io/2021/03/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB46%E3%80%91%E5%8F%A6%E4%B8%80%E7%AF%87%E5%88%86%E6%95%B0%E9%98%B6%E7%BD%91%E7%BB%9C/"/>
    <id>http://maxliu245.github.io/2021/03/31/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB46%E3%80%91%E5%8F%A6%E4%B8%80%E7%AF%87%E5%88%86%E6%95%B0%E9%98%B6%E7%BD%91%E7%BB%9C/</id>
    <published>2021-03-31T02:39:51.000Z</published>
    <updated>2021-03-31T03:56:54.292Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文标题<em>Fractional-Order Deep Backpropagation Neural Network</em>，是1篇18年的文章，对上一篇文章搜代码的时候搜到的</p><p>本文阐述的分数阶网络跟我想的还不一样，它就是梯度下降的时候用的是Caputo导数（我怎么觉得不对劲，见启发部分）</p><p>发的地方争议似乎很大，但本文的参考文献里有些信息是有用的，所以略读一下</p></blockquote><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><div style="width:80%;margin:auto"><img src="/2021/03/31/【论文略读46】另一篇分数阶网络/1.png" title="文献标题"></div><p>这个文章不太水，内容有些单调，分数阶网络有点粗糙感，如标题述，就是讲分数阶网络的。但写得还行，是份<u>完整</u>的工作</p><p>作者是川大的，其中<a href="https://ieeexplore.ieee.org/author/37269178400" target="_blank" rel="noopener">Yifei Pu</a>之前做过很多分数阶的东西</p><p>文献链接：<a href="https://www.hindawi.com/journals/cin/2018/7361628/" target="_blank" rel="noopener">https://www.hindawi.com/journals/cin/2018/7361628/</a></p><h2 id="本文小结"><a href="#本文小结" class="headerlink" title="本文小结"></a>本文小结</h2><p>本文主要<font color="#0000CD">关注</font>的是/idea：</p><ol><li>以往分数阶网络直接限制分数阶范围$(0,1)$没理由</li><li>有的没加正则</li><li>以及此类方程的收敛性条件</li></ol><p>那么<font color="#0000CD">基于Caputo</font>分数阶导数（理由是常数的分数阶导要是0，这点与Fractional-DNN一致），对<font color="#0000CD">分数阶网络的数学形式</font>进行推导，进一步由损失的优化给出了网络<font color="#0000CD">收敛的一些必要条件</font></p><p>实验部分很完整，交代了<font color="#0000CD">网络结构</font>（注意是现在才交代），由数学形式给出了包含<font color="#0000CD">内外部神经元</font>的网络，在MNIST上进行了<u>分数阶数选择、数据集量的选择、正则的加入、训练轮数的选择</u>，主要<font color="#0000CD">说明了</font><u>分数阶导数选在$(0,2)$比较合适、正则确实稳定并增强泛化、网络是收敛的</u>。。</p><div style="width:90%;margin:auto"><img src="/2021/03/31/【论文略读46】另一篇分数阶网络/2.png" title="网络结构"></div><h2 id="本文启发"><a href="#本文启发" class="headerlink" title="本文启发"></a>本文启发</h2><p>个人最关注的其实是参考文献部分，了解到分数阶在18年之前就有很多研究了，主要是<u>方程、控制论、信号处理</u>方向。也有不少<u>图像处理、医学（CT）成像、神经网络</u>，这是个问题啊🤯</p><p>启发之2是本文阐述的分数阶网络跟我想的不一样，它就是梯度下降的时候用的是Caputo导数，在这一点上，我<strong>突然觉得</strong>本文网络的效果可能是网络结构中的外部神经元的作用。。。</p><p>总之就是觉得很矛盾，总觉得这个文章有点离谱。。。</p><blockquote><p>补充一些文章的细节：</p><ol><li>本文分数阶网络的结构见上图，网络的数学表达见文第3页式$(10-22)$，看过了，问题不大，就是不清楚<strong><u>外部神经元刚出现的时候是怎么出现的</u></strong>，毕竟<u>没有输入</u>。。。</li><li>它这个分数阶的网络，<u>分数阶到底体现在哪里</u>？文章的网络本身不含分数！分数阶体现在使用的优化策略是梯度下降，但是<strong><u>求的导数是Caputo分数阶导</u></strong>。。所以以往的分数阶网络都是这？不至于吧</li><li>网络收敛的必要条件是如何推导的？就是优化带正则的损失函数，对参数求分数阶导，令最优参数时分数阶导数为0，得到必要条件</li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文标题&lt;em&gt;Fractional-Order Deep Backpropagation Neural Network&lt;/em&gt;，是1篇18年的文章，对上一篇文章搜代码的时候搜到的&lt;/p&gt;
&lt;p&gt;本文阐述的分数阶网络跟我想的还不一样，它就是梯度下降的时候用的是Caputo导数（我怎么觉得不对劲，见启发部分）&lt;/p&gt;
&lt;p&gt;发的地方争议似乎很大，但本文的参考文献里有些信息是有用的，所以略读一下&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读45】Fractional-DNN</title>
    <link href="http://maxliu245.github.io/2021/03/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB45%E3%80%91Fractional-DNN/"/>
    <id>http://maxliu245.github.io/2021/03/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB45%E3%80%91Fractional-DNN/</id>
    <published>2021-03-30T14:20:37.000Z</published>
    <updated>2021-03-30T17:19:10.074Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文标题<em>Fractional deep neural network via constrained optimization</em>，就是分数阶方程介导的DNN</p><p>本文单纯从历史信息的利用、方程的离散化等思路，得到此分数阶网络Fractional-DNN</p></blockquote><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><div style="width:80%;margin:auto"><img src="/2021/03/30/【论文阅读45】Fractional-DNN/FDNN_1.png" title="Fractional-DNN文献"></div><p>作者信息：作者来自乔治梅森大学，数学与人工智能系和计算流体力学系。</p><p>文献地址：<a href="https://iopscience.iop.org/article/10.1088/2632-2153/aba8e7/meta" target="_blank" rel="noopener">https://iopscience.iop.org/article/10.1088/2632-2153/aba8e7/meta</a></p><p>期刊信息：</p><ol><li>本文发于2020年底的<u>Machine Learning: Science and Technology (MLST)</u>，期刊信息参见<a href="https://www.researchgate.net/journal/Machine-Learning-Science-and-Technology-2632-2153" target="_blank" rel="noopener">researchgate介绍</a>或<a href="https://iopscience.iop.org/journal/2632-2153" target="_blank" rel="noopener">MLST官网</a>，至2021/03/28谷歌引用量3</li><li>期刊似乎是刚刚见刊，搜不到IF，但是知道吴恩达在上面参与过用莫比乌斯变换做数据增广的<a href="https://hjian42.github.io/" target="_blank" rel="noopener">文章</a></li><li>注意到它的<a href="https://publishingsupport.iopscience.iop.org/track-my-article/" target="_blank" rel="noopener">track审稿进度界面</a>有微信支持，我感觉这刊和咱们有关。。可能和<a href="https://china.ioppublishing.org/news/machine-learning-science-and-technology-qi-kan-chu-ban-zui/" target="_blank" rel="noopener">这个</a>有关？</li></ol><h2 id="总体个人观感"><a href="#总体个人观感" class="headerlink" title="总体个人观感"></a>总体个人观感</h2><p>这篇文章像是研究机器学习不深，和很懂方程的作者写出来的，这一点可以从作者信息上体现出来一点。注意到本文</p><ul><li>暂时没有开源代码</li><li>没有引用NODE</li><li>读完后发现文章偏重物理、方程理论，网络的优化算法以及方程离散化是参考DenseNet等得到的启发</li><li>感觉本文对神经网络其实是不太熟悉的，很久没见到专门介绍ML概念和NN概念的文章了</li><li>作者已经于本年年初自引了此文</li></ul><p>这些因素让我觉得文章写得其实不是很充分，有余地，还有搞头【手动憧憬😃】</p><h2 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h2><p>小结不想写了，其实就是上面的个人观感吧，内容上读完了觉得正常，不差，但是也没那么猛</p><h2 id="具体内容"><a href="#具体内容" class="headerlink" title="具体内容"></a>具体内容</h2><h3 id="背景领域"><a href="#背景领域" class="headerlink" title="背景领域"></a>背景领域</h3><p>这篇文章不是从NODE的思路切入的，作者关注更多的是偏方程理论的，比如Karniadakis这个人从pde/物理角度切入的NN模型：fPINN</p><p>那么本文声明本文的Fractional-DNN与之完全不同，只是思路不同。。感觉说话的力度一下子就无了qwq</p><h3 id="Caputo分数阶导数"><a href="#Caputo分数阶导数" class="headerlink" title="Caputo分数阶导数"></a>Caputo分数阶导数</h3><p>参考华师的<a href="http://math.ecnu.edu.cn/~jypan/Research/papers/lect_FDE.pdf" target="_blank" rel="noopener">讲义</a>可以辅助理解本文$(2.2)$节中的Caputo分数阶导。细节就不说了，放一个左导数有个印象：</p><script type="math/tex; mode=display">\displaystyle d_t^{\gamma}u(t)=\dfrac{1}{\Gamma (1-\gamma)}\int_0^t\dfrac{u^\prime (t)}{(t-r)^\gamma}dr \tag{1}</script><p>主要是Caputo把左右分数阶导的定义分开了，见原文第3页的式$(3,4)$，这里要注意的是，这里的<strong>阶数必须是限制在$(0,1)$的</strong>，定义如此，区间外的没有定义，原因暂时不知，参考华师<a href="http://math.ecnu.edu.cn/~jypan/Research/papers/lect_FDE.pdf" target="_blank" rel="noopener">讲义</a></p><p>当然，当阶数趋于1时，Caputo就退化为普通的整数1阶导了，左右Caputo导数经过分部积分就成为原1阶导（已会推导，把阶数看成一般的整数分部积分即可）</p><p>后续的定理不管了，不过很重要，后面总问题写成优化泛函后，推导是用到了左右导数分解的性质的</p><blockquote><p>注：本文表示不用那个刘维尔的分数阶导是因为常数的刘维尔导非0，这样在边界处很难处理。参考华师<a href="http://math.ecnu.edu.cn/~jypan/Research/papers/lect_FDE.pdf" target="_blank" rel="noopener">讲义</a></p></blockquote><h3 id="动机-idea"><a href="#动机-idea" class="headerlink" title="动机/idea"></a>动机/idea</h3><p>（1）希望把历史/记忆信息引入学习模型中，由此引入网络每层直接潜在的连接</p><p>（2）分数阶方程增强历史信息，与分数阶导算子是non-local的有关</p><p>（3）网络和ODE/PDE之间的联系，引入分数阶方程的离散化及其算法</p><p>（4）利用dense block结构缓和梯度消失问题</p><p>（5）做ML的理论是基础而重要的事情，如果能把一个网络做好也不戳</p><h3 id="模型Fractional-DNN"><a href="#模型Fractional-DNN" class="headerlink" title="模型Fractional-DNN"></a>模型Fractional-DNN</h3><p>本文直接把提出的模型命名为Fractional-DNN，分数阶神经网络</p><p>Fractional-DNN是基于算法设计的，所以应该算是model-based；训练本身还是基于数据，但learning-based的成份很弱</p><p>该分数阶网络一步一步导出的思路是</p><script type="math/tex; mode=display">\displaystyle RNN\ as\ optiaml\ problem\rightarrow continuous\ Fractional\ DNN\rightarrow Fractional\ DNN\ with\ specific\ loss\rightarrow discrete\ Fractional\ DNN \tag{2}</script><p>其中第1步，RNN作为优化问题就是优化损失，条件就是RNN的结构，参考文章第4、5页式$(7,9)$，形式很简单，主要是条件作为ODE，<strong>RNN每一层的变换也作为欧拉前向法的一步</strong></p><p>第2步，现在考虑连续形式下的分数阶方程，它作为网络只需要在DNN作为优化问题的基础上变形即可，我觉得也不需要是在RNN的基础上，文章重点提RNN可能是它与方程、上下文信息利用的<u>联系较多</u>。变形就是优化的目标函数可以保持loss不变，只是优化的约束改成分数阶网络，<strong>由一步（整数1）欧拉前向变成分数阶导数</strong>！</p><p>第3步，优化的目标设定成特定损失，本文的实验是分类，所以设定成交叉熵（加正则）。但本文也表示回归也类似，这一点我觉得很奇怪，因为文章特地分了一个小章节介绍CE损失。。。</p><p>第3步结束后，就是要采用拉格朗日乘子法求解能量泛函，然后得到迭代式了，所以先放出第3步的网络作为优化问题的表达式：</p><script type="math/tex; mode=display">\displaystyle  \begin{aligned} \min_{W,K,b} &E(W,Y(T),C_{obs})+\mathcal{R}(W,K(t),b(t)) \\ s.t. &\left\{ \begin{aligned} d_t^{\gamma}Y(t) &= \sigma (K(t)Y(t),b(t)),\ t\in (0,T),\\ Y(0)&=Y_0. \end{aligned}\right. \end{aligned} \tag{3}</script><p>那么在第3步和第4步之间就是用拉格朗日乘子法解一下式$(3)$，得到连续形式的迭代格式。具体的计算不放了，挺多的，原文第6、7页的式$(13-16)$。说句实话吧，<strong>$(15)$式的伴随方程为什么是对约束方程的主变量求导</strong>，难道不是对主优化问题的参数求导么？后面的式子我也没看了</p><p>再到第4步，离散化方程，这就是像NODE的思路了，只不过本文的idea和NODE的是有很大区别的。本文离散化约束ODE方程并不是NODE那样直接作为欧拉前向法中的中间层，而是<strong>采用了所谓的$L^1$机制</strong>，<strong>我没看懂</strong>，但是觉得式$(18)$<strong>像是</strong>分数阶导数的一阶泰勒展开，本质上<strong>像是</strong>给定ODE方程后，对分数阶导数的<strong>近似估计</strong>。。。后续$L^1$机制参照文中第7页及以后的$(17-26)$式</p><blockquote><p>注意：文章特地提到，如果指定优化迭代的算法，那么算法一般是与方程本身无关的，也就是和网络本身无关。所以，如果指定优化迭代算法，就<strong>不用限制网络的结构</strong>，包括层数等</p><p>注2：文章提到了参数化卷积核。。用于减少式$(3)$中未知参数的数量，确实，是可以减少一点的。而且这样也是和PDE-Net有所结合的</p></blockquote><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>（1）似乎是因为引入历史信息/记忆的缘故，对梯度消失问题表现较好（应该是参考DenseNet的思路）</p><p>（2）拟合非光滑数据&amp;非光滑函数（别的文章好像很少提这个事情吧）</p><p>（3）可能是分数阶导带来的好处，导出网络跨层连接缓和梯度消失问题、对非光滑函数的拟合、DE工具都可以整活</p><p>（4）确实如文所述，本文讨论了很多原始NN的理论，不过是迭代优化算法，更是model-based了</p><p>缺点，我不喜欢最后迭代机制中的$L^1$机制，对分数阶导算子还有估计；以及实验的数据太小了，也太少了</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>本文主要是在两个小数据集上做了实验，分别是二分类的CLS数据（自己生成的那种）和香水多分类数据</p><h2 id="参考文献-链接"><a href="#参考文献-链接" class="headerlink" title="参考文献/链接"></a>参考文献/链接</h2><p>[1] Harbir Antil, Ratna Khatri, Rainald Lner, and Deepanshu Verma. Fractional deep neural network via constrained optimization. Machine Learning: Science and Technology, 2(1):015003, 2020.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@article&#123;RN47,</span><br><span class="line">   author = &#123;Antil, Harbir and Khatri, Ratna and Löhner, Rainald and Verma, Deepanshu&#125;,</span><br><span class="line">   title = &#123;Fractional deep neural network via constrained optimization&#125;,</span><br><span class="line">   journal = &#123;Machine Learning: Science and Technology&#125;,</span><br><span class="line">   volume = &#123;2&#125;,</span><br><span class="line">   number = &#123;1&#125;,</span><br><span class="line">   pages = &#123;015003&#125;,</span><br><span class="line">   ISSN = &#123;2632-2153&#125;,</span><br><span class="line">   DOI = &#123;10.1088/2632-2153/aba8e7&#125;,</span><br><span class="line">   url = &#123;http://dx.doi.org/10.1088/2632-2153/aba8e7&#125;,</span><br><span class="line">   year = &#123;2020&#125;,</span><br><span class="line">   type = &#123;Journal Article&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>[2] 华师讲义，涉及本文Caputo分数阶导数详细的定义：<a href="http://math.ecnu.edu.cn/~jypan/Research/papers/lect_FDE.pdf" target="_blank" rel="noopener">http://math.ecnu.edu.cn/~jypan/Research/papers/lect_FDE.pdf</a></p><p>[3] 分数阶导数的讨论（用处不大）：<a href="http://muchong.com/html/201203/4223380.html" target="_blank" rel="noopener">http://muchong.com/html/201203/4223380.html</a></p><p>[4] 搜到了另一篇像是水文的文章：<a href="https://www.hindawi.com/journals/cin/2018/7361628/" target="_blank" rel="noopener">Fractional-Order Deep Backpropagation Neural Network</a>，期刊是奇怪的<a href="https://www.hindawi.com/" target="_blank" rel="noopener">hindawi</a>的18年<a href="https://www.hindawi.com/journals/cin/" target="_blank" rel="noopener">Computational Intelligence and Neuroscience</a>，此文代码<a href="https://github.com/BaoChunhui/Deep-fractional-BP-neural-networks" target="_blank" rel="noopener">在此</a>。有空浏览一下</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文标题&lt;em&gt;Fractional deep neural network via constrained optimization&lt;/em&gt;，就是分数阶方程介导的DNN&lt;/p&gt;
&lt;p&gt;本文单纯从历史信息的利用、方程的离散化等思路，得到此分数阶网络Fractional-DNN&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Optimization" scheme="http://maxliu245.github.io/tags/Optimization/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读44】DPIR——利用深度去噪先验的图像恢复方法</title>
    <link href="http://maxliu245.github.io/2021/03/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB44%E3%80%91DPIR%E2%80%94%E2%80%94%E5%88%A9%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%8E%BB%E5%99%AA%E5%85%88%E9%AA%8C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%81%A2%E5%A4%8D%E6%96%B9%E6%B3%95/"/>
    <id>http://maxliu245.github.io/2021/03/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB44%E3%80%91DPIR%E2%80%94%E2%80%94%E5%88%A9%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%8E%BB%E5%99%AA%E5%85%88%E9%AA%8C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%81%A2%E5%A4%8D%E6%96%B9%E6%B3%95/</id>
    <published>2021-03-28T00:58:54.000Z</published>
    <updated>2021-03-29T06:05:51.352Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读文献DPIR：<a href="https://arxiv.org/abs/2008.13751" target="_blank" rel="noopener"><em>Plug-and-Play Image Restoration with Deep Denoiser Prior</em></a></p><p>利用的深度去噪先验（DP）的图像恢复（IR）方法，至于即插即用，是指？且待分解（见背景部分）</p></blockquote><a id="more"></a><h2 id="文献简介"><a href="#文献简介" class="headerlink" title="文献简介"></a>文献简介</h2><div style="width:80%;margin:auto"><img src="/2021/03/28/【论文阅读44】DPIR——利用深度去噪先验的图像恢复方法/DPIR_1.png" title="DPIR文献"></div><p>ArXiv上表示本文是IRCNN (CVPR17)的拓展，目前本文似乎只发在20年ArXiv上</p><blockquote><p>张凯一作，还有张磊和左旺孟老师：<a href="https://arxiv.org/abs/2008.13751" target="_blank" rel="noopener">https://arxiv.org/abs/2008.13751</a></p><p>代码：<a href="https://github.com/cszn/DPIR" target="_blank" rel="noopener">https://github.com/cszn/DPIR</a></p></blockquote><h2 id="图像恢复（IR）与去噪的关系"><a href="#图像恢复（IR）与去噪的关系" class="headerlink" title="图像恢复（IR）与去噪的关系"></a>图像恢复（IR）与去噪的关系</h2><p>这个问题挺困扰像我这样的初学者，但是又没有专门去了解它们的关系。这次本文在引言中给出了一个介绍！总的来说，图像恢复的范围很大，包括了去噪</p><p>图像恢复问题的数学表达是：</p><script type="math/tex; mode=display">\displaystyle y=\mathcal{T}(x)+n \tag{1}</script><p>指的是利用退化算子$\mathcal{T}$从带有噪声$n$的退化观测（即带噪图）$y$中恢复出干净图$x$</p><p>由此定义，<font color="#0000CD">不同的退化算子$\mathcal{T}$就对应了不同的IR任务</font>：</p><div class="table-container"><table><thead><tr><th style="text-align:center">IR任务</th><th style="text-align:center">退化算子$\mathcal{T}$</th></tr></thead><tbody><tr><td style="text-align:center">传统IR（去噪？）</td><td style="text-align:center">恒等映射</td></tr><tr><td style="text-align:center">去模糊</td><td style="text-align:center">2-d卷积</td></tr><tr><td style="text-align:center">超分辨</td><td style="text-align:center">卷积和下采样的复合</td></tr><tr><td style="text-align:center">去马赛克</td><td style="text-align:center">色彩滤波阵列（CFA）masking</td></tr></tbody></table></div><h2 id="基于模型与基于学习方法的关系"><a href="#基于模型与基于学习方法的关系" class="headerlink" title="基于模型与基于学习方法的关系"></a>基于模型与基于学习方法的关系</h2><p>model-based大概就是为了最小化目标函数，采用巧妙地优化方法，其中可能有精巧的优化机制，也可能是算法unfolding的方式</p><p>learning-based就是用数据对去学习，逼近最优解，可以直接看成是原文第1页式$(3)$的双边优化</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>从标题知，本文的<font color="#0000CD">目标</font>是图像恢复。另外，本文的方法关注的点是<font color="#0000CD">即插即用</font>模块的设计，在下一部分介绍之</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本文的<font color="#0000CD">背景</font>领域是即插即用的去噪，去噪不说了，主要是这个<font color="#0000CD">即插即用</font>是什么</p><p><u>即插即用Plug-and-Play</u>指的是一种<u>处理</u>深度学习<u>目标函数</u>的方式。一般的目标函数包括数据（拟合）项和正则（先验）项，即插即用要把目标函数的这两部分<u>分离</u>，得到<u>2个子问题</u>，即<u>数据子问题&amp;先验子问题</u>。那么要优化这样的目标函数，只需用迭代的方式，交替求解2个子问题。一般这个即插即用都是指☞用现成的工具解先验子问题，这样就不用手动指定显式先验，这样其实就是隐式地用这个现成的工具定义了先验</p><h2 id="动机-Idea"><a href="#动机-Idea" class="headerlink" title="动机/Idea"></a>动机/Idea</h2><p>本文的<font color="#0000CD">动机/idea</font>是要求即插即用模块灵活且能力强。希望即插即用（在本文中就是denoiser）non-blind，且能处理大范围的噪声水平（要求灵活）</p><p>从这两个方面分别考虑的话，参照的基本模型主要是原作者17年CVPR的IRCNN去噪器，可以处理各种各样的噪声水平，但它由25个独立的7层去噪器组成，其中每个去噪器在噪声水平间隔为2的数据上训练。有两个缺点，第1是不能灵活指定特定噪声水平；第2是由于层数少，效果不够</p><p>启示是要模块灵活且强大</p><blockquote><p>ps：利用DCNN的即插即用与deep unfolding的区别：deep unfolding毕竟是对特定任务的优化单独设计的嘛，所以虽然解释性强，需要的迭代也少，但对每个特定任务都是单独训练的。相反，即插即用很容易兼容其它模型，即易部署</p></blockquote><h2 id="模型DPIR"><a href="#模型DPIR" class="headerlink" title="模型DPIR"></a>模型DPIR</h2><p>其实，以上的<font color="#0000CD">问题</font>、<font color="#0000CD">背景</font>和<font color="#0000CD">动机</font>部分都是写作时的组织方式，本文模型DPIR模型的提出其实是另一个思路！以下也将从<u>更自然的思路</u>引出此模型，即从即插即用模块如何<strong><u>由HQS优化算法导出</u></strong></p><p>首先，带噪图还是$y$，干净图还是$x$，则初始问题的概率形式和一般形式分别是：</p><script type="math/tex; mode=display">\displaystyle \hat{x}=\mathop{\arg\max}_{x}\log p(y|x)+\log p(x) \tag{1}</script><script type="math/tex; mode=display">\displaystyle \hat{x}=\mathop{\arg\min}_{x}\dfrac{1}{2\sigma^2}||y-\mathcal{T}(x)||^2+\lambda \mathcal{R}(x) \tag{2}</script><p>那么HQS算法，指Half Quadratic Splitting，要把上述数据项和先验项分离，为此<strong>引入隐变量</strong>$z$，则优化问题变为带约束的问题：</p><script type="math/tex; mode=display">\displaystyle \hat{x}=\mathop{\arg\min}_{x}\dfrac{1}{2\sigma^2}||y-\mathcal{T}(x)||^2+\lambda \mathcal{R}(z)\ s.t.\ z=x \tag{3}</script><p>所以其Lagrangian就是</p><script type="math/tex; mode=display">\displaystyle \mathcal{L}_{\mu}(x,z)=\mathop{\arg\min}_{x}\dfrac{1}{2\sigma^2}||y-\mathcal{T}(x)||^2+\lambda \mathcal{R}(z)+\dfrac{\mu}{2}||z-x||^2\tag{4}</script><p>那么式$(4)$有两个变量其实，分别是目标变量$x$和隐变量$z$，也有两个Lagrange乘子$\lambda$和$\mu$。且注意到上式包含只有$x$、只有$z$和$x,z$都有的项。式$(4)$的求解则用交替优化的方式进行：</p><script type="math/tex; mode=display">\displaystyle\left\{\begin{aligned} x_k&=\mathop{\arg\min}_x||y-\mathcal{T}(x)||^2+\mu\sigma^2||x-z_{k-1}||^2 \\ z_k&=\mathop{\arg\min}_z\dfrac{1}{2\left(\sqrt{\frac{\lambda}{\mu}}\right)^2}||z-x_k||^2+\mathcal{R}(z)\end{aligned}\right.\tag{5}</script><p>式$(5)$就是拉格朗日求导的结果，双变量的。注意到下面的式子相当于是一般的高斯去噪过程，即$z$相当于$x$的带高斯噪图，然后去恢复$x$！好家伙，这就是为什么文章说这个<u><strong>即插即用的模块是用一个深度高斯去噪网络来做</strong></u>的！</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>本文的实验是一般的IR问题，具体在去模糊、单图超分辨（SISR）、彩图去马赛克3个问题上进行了实验</p><p>实验效果都挺好的</p><h2 id="优点-amp-技巧"><a href="#优点-amp-技巧" class="headerlink" title="优点&amp;技巧"></a>优点&amp;技巧</h2><p>优点的话随便写写，（1）优化问题结合算法自然推导出了先验去噪器（这个东西的泛化仅限于IR）；（2）深度去噪器先验建模能力好，提高有效性；（3）没有限定特定任务，这个意义下更灵活</p><p>本文其实有很多技巧性的东西，都算是领域知识吧，比如说（1）HQS算法的选择及其优势；（2）与双边优化问题的联系；（3）残差块结合U-Net，增强表达能力与图像变换能力；（4）实验与各种去噪器对比，如CNN-based、model-based网络；（5）为了增强泛化，把noise-level-map也作为输入，但是这样具体的做法不清楚</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>本文的降噪器从原理上是从优化算法的计算过程中unfolding出来的，所以DPIR在这个HQS框架下是成立的，也只能用HQS优化，以及用高斯去噪器。这个东西总是觉得有点奇怪，即插即用也就是在它的框架下去插。不想用这个优化方法就无了</p><p>从这个角度上说和meta差距还是挺大的。如果硬是要联系的话可能是文章开头的式子$(3)$，它没有指定优化方法，还是优化能量泛函+优化约束。这是否有启发，<u>把约束优化问题做成元学习器</u>，然后再套到pde约束优化能量泛函的框架下呢？</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Kai Zhang, Yawei Li, Wangmeng Zuo, Lei Zhang, Luc Van Gool, and Radu Timofte. Plug-and-Play Image Restoration with Deep Denoiser Prior. arXiv e-prints, page arXiv:2008.13751, August 2020.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@ARTICLE&#123;2020arXiv200813751Z,</span><br><span class="line">       author = &#123;&#123;Zhang&#125;, Kai and &#123;Li&#125;, Yawei and &#123;Zuo&#125;, Wangmeng and &#123;Zhang&#125;, Lei and &#123;Van Gool&#125;, Luc and &#123;Timofte&#125;, Radu&#125;,</span><br><span class="line">        title = &quot;&#123;Plug-and-Play Image Restoration with Deep Denoiser Prior&#125;&quot;,</span><br><span class="line">      journal = &#123;arXiv e-prints&#125;,</span><br><span class="line">     keywords = &#123;Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Computer Vision and Pattern Recognition&#125;,</span><br><span class="line">         year = 2020,</span><br><span class="line">        month = aug,</span><br><span class="line">          eid = &#123;arXiv:2008.13751&#125;,</span><br><span class="line">        pages = &#123;arXiv:2008.13751&#125;,</span><br><span class="line">archivePrefix = &#123;arXiv&#125;,</span><br><span class="line">       eprint = &#123;2008.13751&#125;,</span><br><span class="line"> primaryClass = &#123;eess.IV&#125;,</span><br><span class="line">       adsurl = &#123;https://ui.adsabs.harvard.edu/abs/2020arXiv200813751Z&#125;,</span><br><span class="line">      adsnote = &#123;Provided by the SAO/NASA Astrophysics Data System&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其它参考链接（感觉用处不大）：</p><ul><li><p><a href="https://blog.csdn.net/gwplovekimi/article/details/89417600" target="_blank" rel="noopener">论文阅读笔记之——《Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels》</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/243492602" target="_blank" rel="noopener">ETH Zurich提出DPIR：具有Denoiser先验的即插即用图像恢复</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读文献DPIR：&lt;a href=&quot;https://arxiv.org/abs/2008.13751&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;em&gt;Plug-and-Play Image Restoration with Deep Denoiser Prior&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;利用的深度去噪先验（DP）的图像恢复（IR）方法，至于即插即用，是指？且待分解（见背景部分）&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Denoising" scheme="http://maxliu245.github.io/tags/Denoising/"/>
    
      <category term="Bi-Level" scheme="http://maxliu245.github.io/tags/Bi-Level/"/>
    
      <category term="Meta Learner" scheme="http://maxliu245.github.io/tags/Meta-Learner/"/>
    
  </entry>
  
  <entry>
    <title>【CV知识】PSNR&amp;SSIM指标</title>
    <link href="http://maxliu245.github.io/2021/03/25/%E3%80%90CV%E7%9F%A5%E8%AF%86%E3%80%91PSNR-SSIM%E6%8C%87%E6%A0%87/"/>
    <id>http://maxliu245.github.io/2021/03/25/%E3%80%90CV%E7%9F%A5%E8%AF%86%E3%80%91PSNR-SSIM%E6%8C%87%E6%A0%87/</id>
    <published>2021-03-25T06:04:45.000Z</published>
    <updated>2021-03-25T06:11:27.725Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>学习了图像处理问题中常见的评价指标：PSNR和SSIM，并自己整理了一遍加深印象</p></blockquote><a id="more"></a><p>写在前面：这都是从网络博客重新整理的，链接均位于文末，如有不妥请联系协商~</p><h2 id="PSNR"><a href="#PSNR" class="headerlink" title="PSNR"></a>PSNR</h2><p><font color="0000CD"><strong>PSNR</strong></font>全称Peak Signal to Noise Ratio，即<font color="0000CD"><strong>峰值信噪比</strong></font>，从计算公式看相当于<u>MSE的对数形式</u>，多了<u>像素峰值</u>特征。所以也是一种通用的衡量图像失真、衡量噪声水平的指标。应该是个标量，其单位是dB，一般30dB以上比较好，以下稍微差点吧，现在做到$32^+$的还挺多的</p><p>计算公式为：</p><script type="math/tex; mode=display">\displaystyle PSNR(X,Y)=10*\log_{10}\left(\dfrac{max^2}{MSE}\right)=20*\log_{10}\left(\dfrac{max}{MSE}\right)\overset{also}{=}20*\log_{10}\left(\dfrac{2^b-1}{MSE}\right). \tag{1}</script><p>以普通的单通道图像为例，其中$X,Y$一般是输出的去噪图和gt干净图；不妨设图像的维度都是$m\times n$，则$\displaystyle MSE(X,Y)=\dfrac{1}{mn}\sum_{i=1}^m\sum_{j=1}^n\left(X_{ij}-Y_{ij}\right)^2$；$max=2^b-1$，指的是像素值的极值，与每张图像本身无关，$b$是每个像素的bit数，一般就是8，所以$max=255$</p><h2 id="SSIM"><a href="#SSIM" class="headerlink" title="SSIM"></a>SSIM</h2><p><font color="0000CD"><strong>SSIM</strong></font>全称Structural Similarity，即<font color="0000CD"><strong>结构相似性</strong></font>，从计算公式看，这个指标考虑了图像之间<u>（1）亮度（2）对比度（3）结构之间的差异</u>。它是个标量，参考了几篇文章，SSIM没有单位，取值区间是$[0,1]$，越接近1表示两张图像越相近</p><p>计算公式为：</p><script type="math/tex; mode=display">\displaystyle \begin{aligned}&SSIM\overset{def}{=}L^\alpha\times C^\beta\times S^\gamma\\ where &\left\{ \begin{aligned}&亮度差异L(X,Y)=\dfrac{2\mu_X\mu_Y+c_1}{\mu_X^2+\mu_Y^2+c_1}\\ &对比度差异C(X,Y)=\dfrac{2\sigma_X\sigma_Y+c_2}{\sigma_X^2+\sigma_Y^2+c_2}\\ &结构差异S(X,Y)=\dfrac{\sigma_{XY}+c_3}{\sigma_X\sigma_Y+c_3}\end{aligned}\right.\end{aligned} \tag{2}</script><p>其中小写字母都是数值标量，$\displaystyle \mu_X=\dfrac{1}{mn}\sum_{i=1}^m\sum_{j=1}^nX_{ij}$就是图像像素值的均值，$\displaystyle \sigma_X=\left(\dfrac{1}{mn-1}\sum_{i=1}^m\sum_{j=1}^n\left(X_{ij}-\mu_X\right)^2\right)^{\frac{1}{2}}$是方差的无偏估计，$\sigma_{XY}=\dfrac{1}{mn-1}\sum_{i=1}^m\sum_{j=1}^n\left(X_{ij}-\mu_X\right)\left(Y_{ij}-\mu_Y\right)$是两张图像协方差的无偏估计，注意仍然是数量标量。另外，$c_1,c_2,c_3$都是避免除0的常数，取$c_1=(k_1<em>max)^2,\ k_1=0.01$，$c_2=(k_2</em>max)^2,\ k_2=0.03$，$k_1,k_2,k_3,\alpha,\beta,\gamma$感觉是像控制$L,C,S$权重的。取$\displaystyle c_3=\frac{c_2}{2},\alpha=\beta=\gamma=1$，就是常见的SSIM计算式：</p><script type="math/tex; mode=display">\displaystyle SSIM=L*C*S=\dfrac{(2\mu_X\mu_Y+c_1)(2\sigma_{XY}+c_2)}{(\mu_X^2+\mu_Y^2+c_1)(\sigma_X^2+\sigma_Y^2+c_2)}. \tag{3}</script><h2 id="其它指标"><a href="#其它指标" class="headerlink" title="其它指标"></a>其它指标</h2><p>一个是MSSIM，平均结构相似性，就是给图像分块，每一块分别计算SSIM再平均。据参考链接$[3]$，不用遍历像素点而是分块的方式，<font color="FF0000"><strong>可能</strong></font>有更高的效率；而为什么用高斯函数计算均值、方差和协方差，不知道，这个没有再去学了</p><p>还有就是各种指标拓展到彩图（多通道图）、高光谱图等，大概都是各个通道，谱段分别求再平均，有没有加权的操作则不清楚了</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>都是从网络博客直接学的：</p><p>[1] <a href="https://zhuanlan.zhihu.com/p/50757421" target="_blank" rel="noopener">图像质量评价指标之 PSNR 和 SSIM</a>，知乎文章，写得全，有代码</p><p>[2] <a href="https://blog.csdn.net/weixin_43478836/article/details/104159648" target="_blank" rel="noopener">图像质量评估中的PSNR和SSIM的定义，公式和含义</a>，CSDN博客，写得全</p><p>[3] <a href="https://www.jianshu.com/p/43d548ad6b5d" target="_blank" rel="noopener">图像相似度评价指标</a>，简书文章，有定义和<u>大量</u>代码。注意这里面SSIM范围写错了，而且错得离谱。。</p><p>[4] <a href="https://www.jianshu.com/p/e11539734510" target="_blank" rel="noopener">图像质量评价指标PSNR、SSIM、MSSIM介绍</a>，也比较全，有MSSIM公式</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;学习了图像处理问题中常见的评价指标：PSNR和SSIM，并自己整理了一遍加深印象&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读43】FOCNet——网络与分数阶方程的结合</title>
    <link href="http://maxliu245.github.io/2021/03/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB43%E3%80%91FOCNet%E2%80%94%E2%80%94%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%88%86%E6%95%B0%E9%98%B6%E6%96%B9%E7%A8%8B%E7%9A%84%E7%BB%93%E5%90%88/"/>
    <id>http://maxliu245.github.io/2021/03/24/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB43%E3%80%91FOCNet%E2%80%94%E2%80%94%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%88%86%E6%95%B0%E9%98%B6%E6%96%B9%E7%A8%8B%E7%9A%84%E7%BB%93%E5%90%88/</id>
    <published>2021-03-24T01:19:37.000Z</published>
    <updated>2021-03-24T12:56:52.189Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>为什么不能早看到这篇文章呢？感觉<a href="20210322-0323.pdf" title="20210322-0323">之前</a>基本上在白淦。。。</p><p>本文标题<em>FOCNet: A Fractional Optimal Control Network for Image Denoising</em>，网络模型即FOCNet</p><p>是看到的继TNRD后，总第2篇结合DE和网络结构的文章，引入的是分数阶ODE的离散化，带来长期记忆性。有点动态网络的味道，<strong>但不是</strong>❗</p></blockquote><a id="more"></a><h2 id="文献简介"><a href="#文献简介" class="headerlink" title="文献简介"></a>文献简介</h2><div style="width:80%;margin:auto"><img src="/2021/03/24/【论文阅读43】FOCNet——网络与分数阶方程的结合/FOC_1.png" title="FOC文献"></div><p>FOCNet是2019CVPR的文章，是贾老师、张磊老师等的文章，至2021/03/24谷歌显示有31引用量</p><ul><li>文献链接见<a href="https://ieeexplore.ieee.org/document/8954104" target="_blank" rel="noopener">IEEE</a>或<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jia_FOCNet_A_Fractional_Optimal_Control_Network_for_Image_Denoising_CVPR_2019_paper.html" target="_blank" rel="noopener">CVPR</a></li><li>代码见<a href="https://github.com/hsijiaxidian/FOCNet" target="_blank" rel="noopener">FOCNet</a></li></ul><h2 id="略读笔记"><a href="#略读笔记" class="headerlink" title="略读笔记"></a>略读笔记</h2><p>【1】谁的文章：贾老师、张老师等</p><p>【2】什么问题：图像去噪</p><p>【3】有动机否：基于DnCNNs的方程解释，改成分数阶方程；分数阶方程似乎有长期记忆性</p><p>【4】有无框架：FOCNet，分数最优控制网络，算是分数阶微分方程的离散化；并加强多尺度特征交互来加强网络</p><p>【5】什么模型：与框架一致，求解分数最优控制（FOC）问题，有不少理论保证。有DenseNet/动态网络的味道</p><p>【6】方程类型：分数阶方程，原文第4页式$(7)$，好像就是条件pde变成了分数阶方程，其它都是网络套的</p><p>【7】实验：很多，有经典单图加多种噪声，用多种模型；还有数据集同样处理的</p><h2 id="打算细看一点点"><a href="#打算细看一点点" class="headerlink" title="打算细看一点点~"></a>打算细看一点点~</h2><h3 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h3><p>从标题知，本文的<font color="#0000CD">目标</font>是图像去噪问题。从正文看也是general的图像去噪，没有什么特殊假设</p><h3 id="背景方法"><a href="#背景方法" class="headerlink" title="背景方法"></a>背景方法</h3><p>本文的<font color="#0000CD">背景</font>领域是去噪，其中主要关注的是背景方法是DnCNNs和动力系统解释DNN这两个：</p><ul><li><p><a href="http://maxliu245.github.io/2021/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB40%E3%80%91DnCNNs%E2%80%94%E2%80%94%E7%BB%8F%E5%85%B8%E5%8E%BB%E5%99%AA%E6%96%B9%E6%B3%95/">DnCNNs</a>在low-level的去噪中表现出色</p><blockquote><p>ps：本文在引言部分介绍了大量去噪网络模型，需要的话再看</p></blockquote></li><li><p>深度卷积网络DCNN结合残差可以解释为动力系统，由此引入分数阶ODE</p></li></ul><h3 id="动机-Idea"><a href="#动机-Idea" class="headerlink" title="动机/Idea"></a>动机/Idea</h3><p>本文的<font color="#0000CD">动机/idea</font>有两个</p><ul><li><p>整数阶ODE在时间尺度上局部之间的关系显然是大的，但是全局就不大了，因此只有所谓短期记忆；而分数阶（fractional）ODE有长期记忆（原文第3页图$(1)$所示的power-law memory）。在去噪这个问题上，历史状态（原图）应该也是对稳健控制有关的</p><blockquote><p>ps1：DenseNet、MemNet似乎也可以看成学习长期记忆</p><p>ps2：至于为什么要长期记忆，这是从动力系统当前state可能和历史states都相关启发得到的结论</p></blockquote></li><li><p>多尺度特征交互加强网络性能</p></li></ul><h3 id="模型FOCNet"><a href="#模型FOCNet" class="headerlink" title="模型FOCNet"></a>模型FOCNet</h3><p><font color="#0000CD">FOCNet</font>这个框架就是结合了上述动机的<font color="#0000CD">去噪网络</font>。网络的（前向）结构根据<font color="#0000CD">分数阶ODE</font>的离散化设计</p><blockquote><p>介绍一下分数阶网络，其实就是根据power-law memory的power-law机制重新定义了分数阶导数：</p><script type="math/tex; mode=display">\displaystyle \mathscr{D}^{\beta}\mathbf{u}(t)=\lim_{h\rightarrow 0}\dfrac{1}{h^\beta}\sum_{k=0}^{[\frac{t}{h}]}(-1)^k \binom{\beta}{k}\mathbf{u}(t-kh),\ where\ \beta\in (0,1). \tag{1}</script><p>这个式子是很广泛使用的一种分数阶导数定义（确实有别的），叫做<a href="https://en.wikipedia.org/wiki/Gr%C3%BCnwald%E2%80%93Letnikov_derivative" target="_blank" rel="noopener">Grünwald-Letnikov</a>定义</p><p>但是这个定义咋一看式子有些难懂，看维基百科的话，即知，这个定义是推广出来的概念，可以写个2阶导，分子其实就有$f(x),f(x+h),f(x+2h)$三项，推广至整数n阶导其实就是上面$(1)$的形式，$(1)$又把这个阶数推广到一般阶数，如$(0,1)$之间的阶数，至于里面的二项式系数我就不知道咋算的了哈哈</p></blockquote><p>那么FOCNet的<font color="#0000CD">FOC问题</font>整体是这样的：</p><script type="math/tex; mode=display">\displaystyle  \begin{aligned} \min_{\theta (t)} &\dfrac{1}{2}\int_\Omega (\Phi(\mathbf{u}(T,s))-\mathbf{x}(s))^2ds \\ s.t. &\left\{ \begin{aligned} \mathscr{D}_t^{\beta}\mathbf{u}(t,s) &= f(\mathbf{u}(t,s),\theta (t))\\ \mathbf{u}(0,s) &= \Psi (\mathbf{y}(s)),\ t\in [0,T]. \end{aligned}\right. \end{aligned} \tag{2}</script><p>其中输入的脏图是$\mathbf{y}(s)$，真实的gt干净图是$\mathbf{x}(s)$，$s\in\Omega$是图像上的二维坐标。$\Phi$和$\Psi$都是线性变换如卷积，大概是要把图像稍微处理一下，具体是啥应该不是特别重要</p><hr><p>然后就到了加强性能的时候，idea是考虑多<font color="#0000CD">尺度特征交互</font>，加强长期记忆能力。哎，这个多尺度交互的过程我看了好长时间才看明白。。。是我太菜了</p><p>尺度的变换是通过上pooling或者pooling（平均池化）完成的</p><blockquote><p>注：趁机复习补充了一堆上下采样、上pooling、pooling的知识，参考：</p><ol><li>有2种池化的可视化：<a href="http://www.sniper97.cn/index.php/note/deep-learning/3161/" target="_blank" rel="noopener">【吴恩达深度学习】卷积神经网络</a>、<a href="https://zhuanlan.zhihu.com/p/263526076" target="_blank" rel="noopener">深度学习中的各种卷积操作计算指南</a>、<a href="https://www.it610.com/article/1297906069527404544.htm" target="_blank" rel="noopener">上池化(unpooling),上采样(unsampling)和反卷积(deconvolution)的区别</a></li><li>有2种池化的意义解释：<a href="http://www.vtoo.pro/post/37/" target="_blank" rel="noopener">平均池化和最大池化的区别和使用场景</a>、<a href="https://www.zhihu.com/question/23437871" target="_blank" rel="noopener">图像分类中的max pooling和average pooling是对特征的什么来操作的，结果是什么？</a></li><li>都有：<a href="https://www.zhihu.com/question/335595503/answer/778307744" target="_blank" rel="noopener">平均池化和最大池化分别适用于什么场景呢？</a></li></ol></blockquote><p>先上网络的结构图：</p><div style="width:100%;margin:auto"><img src="/2021/03/24/【论文阅读43】FOCNet——网络与分数阶方程的结合/FOC_2.png" title="FOC网络结构"></div><p>用数学形式表示交互的过程为原文第4页的$(8)$式：</p><script type="math/tex; mode=display">\displaystyle \left\{\begin{aligned} \mathscr{D}_t^{\beta}\mathbf{u}(t,s,l_1) &= f(\mathbf{u}(t,s,l_1),g(\mathbf{u}(t,s,l_{1+1})),\theta_1 (t))\\ \mathscr{D}_t^{\beta}\mathbf{u}(t,s,l_2) &= f(\mathbf{u}(t,s,l_2),g(\mathbf{u}(t,s,l_{2\pm 1})),\theta_2 (t))\\ \cdots \\ \mathscr{D}_t^{\beta}\mathbf{u}(t,s,l_k) &= f(\mathbf{u}(t,s,l_k),g(\mathbf{u}(t,s,l_{k-1})),\theta_k (t))\\ \mathbf{u}(0,s,l_1)=&\Psi\mathbf{y}(s),\ \mathbf{u}(0,s,l_i)=T_{\downarrow}\mathbf{u}(1,s,l_{i-1})\\ 1\leq l_i\leq k,\ 0&\leq t\leq T. \end{aligned}\right. \tag{3}</script><p>这个$(3)$式要配合上图一起看，以一般的中间式子$\mathscr{D}_t^{\beta}\mathbf{u}(t,s,l_i) = f(\mathbf{u}(t,s,l_i),g(\mathbf{u}(t,s,l_{i\pm 1})),\theta_i (t))$为例，这个$\beta$阶导数指的是第$i$个尺度（scale）的变化过程，即图中的第$i$行网络。图中第$i$行网络中每个侧着的方形都是一个状态（state），为了前进到下一步，以变化率$f$前进，$f$取决于三个因素，$\mathbf{u}$、$g$和$\theta_i$。其中</p><ul><li>$\mathbf{u}=\mathbf{u}(t,s,l_i)$是前当前state</li><li>$g=g(\mathbf{u}(t,s,l_{i\pm 1}))$中的$g$本身叫做<strong>scale switch</strong>函数（图中最左下角的黑字），包含在图中的浅绿色箭头中，$g(x)=wT(x)$，$w$是0-1二元变量，$T$是pooling或者上pooling算子，也就是说，$g$是把前一个（$i-1$）或者下一个（$i+1$）尺度信息利用到当前尺度（$i$）中的算子，就是图中的浅绿色箭头，式子中的$\pm$就是指中间的尺度可能接受来自上下两个尺度的信息。如图中深蓝色圆圈所示，状态<font color="#0000CD"><strong>2</strong></font>就从下一个尺度的状态<font color="#0000CD"><strong>1</strong></font>进行了scale switch，状态<font color="#0000CD"><strong>4</strong></font>就从上一个尺度的状态<font color="#0000CD"><strong>3</strong></font>进行了scale switch</li><li>最后$\theta_i$就是尺度$i$的网络参数了</li></ul><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>实验在Berkeley Segmentation Dataset和DIV2K的部分数据上进行训练，其中有超参数的选择，如分数阶$\beta$，用多少尺度</p><p>测试则在Set12、BSD68、Urban100三个常用数据集上测试，并和其它诸多方法进行了对比，效果显著。具体可参考文中实验结果表，以及PSNR和计算时间的对比，显然它表现在几个方法中最优，且计算也不慢：</p><div style="width:60%;margin:auto"><img src="/2021/03/24/【论文阅读43】FOCNet——网络与分数阶方程的结合/FOC_3.png" title="PSNR&计算时间对比"></div><hr><p><a href="https://github.com/hsijiaxidian/FOCNet" target="_blank" rel="noopener"><code>FOCNet</code></a>代码中，<a href="https://github.com/hsijiaxidian/FOCNet/blob/master/FracDCNN.m" target="_blank" rel="noopener"><code>FracDCNN.m</code></a>定义了添加网络模块的函数，以及定义了本文的FOCNet，<a href="https://github.com/hsijiaxidian/FOCNet/blob/master/FracDCNN_train_dag.m" target="_blank" rel="noopener"><code>FracDCNN_train_dag.m</code></a>则包含了训练的过程设置</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>通过引入分数阶ODE，网络前向后向传播过程中都有一定的<strong>长期记忆</strong>能力</li><li>利用<strong>多尺度特征交互</strong>，即网络分层的形式，加强了网络性能</li><li>方程做成网络，是残差的形式，训练也好弄</li><li>实验表示去噪的视觉效果和指标都不戳</li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ol><li><p>图像去噪的过往方法：PDE-based，稀疏编码（可能是GAN一类的）、低秩估计（分解），etc</p><p>而过去的方法很多对图像先验的假设是有限的</p><p>那么是否对于general的去噪，先验的作用要削弱；对于specific的去噪任务，自适应加强先验呢❓大概是的，应该有不少工作是要<font color="#FF0000"><strong>自适应学习图像的先验信息</strong></font>，这个模块不能丢掉</p></li><li><p>既然分数阶ODE记忆长期，那么分数阶ODE会有<u><strong>混沌</strong></u>么❓</p></li><li><p>FOCNet也是堆积了网络模块，但其实不是动态网络，结构还是固定的</p></li><li><p>能不能糅合DnCNNs、FOCNet、动态网络得到动态+残差+BN+分数阶方程。。。是不是在瞎搞❓也没啥创意。。。</p></li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] X. Jia, S. Liu, X. Feng, and L. Zhang. Focnet: A fractional optimal control network for image denoising. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 6047–6056.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;RN45,</span><br><span class="line">   author = &#123;Jia, X. and Liu, S. and Feng, X. and Zhang, L.&#125;,</span><br><span class="line">   title = &#123;FOCNet: A Fractional Optimal Control Network for Image Denoising&#125;,</span><br><span class="line">   booktitle = &#123;2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)&#125;,</span><br><span class="line">   pages = &#123;6047-6056&#125;,</span><br><span class="line">   ISBN = &#123;2575-7075&#125;,</span><br><span class="line">   DOI = &#123;10.1109/CVPR.2019.00621&#125;,</span><br><span class="line">   type = &#123;Conference Proceedings&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;为什么不能早看到这篇文章呢？感觉&lt;a href=&quot;20210322-0323.pdf&quot; title=&quot;20210322-0323&quot;&gt;之前&lt;/a&gt;基本上在白淦。。。&lt;/p&gt;
&lt;p&gt;本文标题&lt;em&gt;FOCNet: A Fractional Optimal Control Network for Image Denoising&lt;/em&gt;，网络模型即FOCNet&lt;/p&gt;
&lt;p&gt;是看到的继TNRD后，总第2篇结合DE和网络结构的文章，引入的是分数阶ODE的离散化，带来长期记忆性。有点动态网络的味道，&lt;strong&gt;但不是&lt;/strong&gt;❗&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Denoising" scheme="http://maxliu245.github.io/tags/Denoising/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
  </entry>
  
  <entry>
    <title>【Hexo5】在博客主页侧边栏添加网易云音乐外链&amp;访问者地图</title>
    <link href="http://maxliu245.github.io/2021/03/21/%E3%80%90Hexo5%E3%80%91%E5%9C%A8%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A1%B5%E4%BE%A7%E8%BE%B9%E6%A0%8F%E6%B7%BB%E5%8A%A0%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E5%A4%96%E9%93%BE-%E8%AE%BF%E9%97%AE%E8%80%85%E5%9C%B0%E5%9B%BE/"/>
    <id>http://maxliu245.github.io/2021/03/21/%E3%80%90Hexo5%E3%80%91%E5%9C%A8%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A1%B5%E4%BE%A7%E8%BE%B9%E6%A0%8F%E6%B7%BB%E5%8A%A0%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E5%A4%96%E9%93%BE-%E8%AE%BF%E9%97%AE%E8%80%85%E5%9C%B0%E5%9B%BE/</id>
    <published>2021-03-21T06:08:02.000Z</published>
    <updated>2021-03-21T06:39:55.106Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>今天心血来潮，给博客加了网易云音乐，以及基于<u><a href="https://www.revolvermaps.com/?target=gallery" target="_blank" rel="noopener">RevolverMaps</a></u>的访客地图，地图于2021/03/21开始使用</p><p>这两个操作都放在博客主页侧边栏，不影响正文</p><p>但是要注意，在本地预览的时候，在<u>localhost</u>页面也会统计访客访问量！</p></blockquote><a id="more"></a><h2 id="侧边栏调整"><a href="#侧边栏调整" class="headerlink" title="侧边栏调整"></a>侧边栏调整</h2><p>很长时间没有修改过页面的结构了，都忘了侧边栏在哪里调整了</p><p>在<u>Next</u>主题下，自定义主页侧边栏的路径在</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\themes\next\layout\_macro\sidebar.swig</span><br></pre></td></tr></table></figure><p>在里面判断一下可以插入新东西的位置即可，我选择的是友链下面的区域，如下所示：</p><div style="width:90%;margin:auto"><img src="/2021/03/21/【Hexo5】在博客主页侧边栏添加网易云音乐外链-访问者地图/1.png" title="我选择的插入位置"></div><h2 id="添加网易云音乐"><a href="#添加网易云音乐" class="headerlink" title="添加网易云音乐"></a>添加网易云音乐</h2><p>和在博客正文加入外链是一样的，直接加即可</p><h2 id="添加访问者地图"><a href="#添加访问者地图" class="headerlink" title="添加访问者地图"></a>添加访问者地图</h2><p>我选择的是<a href="https://www.revolvermaps.com/?target=gallery" target="_blank" rel="noopener">RevolverMaps</a>的外链，因为不用注册。在它的网站上自己选择版式，生成外链即可</p><p>地图于2021/03/21开始使用</p><p>注意本地预览的时候发现localhost页面也会统计访客访问量，这一点要注意，像我这样经常本地查看自己笔记的同学可能会<strong>暴露</strong>自己的地理位置。不过没关系，一方面敢写敢发就敢露头，另一方面科学上网也可🤭</p><div style="width:90%;margin:auto"><img src="/2021/03/21/【Hexo5】在博客主页侧边栏添加网易云音乐外链-访问者地图/2.png" title="效果预览"></div><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://blog.csdn.net/qq_40871466/article/details/96276151" target="_blank" rel="noopener">HexoNext添加网易云音乐</a></li><li><a href="https://music.163.com/#/outchain/2/1400256289/" target="_blank" rel="noopener">网易云音乐插件</a></li><li>访问者地图站：<a href="https://www.revolvermaps.com/?target=gallery" target="_blank" rel="noopener">Widget Gallery</a></li><li>地图站介绍：<a href="https://www.jianshu.com/p/e883329f1b99" target="_blank" rel="noopener">RevolverMaps——网站访问统计小工具</a>、<a href="http://www.luoxiao123.cn/revolvermaps-site-visitor.html" target="_blank" rel="noopener">给你的网站添加3D地球显示的访客统计(使用RevolverMaps)</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;今天心血来潮，给博客加了网易云音乐，以及基于&lt;u&gt;&lt;a href=&quot;https://www.revolvermaps.com/?target=gallery&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RevolverMaps&lt;/a&gt;&lt;/u&gt;的访客地图，地图于2021/03/21开始使用&lt;/p&gt;
&lt;p&gt;这两个操作都放在博客主页侧边栏，不影响正文&lt;/p&gt;
&lt;p&gt;但是要注意，在本地预览的时候，在&lt;u&gt;localhost&lt;/u&gt;页面也会统计访客访问量！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Hexo" scheme="http://maxliu245.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读42】神经流形ODE——进一步可构建CNF的流形版本MCNF</title>
    <link href="http://maxliu245.github.io/2021/03/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB42%E3%80%91%E7%A5%9E%E7%BB%8F%E6%B5%81%E5%BD%A2ODE%E2%80%94%E2%80%94%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%8F%AF%E6%9E%84%E5%BB%BACNF%E7%9A%84%E6%B5%81%E5%BD%A2%E7%89%88%E6%9C%ACMCNF/"/>
    <id>http://maxliu245.github.io/2021/03/19/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB42%E3%80%91%E7%A5%9E%E7%BB%8F%E6%B5%81%E5%BD%A2ODE%E2%80%94%E2%80%94%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%8F%AF%E6%9E%84%E5%BB%BACNF%E7%9A%84%E6%B5%81%E5%BD%A2%E7%89%88%E6%9C%ACMCNF/</id>
    <published>2021-03-18T18:11:47.000Z</published>
    <updated>2021-03-21T02:36:54.573Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>本文的标题<em>Neural Manifold Ordinary Differential Equations</em>着实是吸引了我（自己记为<u>MODE</u>）</p><p>摘要里也说这算是NODE的流形版</p><p>那就看看和之前看的<a href="http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/">深度微分同胚归一化流DDNF</a>有啥区别，估摸着大概是DDNF是直接假设隐变量在流形上积分，这个MODE还有把隐变量逆回原始数据空间的操作</p><p>ps：这份笔记写急了，写得很烂。。。不喜请勿食用</p></blockquote><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><div style="width:60%;margin:auto"><img src="/2021/03/19/【论文阅读42】神经流形ODE——进一步可构建CNF的流形版本MCNF/1.png" title="MODE"></div><p>这篇文章是<a href="https://papers.nips.cc/paper/2020" target="_blank" rel="noopener">NeurIPS 2020</a>上的，作者主要来自康奈尔和脸书，其中最后一个作者<a href="https://www.cs.cornell.edu/~cdesa/" target="_blank" rel="noopener">Christopher De Sa</a>是康奈尔大学的，看看人家的<a href="https://www.cs.cornell.edu/~cdesa/" target="_blank" rel="noopener">研究</a>，就离谱。。。</p><p>本文提出的框架叫<strong>神经流形ODE</strong>，简称MODE；进一步结合NF提出MCNF，<strong>流形连续归一化流</strong></p><script type="math/tex; mode=display">MODE= \varphi_k\circ ODE_k\circ (\varphi_k^{-1}\circ \varphi_{k-1})\circ \cdots\circ (\varphi_2^{-1}\circ \varphi_{1})\circ ODE_1 \circ \varphi_1^{-1} \tag{1}</script><p>文献地址：</p><ul><li><a href="https://papers.nips.cc/paper/2020" target="_blank" rel="noopener">NeurIPS 2020</a>：<a href="https://papers.nips.cc/paper/2020/hash/cbf8710b43df3f2c1553e649403426df-Abstract.html" target="_blank" rel="noopener">https://papers.nips.cc/paper/2020/hash/cbf8710b43df3f2c1553e649403426df-Abstract.html</a></li><li>ArXiv：<a href="https://arxiv.org/abs/2006.10254" target="_blank" rel="noopener">https://arxiv.org/abs/2006.10254</a></li><li>原文的审稿记录：<a href="https://papers.nips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-AuthorFeedback.pdf" target="_blank" rel="noopener">https://papers.nips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-AuthorFeedback.pdf</a></li><li>代码：<a href="https://github.com/CUAI/Neural-Manifold-Ordinary-Differential-Equations" target="_blank" rel="noopener">https://github.com/CUAI/Neural-Manifold-Ordinary-Differential-Equations</a></li></ul><h2 id="背景方法"><a href="#背景方法" class="headerlink" title="背景方法"></a>背景方法</h2><p>由于本文针对的<font color="#000FFF">问题</font>是数据中几何结构的建模，所以自然的想法就是隐变量分布在流形上。由此，基本的背景方法是<u>生成模型</u>，偏<u>流</u>的建模或者和<u>流形</u>的联系，有一定可解释性</p><p>具体的背景方法请见原文的第$(2)$章，related work</p><blockquote><p>CNF似乎也是NODE，把隐变量建模，连续变化？查一下确认一下</p></blockquote><h2 id="动机-Idea"><a href="#动机-Idea" class="headerlink" title="动机/Idea"></a>动机/Idea</h2><p>本文的<font color="#000FFF">动机</font>是，生成模型要与流形结合使之有更直观的解释性。但是在<strong>推广到非欧几何</strong>后会有诸多限制，比如可能手动设计网络，对网络施加保持非欧几何性质的限制，这样也会<strong>难以推广</strong>到任意流形</p><blockquote><p>我觉得文章说“<code>难以推广到任意流形</code>”是指若推广到任意流形，则整个映射是微分同胚，意味着数据的几何结构是一样的，而这不现实！</p></blockquote><p><font color="#000FFF">Idea</font>是把NODE进行流形推广，只用（<font color="#000FFF">疑问</font>：真的只用这个？）考虑<strong>局部流形</strong>限制，然后“推广”到整个流形上（<font color="#000FFF">疑问</font>：那这个局部其实是很强的条件，这里所谓的推广应该只是指积分的过程，整个映射未必还保持微分同胚了）</p><p><font color="#000FFF">Idea</font>继续发散，归一化流NF大概是用一系列成串的可逆可微映射拟合一个复杂，且tractable的后验分布。NF中这个整体的分布变换是微分同胚，要求是forward映射的Jacobi好算，逆好算，采样好采。但正因为引入NF，要求两个分布其实是同胚，几何上等价，隐空间中必须保持拓扑性质，这其实对于大多数数据不成立。所以由此退而求其次，本文只取<strong>有限维</strong>光滑流形的假设，不必要是同胚，导出的模型叫做<font color="#000FFF">MCNF</font>，流形连续归一化流</p><p>上述idea弄出来以后，可以理解为MODE的特例，即微分结构（chart）不取指数映射，取id</p><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>本文针对的问题是数据几何建模，结合流模型、NODE的思想</p><h2 id="模型MODE"><a href="#模型MODE" class="headerlink" title="模型MODE"></a>模型MODE</h2><p>基本的<strong>MODE</strong>很简单，<strong>DE设置到流形上即可</strong>，那么一阶导数其实就是切向量场</p><blockquote><p>思路和之前写的<a href="http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/">深度微分同胚归一化流DDNF</a>基本一致！然而投稿差异。。</p></blockquote><p>此ODE前向和后向的计算<strong>不太一样</strong>，前者需要在流形上显示计算，后者单在欧氏空间中计算！</p><p>其中前向的gt（ground truth）一般用数值求解器（solver），过去就有两种方案：投影转化到欧氏空间中求解再投影回去；和隐式方法。在流形上会涉及真正流形上的计算，和李群、指数映射什么的有关。本文表示前者在全局流形意义下点的表示上有所缺陷，后者更简单通用一点，但是本文MODE不就是前者❓这个和我黎曼几何大作业翻译的文章是一致的❗</p><p>后向也不简单，涉及伴随方法、伴随梯度计算，我猜要用G导数和近似。似乎只要取$\mathbb{R}^{2n}$，那么由Whitney Embedding Theorem，$n$维流形$\mathcal{M}$上的曲线就可以嵌入此流形的周围空间（ambient space）。看了附录，本文定理$(4.1)$的证明挺简单的，只用了伴随的定义。这个定理只是<strong>帮助计算</strong>向后传播的梯度的</p><div style="width:60%;margin:auto"><img src="/2021/03/19/【论文阅读42】神经流形ODE——进一步可构建CNF的流形版本MCNF/2.png" title="最终的近似计算：可以选择多次流形-欧氏空间之间的变换"></div><p>那么上述是MODE的思路，计算上就麻烦了，涉及欧氏空间到流形切空间的<strong>指数映射</strong>与伴随方法的<strong>G导数</strong>计算。为此使用了所谓的dynamic chart method方法<strong>近似</strong>优化，还是<font color="#FF0000">近似</font>！详情见优化部分</p><hr><p>进一步MODE的一个应用是CNF的流形形式，称为<strong>MCNF</strong>。这个推广很自然，想想CNF的结构，把隐空间变一下变到流形上就是了，这样看来CNF算是MODE的特例</p><blockquote><p>道理与MODE一样，同胚通过把欧氏空间的局部动力性质积分，然后通过微分结构（本文用的说法是chart，和那个map一致）映射到流形上。CNF就转化到流形空间中了</p></blockquote><h2 id="训练-优化"><a href="#训练-优化" class="headerlink" title="训练/优化"></a>训练/优化</h2><p>MODE的思路只是一个框架，是本文general的<strong>神经流形ODE</strong></p><p>具体计算使用了dynamic chart method，是一个欧氏空间-流形切空间之间变换的近似过程。用到MODE优化中，算是黎曼梯度下降的<strong>替代品</strong>。那么这个方法的一个关键是chart变换的选择，自然的选择是指数映射，局部流形切空间和欧氏空间就联系起来了，但是文章的指数映射<strong><font color="#FF0000">为什么取成</font></strong></p><script type="math/tex; mode=display">z_{t+1}=exp(-\eta \nabla_{z_t} f) \tag{2}</script><p>我不是很明白它的具体选取方式，可能需要自己去查代码</p><p>文章这个方法的一大优点是提供了两个理论保证，此外还有别的：</p><ul><li><strong>理论保证</strong>：定理$(5.1)$是流形ODE局部解的存在性；定理$(5.2)$是收敛性，有限次chart转换就可以了</li><li>对于特定的非欧几何，这个dynamic chart method似乎可以更快，和近似的解析形式有关</li><li>avoid catastrophic gradient instability，这个没看，<strong>没看懂</strong></li></ul><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li><p>流的思想使之适用于密度估计（density estimation）和流相关（downstream tasks）的问题</p></li><li><p>与CNF的对比，是其流形形式manifold analogue</p></li><li><p>与NODE的对比，其流形形式✅，且NODE的拓展，它基本上也可以用啊</p></li><li><p>broader impact，准确建模数据拓扑？确实有意义</p></li></ul><p>缺点略，就是觉得和那个CVPRW2018思路一致，但它就加了个微分结构和一些理论</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验不多，只有一个密度估计和一个变分推断的比较。总的来说，MODE比比较的方法都<strong>显著地好</strong></p><p>但是实验不是太能看得明白，扫了一眼附录，觉得<strong>非常几何</strong>，这个虽然我喜欢，但是确实看不大明白，毕竟没研究过双曲空间、球面的具体性质</p><h2 id="读审稿意见"><a href="#读审稿意见" class="headerlink" title="读审稿意见"></a>读审稿意见</h2><p>感觉出来本文的作者有不少生物、物理上的认识，对方程、流形非常熟悉</p><p>里面也有一些我的疑问，比如chart的选择，作者回应，这是<strong>作为先验显式规定</strong>好的</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Aaron Lou, Derek Lim, Isay Katsman, Leo Huang, Qingxuan Jiang, Ser Nam Lim, and Christopher M De Sa. Neural manifold ordinary differential equations. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 17548–17558. Curran Associates, Inc., 2020.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;NEURIPS2020_cbf8710b,</span><br><span class="line">author = &#123;Lou, Aaron and Lim, Derek and Katsman, Isay and Huang, Leo and Jiang, Qingxuan and Lim, Ser Nam and De Sa, Christopher M&#125;,</span><br><span class="line">booktitle = &#123;Advances in Neural Information Processing Systems&#125;,</span><br><span class="line">editor = &#123;H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin&#125;,</span><br><span class="line">pages = &#123;17548--17558&#125;,</span><br><span class="line">publisher = &#123;Curran Associates, Inc.&#125;,</span><br><span class="line">title = &#123;Neural Manifold Ordinary Differential Equations&#125;,</span><br><span class="line">url = &#123;https://proceedings.neurips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-Paper.pdf&#125;,</span><br><span class="line">volume = &#123;33&#125;,</span><br><span class="line">year = &#123;2020&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文的标题&lt;em&gt;Neural Manifold Ordinary Differential Equations&lt;/em&gt;着实是吸引了我（自己记为&lt;u&gt;MODE&lt;/u&gt;）&lt;/p&gt;
&lt;p&gt;摘要里也说这算是NODE的流形版&lt;/p&gt;
&lt;p&gt;那就看看和之前看的&lt;a href=&quot;http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/&quot;&gt;深度微分同胚归一化流DDNF&lt;/a&gt;有啥区别，估摸着大概是DDNF是直接假设隐变量在流形上积分，这个MODE还有把隐变量逆回原始数据空间的操作&lt;/p&gt;
&lt;p&gt;ps：这份笔记写急了，写得很烂。。。不喜请勿食用&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Manifold" scheme="http://maxliu245.github.io/tags/Manifold/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读41】动态神经网络综述</title>
    <link href="http://maxliu245.github.io/2021/03/18/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB41%E3%80%91%E5%8A%A8%E6%80%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%BC%E8%BF%B0/"/>
    <id>http://maxliu245.github.io/2021/03/18/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB41%E3%80%91%E5%8A%A8%E6%80%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%BC%E8%BF%B0/</id>
    <published>2021-03-18T05:37:17.000Z</published>
    <updated>2021-03-22T00:53:33.714Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>这次略读了综述<em>Dynamic Neural Networks: A Survey</em></p><p>阅读的<u>动机是觉得这个和动力系统有关系</u>，不过读完了没什么感觉，大的感悟是玄学，小的感悟是和元学习、NAS、ODE、流什么的其实都有点关系，觉得框架不太优美，多而杂</p><p>ps：其实没有读完，正文只读了前四大章，到优化训练前面。后面参考他人的博客了解了概览</p><p>ps2：这次写作引入了缩放图片的<a href="http://xring.info/2018/hexo-pic-size.html" target="_blank" rel="noopener">方法</a>，且兼容中文图片标题</p></blockquote><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><div style="width:60%;margin:auto"><img src="/2021/03/18/【论文略读41】动态神经网络综述/1.png" title="Dynamic Neural Networks: A Survey"></div><p><a href="https://arxiv.org/abs/2102.04906" target="_blank" rel="noopener">本文</a>是动态神经网络的一个综述，引言之后就按动态网络分类，分三类介绍，然后讲优化训练技巧，最后讲应用和未来方向。正文15页，作者都是清华的，主力似乎是<a href="http://www.gaohuang.net/" target="_blank" rel="noopener">黄高</a>老师。我自己读到了正文前四大章，到优化/训练的前面。本来想着这个动态网络和NODE有点关系，但是读了一大半发现目前关系不大，下次读文章还是要<u>搞清楚我的初始目标</u>是什么，不然要花好多时间。后面的内容<strong>有人已经总结好了</strong>（<del>虽然自己读的确实详细一点</del>），请参考下列博客：</p><ul><li><p><a href="https://www.toutiao.com/c/user/token/MS4wLjABAAAA9hMKA_HwTPZFwHS1O-PYqDQUiH8qpEJuNpqGuMb9KUg/" target="_blank" rel="noopener">AI科技评论</a>的文章<a href="https://www.toutiao.com/i6939102678295249439" target="_blank" rel="noopener">「深度」清华黄高等人新作：动态神经网络首篇综述</a></p></li><li><p><a href="https://www.zhihu.com/org/bei-jing-zhi-yuan-ren-gong-zhi-neng-yan-jiu-yuan" target="_blank" rel="noopener">北京智源人工智能研究院</a>(<a href="https://www.zhihu.com/question/48510028)的文章[【深度】动态神经网络综述](https://zhuanlan.zhihu.com/p/354507714)，这个和第一个差不多" target="_blank" rel="noopener">https://www.zhihu.com/question/48510028)的文章[【深度】动态神经网络综述](https://zhuanlan.zhihu.com/p/354507714)，这个和第一个差不多</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/149303296" target="_blank" rel="noopener">Dynamic Neural Networks（上）</a>，这个供参考，其实我没读</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@ARTICLE&#123;2021arXiv210204906H,</span><br><span class="line">       author = &#123;&#123;Han&#125;, Yizeng and &#123;Huang&#125;, Gao and &#123;Song&#125;, Shiji and &#123;Yang&#125;, Le and &#123;Wang&#125;, Honghui and &#123;Wang&#125;, Yulin&#125;,</span><br><span class="line">        title = &quot;&#123;Dynamic Neural Networks: A Survey&#125;&quot;,</span><br><span class="line">      journal = &#123;arXiv e-prints&#125;,</span><br><span class="line">     keywords = &#123;Computer Science - Computer Vision and Pattern Recognition&#125;,</span><br><span class="line">         year = 2021,</span><br><span class="line">        month = feb,</span><br><span class="line">          eid = &#123;arXiv:2102.04906&#125;,</span><br><span class="line">        pages = &#123;arXiv:2102.04906&#125;,</span><br><span class="line">archivePrefix = &#123;arXiv&#125;,</span><br><span class="line">       eprint = &#123;2102.04906&#125;,</span><br><span class="line"> primaryClass = &#123;cs.CV&#125;,</span><br><span class="line">       adsurl = &#123;https://ui.adsabs.harvard.edu/abs/2021arXiv210204906H&#125;,</span><br><span class="line">      adsnote = &#123;Provided by the SAO/NASA Astrophysics Data System&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h2><p>动态网络的<font color="#000FFF">背景</font>方法是静态网络，后者有固定的权重、计算图和网络结构；</p><p>研究它的<font color="#000FFF">动机</font>是与静态网络对比，超越其诸多限制；</p><p>要解决的<font color="#000FFF">问题</font>可以分特定任务考虑，也可以说是针对静态网络的缺点（静态限制了表达能力，计算效率，以及某种意义下的可解释性）；</p><p>动态网络的表示方法可以<font color="#000FFF">分</font>为3大<font color="#000FFF">类</font>，具体是<strong>instance-wise，spatial-wise，temporal-wise</strong>。大致就是网络🉑根据每个输入的样本、或样本中的位置（如图像上像素位置）、或时间（主要是TS或视频数据）自适应变化。另外，动态也可以指在测试的时候动态，即自适应推断，测试样本来的时候，可能有级联（非串联）或者并行（不严格是并联）的结构；</p><p>其训练<font color="#000FFF">优化</font>方法也很重要，因为相比静态，动态的训练更难；</p><p>动态网络的<font color="#000FFF">优点</font>，主要是对比静态网络：</p><ul><li>可解释性up，这个解释的角度清奇啊，动态网络可能打通深度模型和人脑机制之间的gap？理由是脑处理信息是动态的，比如接收不同信息后脑的激活区域不同。这个idea是启发式的，所以其实可解释性不强</li><li>计算效率up，比如分配计算，激活部分结构</li><li>表示能力up，参数空间动态变化，更大了</li><li>自适应性🉑，动态平衡准确率和计算效率</li><li>兼容性🉑，与现有方法，技巧基本上兼容</li><li>一般性/泛化性🉑，动态的比静态的更general，应用也都可以用</li></ul><p><font color="#000FFF">缺点</font>，显然的一个缺点是理论证明不充分，只有一小部分启发式的道理，所以玄学感强；</p><p>其未来<font color="#000FFF">研究方向</font>有，继续设计网络结构、优化技巧；寻找应用；补充现在缺乏的理论证明，etc</p><h2 id="方法分类（看图即可）"><a href="#方法分类（看图即可）" class="headerlink" title="方法分类（看图即可）"></a>方法分类（看图即可）</h2><p>这一部分是把综述里列举的动态网络分类一一列出来，和网上的其它博客差不多。写在这里是因为自己看过一遍，就列一遍<u>仅供自己</u>日后回忆</p><p>文章的图$(1)$其实很🉑，看了可以加深对本文的认识，不错，我基本上看懂了。下面是具体的分类：</p><div style="width:95%;margin:auto"><img src="/2021/03/18/【论文略读41】动态神经网络综述/2.png" title="综述分类"></div><ul><li><p>第一大类【instance-wise】</p><p>总的来说，它指根据输入样本，不改变参数时调整使用的计算图（即模型结构）；或者不改变计算图时自适应模型参数（会增大计算消耗但确实性能有所提升）</p><ul><li><p>【动态结构】，主要是推断/测试的时候</p><ul><li><p>【调整网络深度】，具体方法包括</p><ol><li><p>【提前中止网络】，道理是简单样本确实不需要太多计算，难的样本才需要深度特征</p><p>例一是网络级联，参考原文图$(3a)$，不是串联！像树一样分好多模型，选择其中的部分模型；</p><p>例二是在中间层设置分类器，某一层之后如果显著确定类别就可以提前终止了；</p><p>例三是多尺度的提前中止，这个多尺度指的是浅层和深度特征的选择，主要是DenseNet，Dense连接之类的方法，权衡选择浅层或深度特征</p></li><li><p>【跳过某些中间层】，其实有点像提前中止的灵活版，skip的操作可用ResNet那样的连接完成</p><p>例一，halting score，是个分数（标量），具体怎么算没看。感觉是要网络前进过程种这个量会累计，当超过一定的阈值之后网络才会跳到下一层，否则循环上一层；</p><p>例二，门函数（gating functions），输入还是上一层的输出，输出是0或1，原文$(4)$式很清楚。特点是即插即用（plug-and-play）模块，如原文图$(4)$，确实是像开关一样即插即用；</p><p>例三是策略网络，就是单独用一个网络来当门函数，输入取原始的输入，它怎么就能是policy暂时不太明白</p></li></ol></li><li><p>【调整中间层宽度】，具体方法🈶</p><ol><li><p>FC层【动态宽度】，思想是有的神经元表示的特征不太重要，就不必被激活</p></li><li><p>【专家混合（MoE）】，这个和上面的网络级联有点像，但是不会说一个专家网络🆗了其它的网络就不计算了。MoE都计算，只是会为每个专家的输出赋权，权重与样本数据有关，可以通过单独的函数或者输出稀疏系数的hard门函数</p></li><li><p>CNN中的【动态channel剪枝】，这个的idea是对不同样本，有的channel可能用不上，所以可以跳过一些channel（不是真剪了）</p><p>例一，Multi-stage architectures along the channel dimension没看懂；</p><p>例二、三分别是基于门函数和特征激活的动态剪枝。我对剪枝不感兴趣，也看不太明白，不看了</p></li></ol></li><li><p>用超网络【选择计算图路径】，这个主要是讨论怎么确定选择路径的策略，以及超网络的结构。注意之前提早中止也相当于是一种路径选择。具体的实例不感兴趣，怎么觉得和剪枝很像，越看越不明白，怎么看都像NAS，再看就是玄学。和ODE关系不大，不看了！</p></li></ul></li><li><p>【动态参数】，首先还是在样本-wise的框架下，所以这个动态参数是指对每个输入样本，网络的结构不要变，参数有所变化</p><ul><li><p>CNN中的【卷积核参数化】，原文标题weights调整应该就是这个意思，根据输入调整训练参数，这样做的好处是消耗一定的计算资源提高性能。具体细节以前没有关注过，感觉分两种：</p><p>一种是只改卷积核参数，比如用多个核加权近似；</p><p>还有一种是卷积核大小自适应，具体不太了解，应该和感受域大小有关</p></li><li><p>【权重预测】，这个比上一条更暴力，根据输入样本直接预测/生成网络中的滤波器/参数。一般的做法是直接上超网络，输出就是滤波器/卷积算子；另外，特定任务的信息也可以拿来训练生成这些参数</p></li><li><p>【动态特征】，这类方法的动机是利用上述动态参数进行测试/推断的时候，其实生产的特征也是动态的，其中会暗含一些不清楚是什么的新特征；而现在可以更直接地得到这样的动态特征。文章总结了三种方法来获取动态特征：</p><ol><li>利用attention直接对多channel加权；</li><li>利用attention直接对输入的不同位置进行自适应加权；</li><li>直接对激活函数动态加权，方式似乎是在激活函数中引入了调整参数</li></ol></li></ul></li></ul></li></ul><ul><li><p>第二大类【spatial-wise】</p><p>动机合理，vision task中，不是图像中所有区域都很重要，位置信息有冗余；且使用不同分辨率的图像效果也不同。由此动机，空间-wise分三类，<strong>像素自适应、区域自适应和分变量自适应</strong></p><ul><li><p>【像素自适应】，这个自适应又分动态结构、动态参数</p><ol><li><p>【动态结构】，例子是稀疏卷积，指的是只对图像上部分区域进行卷积，这些像素位置可以通过采样位置进行卷积或者先学习mask再卷积</p></li><li><p>【动态参数】</p><p>例一是每个像素位置生成不同的卷积核；</p><p>例二是每一层生成不同的卷积核，这样改变了每一层处理的感受野；</p><p>例三是动态特征，动态参数生成的是动态特征，因此跳过卷积核直接自适应加权像素位置</p></li></ol></li><li><p>【区域自适应】，对图像上不同区域区分，也是要区分图像上空间位置中的冗余信息。可以稀疏采样区域，或者用attention机制、RNN等网络递归学习每一层关注哪个区域</p></li><li><p>【分辨率自适应】这个同区域自适应，也是要区分空间位置中的冗余信息。但是它不是直接按位置来分，而是按照多尺度下，不同分辨率来自适应</p><ol><li>例一是，每一层都自适应选择分辨率尺度；</li><li>例二是，网络的结构级联分层，通过选择上下采样判断下一步使用哪个尺度的模型</li></ol></li></ul></li><li><p>第三大类【时间-wise】</p><p>针对有顺序的数据，如文本、音视频、TS。这个<strong>和流的关系最大</strong></p><ul><li>【文本处理任务】，静态方法的话，可以训练好一个RNN，持续预测后续词句。基于上游每层输出对下游网络影响不同的动机，可以改造成动态网络（很自然的想法就是DenseNet）<ul><li>RNN中中间状态动态更新：例一，不重要的信息可以直接跳层；例二叫做粗略更新，一般会调整隐层的深度或者宽度；例三，高尺度/层的RNN模块判断使用哪些低尺度模型传来的中间状态</li><li>NLP类任务也可以选择跳层/提前中止，或者甚至跳过文本中的部分片段</li></ul></li><li>【视频流任务】，视频流按帧成为TS数据。一种挺无语的处理方式是直接把每一帧编码成所谓特征向量，再当成一般的输入<ul><li>RNN类方法，和前面涉及RNN更新中间状态的方式基本一致</li><li>关键帧选取方法，即不用RNN训练处理判断每一帧。可以直接采样或者attention机制去选择关键帧</li></ul></li></ul></li><li><p>【训练优化策略】</p><p>后面的基本上只看了别人的博客。显然，如果只是动态参数，那么一样的梯度下降就可以；难的是各种结构上的变化怎么弄，即discrete decision making怎么优化，见仁见智了</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这次略读了综述&lt;em&gt;Dynamic Neural Networks: A Survey&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;阅读的&lt;u&gt;动机是觉得这个和动力系统有关系&lt;/u&gt;，不过读完了没什么感觉，大的感悟是玄学，小的感悟是和元学习、NAS、ODE、流什么的其实都有点关系，觉得框架不太优美，多而杂&lt;/p&gt;
&lt;p&gt;ps：其实没有读完，正文只读了前四大章，到优化训练前面。后面参考他人的博客了解了概览&lt;/p&gt;
&lt;p&gt;ps2：这次写作引入了缩放图片的&lt;a href=&quot;http://xring.info/2018/hexo-pic-size.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;方法&lt;/a&gt;，且兼容中文图片标题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读40】DnCNNs——经典去噪方法</title>
    <link href="http://maxliu245.github.io/2021/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB40%E3%80%91DnCNNs%E2%80%94%E2%80%94%E7%BB%8F%E5%85%B8%E5%8E%BB%E5%99%AA%E6%96%B9%E6%B3%95/"/>
    <id>http://maxliu245.github.io/2021/03/15/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB40%E3%80%91DnCNNs%E2%80%94%E2%80%94%E7%BB%8F%E5%85%B8%E5%8E%BB%E5%99%AA%E6%96%B9%E6%B3%95/</id>
    <published>2021-03-15T11:39:48.000Z</published>
    <updated>2021-03-15T13:09:30.279Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>顺着<a href="http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/">【论文略读39】与38相关文章</a>中的第二篇，即<a href="https://www.zhihu.com/people/chen-yun-jin-5" target="_blank" rel="noopener">陈运锦</a>老师的TNRD，找到了这篇文章</p></blockquote><a id="more"></a><h3 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h3> <img src="/2021/03/15/【论文略读40】DnCNNs——经典去噪方法/DnCNNs.png" title="DnCNNs"><p>该文名为Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising，是17年的<strong>TIP</strong>。所提模型是前向的denoising convolutional neural networks，即<font color="#000FFF">DnCNNs</font></p><p>作者是鼎鼎大名的<strong><a href="https://cszn.github.io/" target="_blank" rel="noopener">张凯</a></strong>、陈运锦老师、左老师、孟老师、港理工的<a href="https://www4.comp.polyu.edu.hk/~cslzhang/" target="_blank" rel="noopener">张磊</a>老师</p><ul><li>文献地址：<a href="https://ieeexplore.ieee.org/abstract/document/7839189" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/7839189</a> 或 <a href="https://arxiv.org/abs/1608.03981" target="_blank" rel="noopener">https://arxiv.org/abs/1608.03981</a></li><li>一作张凯提供的代码：<a href="https://github.com/cszn/DnCNN" target="_blank" rel="noopener">https://github.com/cszn/DnCNN</a></li><li>截至2021/03/15，该文在谷歌学术上引用量2868，TNRD的引用量为678，真的迪奥</li><li>根据参考文献中列出的博客来看，这篇文章可谓是图像去噪中的<strong>经典</strong>牛文了</li></ul><blockquote><p>注：由于先入为主，先看了几篇相关博客，讲得应该都没啥问题。所以就没有再在文章上花太多时间了，只是把实验外的部分读了一遍，没有再去思考什么，谨记于此</p></blockquote><h3 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h3><p>本文提出<strong>模型</strong>DnCNNs，针对图像去噪（本文是高斯噪声）<strong>问题</strong>，采用的<strong>网络</strong>是端到端学习带噪图和gt之间残差的CNN，其中不仅引入了<strong>学习残差</strong>的策略，还使用了<strong>BN</strong>（ batch normalization）策略。这样做的<strong>动机</strong>有以往模型的缺点（见图$(2)$下面）、CNN的良好性质、两种改进策略结合的优势、TNRD的启发，等等</p> <img src="/2021/03/15/【论文略读40】DnCNNs——经典去噪方法/DnCNNs-1.png" title="简单理不糙的强效结构"><p>本文除了用大量的实验验证了DnCNNs的性能，还有额外的对比实验，验证了<strong>残差学习和BN结合相互促进</strong>（或者说辅助）的优势，见原文图$(2)$：</p> <img src="/2021/03/15/【论文略读40】DnCNNs——经典去噪方法/DnCNNs-2.png" title="验证残差学习和BN结合相互促进"><p>它的<strong>优点</strong>为何？文章反复强调了以往方法的弱点，包括加深网络后<strong>训练难</strong>度加大、往往<strong>只能针对特定</strong>程度的特定噪声等。<strong>前者</strong>被残差学习加速训练➕BN缓解internal covariate shift（指训练过程中分布变化导致激活后梯度停滞，BN则通过激活前归一化使分布难偏移）以加速收敛给淦了；<strong>后者</strong>被DnCNNs的拓展模型gank了，借鉴TNRD的思想，对模型进行拓展，可以训练单个DnCNNs，同时解决Gaussian denoising，single image super-resolution和JPEG image deblocking三种问题</p><p>本文还有一些<strong>技巧</strong>，比如感受野和网络深度的选择，与TNRD的比较等，略</p><p>最后，本文的作者们表示，更genral的去更general噪的方法是研究的目标，目前来看，unfolding、plug-and-play（即插即用）模块设计等都是研究的方向</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising. IEEE Transactions on Image Processing, 26(7):3142–3155, 2017.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@article&#123;RN37,</span><br><span class="line">   author = &#123;Zhang, K. and Zuo, W. and Chen, Y. and Meng, D. and Zhang, L.&#125;,</span><br><span class="line">   title = &#123;Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising&#125;,</span><br><span class="line">   journal = &#123;IEEE Transactions on Image Processing&#125;,</span><br><span class="line">   volume = &#123;26&#125;,</span><br><span class="line">   number = &#123;7&#125;,</span><br><span class="line">   pages = &#123;3142-3155&#125;,</span><br><span class="line">   ISSN = &#123;1941-0042&#125;,</span><br><span class="line">   DOI = &#123;10.1109/TIP.2017.2662206&#125;,</span><br><span class="line">   year = &#123;2017&#125;,</span><br><span class="line">   type = &#123;Journal Article&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要参考的博客：</p><ol><li>有重要思考的博客：<a href="https://blog.csdn.net/ewen_lee/article/details/106851978" target="_blank" rel="noopener">【图像去噪】DnCNN论文详解（Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising）…</a></li><li>总结精辟的博客：<a href="https://blog.csdn.net/weixin_41923961/article/details/80382529" target="_blank" rel="noopener">DnCNN论文阅读笔记【MATLAB】</a></li><li>纯翻译：<a href="https://blog.csdn.net/u013049912/article/details/86609356" target="_blank" rel="noopener">Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising</a></li><li>讲了一点DnCNNs后续发展：<a href="https://zhuanlan.zhihu.com/p/94382390" target="_blank" rel="noopener">基于卷积神经网络的图像去噪</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;顺着&lt;a href=&quot;http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/&quot;&gt;【论文略读39】与38相关文章&lt;/a&gt;中的第二篇，即&lt;a href=&quot;https://www.zhihu.com/people/chen-yun-jin-5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈运锦&lt;/a&gt;老师的TNRD，找到了这篇文章&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Denoising" scheme="http://maxliu245.github.io/tags/Denoising/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
      <category term="CNN" scheme="http://maxliu245.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读39】与38相关文章</title>
    <link href="http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/"/>
    <id>http://maxliu245.github.io/2021/03/09/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB39%E3%80%91%E4%B8%8E38%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0/</id>
    <published>2021-03-09T02:04:19.000Z</published>
    <updated>2021-03-14T16:09:14.374Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>截至2021/03/08，谷歌学术上引用林老师<em>Learning PDEs for Image Restoration via Optimal Control</em>的有46篇，打算抽上几篇看看，目前只看了3篇（有笔记的）</p><p>ps1：发现林老师此文引用量不高可能是因为没复现代码？</p><p>ps2：这次写作的时候发现，如果断网，本地localhost预览博客可能会出现公式无法渲染的问题</p></blockquote><a id="more"></a>  <h2 id="Adaptive-Partial-Differential-Equation-Learning-for-Visual-Saliency-Detection"><a href="#Adaptive-Partial-Differential-Equation-Learning-for-Visual-Saliency-Detection" class="headerlink" title="Adaptive Partial Differential Equation Learning for Visual Saliency Detection"></a>Adaptive Partial Differential Equation Learning for Visual Saliency Detection</h2><h3 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h3><p>这篇文章是刘日升林宙辰老师的CVPR2014的文章，百度显示至2021/03/09引用量131。标题表明本文提出的<strong>模型是自适应学习PDE</strong>，模型叫做Linear Elliptic System with Dirichlet boundary （<strong>LESD</strong>），<strong>目标是视觉显著性检测</strong></p><blockquote><p>注1：这个视觉显著性指的是图像中的重要区域，参考这个<a href="https://max.book118.com/html/2017/0607/112170172.shtm" target="_blank" rel="noopener">PPT</a>，比较清楚</p><p>注2：显著性后续似乎有别人的很顺眼的工作：参考<a href="http://dpfan.net/SOCBenchmark/" target="_blank" rel="noopener">Salient Objects in Clutter: Bringing Salient Object Detection to the Foreground</a></p><p>注3：读了本文之后觉得它似乎是尝试<strong>用传统CV方法解决近年来CV问题</strong>。。。好像<strong>没用神经网络</strong>耶</p></blockquote><p>文献地址参考：<a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Liu_Adaptive_Partial_Differential_2014_CVPR_paper.html" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_cvpr_2014/html/Liu_Adaptive_Partial_Differential_2014_CVPR_paper.html</a></p><h3 id="背景方法与动机"><a href="#背景方法与动机" class="headerlink" title="背景方法与动机"></a>背景方法与动机</h3><p>本文的target是显著性检测，分为<strong>bottom-up和top-down</strong>方法，前者是<strong>数据驱动</strong>，具体又有纹理特征判断、对比度判断等；后者是<strong>模型驱动</strong>，直接监督或者通过显著图（map）监督，等</p><p>本文的动机：</p><ul><li><p>这个target的问题不简单，要把人的感知（显著区域）和高级（复杂）的先验弄进PDE</p></li><li><p>林宙辰老师之前ECCV2010的工作有个缺点，对图像的刻画适合传统CV（参考GT的CV课程），对近年来的CV高级任务不合适</p><blockquote><p>ps：读了本文之后觉得它似乎是尝试用传统CV方法解决近年来CV问题。。。</p></blockquote></li></ul><h3 id="模型LESD与实验"><a href="#模型LESD与实验" class="headerlink" title="模型LESD与实验"></a>模型LESD与实验</h3><p>本文提出的模型叫Linear Elliptic System with Dirichlet boundary （LESD），是自适应学习PDE，此PDE的特点是<strong>假设</strong>了<strong>显著性扩散</strong>，<strong>学习的目标</strong>是LESD的<strong>公式形式和边界条件</strong>。具体扩散的<strong>假设是核心</strong>！</p><p>模拟了人的注意力机制，先注意到图像的一个极其显著的区域，即人注意到的初始区域，记为$\mathcal{S}$，称为<strong>显著性种子</strong>，然后用PDE模拟注意力转移（扩散）的过程。</p><p>下面开始建模，向量或者位置用粗体字母表示。设整个图片区域为$V$，可以由像素点$\mathbf{p}$或者像素块$\mathbf{p}$（超像素）组成；定义实值的<strong>注意力score函数</strong>，记为$f(\mathbf{p})\overset{def}{=}s_\mathbf{p}$，支集定义在$\mathcal{S}$上。那么在Dirichelet边界条件（$V$内$\mathcal{S}$外$f=0$）下，显著性（注意力）扩散的PDE方程为</p><script type="math/tex; mode=display">\displaystyle \dfrac{\partial f(\mathbb{p},t)}{\partial t}=F(f,\nabla f),\ f(\mathbf{g})=0,\ f(\mathbf{p})=s_{\mathbf{p}},\ \mathbf{p}\in \mathcal{S}. \tag{1}</script><p>其中$\mathbf{g}$是$V$之外的点，分数为0。$F$就是一个待定函数</p><p>这个score函数$f$对时间的偏导$F$定义为线性扩散项，$div(K_{\mathbf{p}}\nabla  f(\mathbf{p}))$，$K_{\mathbf{p}}$是一个非均匀度量张量，用于控制$\mathbf{p}$处的局部扩散率。人的感知怎么导入方程？用正则项，用$\mathbf{p}$的得分和引导图$g(\mathbf{p})$（此$g$是实值函数，非彼$\mathbf{g}$）的差异度量。。。即</p><script type="math/tex; mode=display">F(f,\nabla f)=div(K_{\mathbf{p}}\nabla  f(\mathbf{p}))+\lambda (f(\mathbf{p})-g(\mathbf{p})). \tag{2}</script><p>其中度量$K_{\mathbf{p}}$和引导图$g$是干什么的？前者和$f$的形式参考原文$(2.3)$节，后者参考原文$(3.2)$节。。。看的有点累，到处找概念。<strong>大概就是</strong>本文把图像看成超像素集合，构建了点集意义（即没有概率意义）上的<strong>无向图</strong>，在注意力区域内$\mathbf{p}$和其多个邻域内的点有连接，连接之间的度量代表扩散的程度，因此$K_{\mathbf{p}}$真的是个度量矩阵，矩阵则有高斯核决定；然后由$K_{\mathbf{p}}$和$g(\mathbf{p})$联合定义了$f(\mathbf{p})$，形式我觉得不重要不写了；最后引导图$g$比较麻烦，本文自己定义出了一个点属于前景的概率$f_f(\mathbf{p})$，乘上本文的参考文献$[34]$中提出的color prior map$f_c$和center prior map$f_l$，最后归一化得到所谓的引导图。我对它的意义不是很理解，只知道是把先验信息弄成像文中图$(3,4)$底部那样的图（取值为$[0,1]$），然后在PDE的约束下去优化得到注意力（显著性）区域</p><p>上面所述就是本文的LESD框架，接着假定注意力<strong>得分函数随时间不变</strong>！为什么？因为我们需要就是给定一张图片后，显著性固定，不随时间$t$变化🆗。由此令$(1)$式中的$F=0$，就是LESD的final形式。现在看这个方程的话，显著性信息就体现在$g$所在区域和$\mathcal{S}$区域的划分上，它们体现了人的感知先验和初始注意力区域的选择</p><p>最最后再说一下LESD模型的可行性：文章给出了定理$1$，它保证，在LESD的假设下，score函数$f$是单调次模函数，次模的概念可参考<a href="https://www.zhihu.com/question/34720027" target="_blank" rel="noopener">知乎问题</a>，但是具体定义为什么保证可行性我先<strong>不管了</strong>。。。</p><p>实验的话，实验部分不管了，我喜欢的是它展示了一些更改先验感知信息$g$，更改初始区域$\mathcal{S}$的例子，分别见图$(3,4)$。另外展示了实际数据实验的预测准确率等</p> <img src="/2021/03/09/【论文略读39】与38相关文章/1-1.png" title="先验信息引入、更改初始注意区域的实例"><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点</p><ul><li><p>动机不错，考虑更复杂的任务，ECCV2010的PDE形式不太合适了</p></li><li><p>模型LESD新颖，又是<strong>图</strong>的建立又是传统CV，还是很interesting的</p></li><li><p>文章表示LESD的公式中包含了bottom-up和top-down的先验信息。yysy确实既有模型驱动也有数据驱动</p></li><li><p>文章表示对LESD既有数值，也<strong>有理论</strong>分析</p></li><li>和之前ECCV2010小小<strong>对比</strong>了下，Discussion部分提了几句，二者target任务不同，本文的任务难一些；二者都是PDE学习，PDE的形式不同；训练的方式不同，10年的是稀疏回归，本文更像是<strong>古典CV</strong>，从文中算法$1$可以看出来，构造点的连接，然后优化也是离散的，<strong>没有涉及网络结构</strong>（应该没有）</li></ul><p>缺点的话，看不出来啥缺点，可以自圆其说（虽然我不太懂），无情的刷文机器。。</p><h3 id="自己的问题（待解决）"><a href="#自己的问题（待解决）" class="headerlink" title="自己的问题（待解决）"></a>自己的问题（待解决）</h3><p>文中提了一句PDE处理图像问题的<strong>合理性</strong>：the multiscale representation of images are indeed solutions of heat equation with different time parameters，我喵喵喵？迷迷糊糊明白一点，但是这个理论需要专门去了解么？</p><h2 id="Trainable-Nonlinear-Reaction-Diffusion-A-Flexible-Framework-for-Fast-and-Effective-Image-Restoration"><a href="#Trainable-Nonlinear-Reaction-Diffusion-A-Flexible-Framework-for-Fast-and-Effective-Image-Restoration" class="headerlink" title="Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration"></a>Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration</h2><p>这文章吓到我了，被干吐了。。</p><h3 id="文献信息-1"><a href="#文献信息-1" class="headerlink" title="文献信息"></a>文献信息</h3><p>本文是16年的TPAMI，一作<a href="https://www.zhihu.com/people/chen-yun-jin-5" target="_blank" rel="noopener">陈运锦</a>老师，从各方面的资料这个文章还是很猛的</p><ul><li>文献地址：<a href="https://ieeexplore.ieee.org/abstract/document/7527621" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/7527621</a></li><li>一作自己的评论：<a href="https://www.zhihu.com/question/62599196/answer/233376903" target="_blank" rel="noopener">https://www.zhihu.com/question/62599196/answer/233376903</a></li><li><a href="https://blog.csdn.net/qq_25196865" target="_blank" rel="noopener">_JoeZoe</a>关于<strong>TNRD</strong>模型的博客：<a href="https://blog.csdn.net/qq_25196865/article/details/78894051" target="_blank" rel="noopener">https://blog.csdn.net/qq_25196865/article/details/78894051</a></li><li>引用了此文的一个专利：<a href="http://www.xjishu.com/zhuanli/55/201810750492.html" target="_blank" rel="noopener">一种基于深度学习的自适应图像去噪方法与流程</a></li><li>代码实在是找不着，可能在<a href="https://github.com/leolee5633/Part-III-project" target="_blank" rel="noopener">这里</a>。。</li><li>TNRD的一个拓展<a href="https://epubs.siam.org/doi/abs/10.1137/16M1093707" target="_blank" rel="noopener">Image Denoising via Multiscale Nonlinear Diffusion Models</a>，大概就是在下面网络结构图里，第一次卷积前和第二次卷积后分别加一次下、上采样</li></ul><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><blockquote><p>这部分写得细但是乱，<strong>不利</strong>于展示！</p></blockquote><p>背景是图像恢复/修复问题，图像恢复方法的两个评价对象，修复质量和计算效率。本文在其中的PDE方法上进行改进，下面回顾一下本文主要参考的PDE方法：</p><p>刚开始的PM扩散方程</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dfrac{\partial u}{\partial t} &= div(g(|\nabla u|)\nabla u) \\ u|_{t=0} &= f \end{aligned} \right., \tag{3}</script><p>其中$f$是初始待恢复图像，$g$称为边缘停止（edge-stopping）函数或<strong>扩散函数</strong>，经典的是$\displaystyle g(z)=\dfrac{1}{1+z^2}$。PM扩散方程的特点是非线性各向异性扩散，可以保持和增强图像边缘，我也不知道为什么，但必和这个$div$的形式有关</p><p>从PDE的角度去改进，可以改进/选择的有扩散函数、方程的最优停止时间和合适的反作用力（反应扩散方程中的概念），由此，一般的形式如下，即加了正则$\kappa (u)$、系数$a$和各种不变量或者算子$\mathcal{O}(u)$，这个形式和先前林宙辰老师的文章一致：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dfrac{\partial u}{\partial t} &= \kappa (u) + a(t)^T\mathcal{O}(u) \\ u|_{t=0} &= f \end{aligned} \right.. \tag{4}</script><p>从传统CV处理图像的方式看，把图像展成列向量$u\in\mathbb{R}^N$，那么</p><script type="math/tex; mode=display">\displaystyle \nabla u\approx \dfrac{u_{t+1}-u_t}{\Delta t}=-\sum_{i=\{x,y\}}\nabla_i^T\Lambda(u_t)\nabla_iu_t\overset{\cdot}{=}-\sum_{i=\{x,y\}}\nabla_i^T\phi(\nabla_iu_t). \tag{5}</script><p>其中$\Lambda(u_t)=diag\left(g\left(\sqrt{(\nabla_xu_t)_p^2+(\nabla_yu_t)_p^2}\right)\right)_{p=1,\cdots,N}$是$N\times N$的对角阵，$g$是扩散函数，$\nabla_x$和$\nabla_y\in \mathbb{R}^{N\times N}$是$x,y$两个方向上的梯度的差分近似，这里算子为$N\times N$维，作用在$u_t\in\mathbb{R}^N$上很奇怪，<strong><font color="#FF0000">这一点我没看懂</font></strong>（<strong>懂了</strong>，见下一段），先跳过。另外定义的$\phi(z)=zg(z)$就是影响函数，也成为flux函数，似乎这个对角阵$\Lambda(u_t)$的元素是和$\nabla u_t$的分量一一对应的，<strong><font color="#FF0000">这一点我也没看懂</font></strong>，先跳过</p><p>上面是基本的反应扩散方程模型，扩散的过程对应求能量泛函（也可以说是惩罚项）$\displaystyle \mathcal{R}=\sum_{i\in\{x,y\}}\sum_{p=1}^N\rho((k_i<em>u)_p)$的极小，但是<strong><font color="#FF0000">为什么是惩罚项是这样的呢</font></strong>？其中函数$\rho$就是惩罚项，如$\rho(z)=\log(1+z^2)$，不知道这里$\rho^\prime (z)=\phi (z)$有没有什么意义。另外注意这里$\nabla_xu$是<em>*矩阵和向量的积</em></em>，对应线性滤波$k_x=[-1,1]$的作用，确实，从差分的角度看这样是合理的，同理$\nabla_y$对应线性滤波$k_y=[-1,1]^T$的作用</p><h3 id="TNRD小结"><a href="#TNRD小结" class="headerlink" title="TNRD小结"></a>TNRD小结</h3><p>本文针对图像恢复问题，提出<strong>模型</strong>TNRD，即标题里的Trainable Nonlinear Reaction Diffusion。它的模型<strong>核心/idea</strong>是在反应扩散方程中使用了时变的线性滤波器和影响函数（influence function）；<strong>动机</strong>是尽管最近（16年前）的PDE方法在许多图像处理任务中表现出良好的性能，但它们仍然不能为经典的图像恢复任务产生最先进的质量；<strong>优化</strong>方法是数据驱动，直接最小化损失函数。进行的<strong>实验</strong>有三个， 高斯图像去噪、单图超分辨、和JPEG deblocking，具体实验很多先不看了</p><p>TNRD模型的细节还是比较多的，所以还是决定小结一下</p><p>整体的general TNRD模型如<a href="https://blog.csdn.net/qq_25196865/article/details/78894051" target="_blank" rel="noopener">博客</a>所述，其实就是：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \min_{\Theta} &= \sum_{s=1}^S \frac{1}{2}||u_T^s-u_{gt}^s||_2^2 \\ s.t. &\left\{ \begin{aligned} u_0^s &= I_0^s\\ u_t^s &= Prox_{\mathcal{G}}\left(u_{t-1}^s-\left(\sum_{i=1}^{N_k}(K_i^t)^T\phi_i^t(K_i^tu_{t-1}^s)+\psi^t(u_{t-1}^s,f^s)\right)\right) \\ t &= 1,\cdots,T\end{aligned} \right. \end{aligned} \right.. \tag{5}</script> <img src="/2021/03/09/【论文略读39】与38相关文章/2-1.png" title="TNRD的网络结构解释"><p>优化目标中的$u_{gt}$指ground truth图像，$u_{T}$是方程最后一个stage（第$T$个，一共也是$T$个stage）的输出，$s$指有这么多样本，训练集一共$S$张图像，目标也可以使用其它的loss，应该是的🤔；$(5)$式中的条件是general的TNRD，$I_0^s$指第$s$个样本对应的初始带噪图像，是输入的初值</p><p>然后要分析最长的那个式子，它也是最复杂的，还是建议参考文章的图$(1)$来理解，如上图。对第$t-1$个stage的第$s$个样本$u_{t-1}^s$的操作如上图蓝色方框所示，对应关系直接给出来，也省得我写一堆字了。其中要<strong>注意</strong>，网络结构中，第二个卷积（即对应线性滤波）和第一个卷积有关联，注意看第二个卷积头上有一$\bar{}$，表示是把第一个卷积<strong>旋转</strong>了$180^\circ$！最后最外层的$Prox_{\mathcal{G}}$叫proximal mapping operation，具体公式参考原文图$(1)$下面的公式，它套在最外面是为了让里面的式子可求导，所以用这个所谓的近似映射，怎么近似的就不管啦</p><font color="#0000FF">最后提一下设置这样形式的反应扩散方程的道理，首先要强调的一点是**这种结构是从传统算法推导出来的**，思路就是从上文的背景模型一步步推出方程，然后里面的反应项（force项）和扩散项就这样设计了。。。我觉得还是从$\nabla u$的离散近似出发，设置成线性滤波的形式，后面的force项则引入影响函数，这样设计出来的，真是的思路还是要参考以前的文献了，此处估计日后不怎么看了</font><blockquote><p>作者原话，来自知乎：</p><p>这种网络结构是从传统算法推导出来的，不是刻意设计的，然后恰好就和<em>EDSR</em>的<em>residual block</em>的结构相似啦。那是不是意味着<em>EDSR</em>的<em>residual block</em>的结构选择成目前这个样子，效果就好，有一些深层次的原因呢？需要paper的筒子们刻意挖一挖嘛。</p></blockquote><p>另外有个trick是网络中的非线性激活函数由基函数拟合出，文中是63个高斯径向基函数线性组合，这样组合出来的非线性函数的形状可以比较任意，我<font color="#0000FF">寻思着这会增加计算复杂度</font>（不像是提前决定好的啊）啊</p><p>至于训练方法什么的，再见，叭看！</p><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p>它的优点有：</p><ul><li>是个灵活的可学习框架，是有线性滤波和影响函数的非线性反应扩散模型</li><li>调整结构可以适用于多种图像恢复中的任务（如提到的3个实验）</li><li>模型保持了非线性扩散模型的结构简单性，并且只需要少量的扩散步骤，因此高效</li><li>似乎是因为结构简单性，可在GPU上高速训练</li><li>文章表示较好地平衡了计算效率和去噪质量的关系（难道是实验的观察结论）</li></ul><p>缺点：</p><ul><li><p>是基于先验知识的分析模型，在获取图像全部特征结构时受到限制，以及在整个训练阶段需要手动的微调参数，此外这些方法训练出的模型都是针对已知具体的噪声级，无法实现未知噪声级图像的盲去噪</p><blockquote><p>这些话是引自一个专利的，参考<a href="http://www.xjishu.com/zhuanli/55/201810750492.html" target="_blank" rel="noopener">一种基于深度学习的自适应图像去噪方法与流程</a></p></blockquote></li><li><p>文章自己表示，本文TNRD只适合监督，这似乎不算什么缺点。。</p></li><li><p>另外我有不少问题，不见得是缺点吧，<strong>见上文的彩色字体部分</strong></p></li></ul><h2 id="Toward-designing-intelligent-PDEs-for-computer-vision-An-optimal-control-approach"><a href="#Toward-designing-intelligent-PDEs-for-computer-vision-An-optimal-control-approach" class="headerlink" title="Toward designing intelligent PDEs for computer vision: An optimal control approach"></a>Toward designing intelligent PDEs for computer vision: An optimal control approach</h2><h3 id="文献信息-2"><a href="#文献信息-2" class="headerlink" title="文献信息"></a>文献信息</h3><p>这篇文章是刘日升、林宙辰老师等于11年提交，12年接收，发在Image and Vision Computing这个刊上的</p><p>文献地址：<a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885612001746" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/S0262885612001746</a></p><p> 观标题，是用PDE解图像处理问题，这次准备了一个自己去找的框架，不知道是不是又是字典稀疏回归，且待分解~是的，要学习的<strong>与时间$t$相关</strong>的系数，而且字典大得一批。。</p><img src="/2021/03/09/【论文略读39】与38相关文章/3-1.png" title="本文稀疏回归使用的字典"><h3 id="文献小结"><a href="#文献小结" class="headerlink" title="文献小结"></a>文献小结</h3><p>这个文章年限摆在那里，<strong>方法</strong>还是一个以PDE为条件的优化问题。考虑自动从数据中学习限制条件PDE，<strong>动机</strong>是视觉任务的intuition和手动设计PDE不优美，另外考虑把适合多数视觉任务的不变性当成基本的不变量扔进方程。PDE仍然是要学习<strong>不变量</strong>的<strong>系数</strong>，其中最高考虑的是2阶的不变量，这个阶指的是导数的阶，主要包括<strong>平移和旋转不变性</strong>。优化的目标是正常的loss，输出用ground truth监督</p><h3 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h3><p>这个自动学习PDE的框架有个特点，考虑了<strong>两组</strong>PDE方程，一个方程用来控制输出图像$u$的变化（evolution）过程；另一个作为所谓的indicator函数$v$，它学习图像的全局特征，<strong>辅助监督</strong>第一个方程。它的形式如下所示：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} &\dfrac{\partial u}{\partial t} = F_u(u,v,\mathbf{a}),\ (x,y,t)\in Q, \\ &u(x,y,t) = 0,\ (x,y,t)\in \Gamma, \\ &u|_{t=0} = f_u,\ (x,y)\in \Omega. \\ &\dfrac{\partial v}{\partial t} = F_v(v,u,\mathbf{b}),\ (x,y,t)\in Q, \\ &v(x,y,t) = 0,\ (x,y,t)\in \Gamma, \\ &v|_{t=0} = f_v,\ (x,y)\in \Omega.\end{aligned} \right.. \tag{6}</script><p>如上，直接的观察结论是$u$和$v$的演化都用$F$表示，但是内容可能不同。不过本文中，都还是各种不变量的线性组合</p><p>由动机，手动设计PDE，不仅可能只适用少数问题，还很麻烦。因此只说，<strong>平移不变性和旋转不变性</strong>是大多数vision task的<strong>共性</strong>，若要保持这些性质，PDE方程的形式需要是平移、旋转这样的算子下不变的（有点像群在集合上作用那味儿），也是这些不变量的函数，依据是文章引用的<em>微分不变量理论</em>。。。</p><p>文章声明最高考虑的是2阶的不变量，其理由主要在于更高阶的不变量会有数值问题，以及字典太大导致计算复杂，还有当模型<strong>拓展为针对三通道图像</strong>时字典更是加大</p><p>PDE方程就是这样，没啥。对于优化，优化的目标函数（能量泛函）也很正常，是gt的监督以及两组系数$\mathbf{a,b}$的正则。优化的方法仍然是伴随方法，推导G导数，然后近似迭代</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>优点：</p><ol><li>相比原始的10年文章，这个框架引入的不变量更多，还包括一些耦合的不变量，因此框架适用于更多vision task，包括边缘检测、去噪、修复，etc</li><li>这个证了不变量具有的平移和旋转不变性（没看）</li></ol><p>所以说这个文章算是10年那个文章的<strong>直接推广</strong>，PDE在形式上增广了，加了些不变性理论，加了些实验</p><p>最后，注意下几个小知识点：</p><ol><li>文中提到一个有意思的思路叫<em>Multi-layer PDE systems</em>，每层PDE的形式相同，即最多二阶的不变量的线性组合。但每一层的参数值和初值不同，具体采用贪婪策略学习多层结构，即每一层确定后，用上一层的输出作为下一层的输入。每一层的预期输出都是gt！那么由于每一层都在逼近gt，这样做可能能<strong>连续地提高近似的精度</strong></li><li>突然意识到，这些基于PDE的方法和<strong>水平集</strong>拓展方法的设计思想没什么区别啊！</li></ol><h2 id="其它暂未阅读的文献"><a href="#其它暂未阅读的文献" class="headerlink" title="其它暂未阅读的文献"></a>其它暂未阅读的文献</h2><ul><li>董彬老师组18年PMLR的<a href="http://proceedings.mlr.press/v80/lu18d.html" target="_blank" rel="noopener">Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations</a></li><li>剑桥的奇怪杂志Acta Numerica上的<a href="https://www.cambridge.org/core/journals/acta-numerica/article/solving-inverse-problems-using-datadriven-models/CE5B3725869AEAF46E04874115B0AB15?__cf_chl_jschl_tk__=58c78f0b80836ffecb5c616c191f72229855d968-1615168268-0-AbGsCfjDCGWPcOgqc6G8cxdlSM63cp31QBNUZo6CojNnGl9t9bVPq7a7Go3_OCjrA7kNQW4KlxVvgcy4y3QBD1VGcBltZpX1hyW_goa8Ttr4ckII-npANh-NDlEbTnJXHurph-0Sqvinh3WLs9k0fGVP7pdp6IOIMJg1c-5m9nHwSkwPtjcd4-7gFB7qTBUwZl-LyIHYip6-5bhNE4FOFeus1eZ50MZVoJZslP3Wgx9pm_-uXaGRJqtsZr37cEpjKD9riKLSl9VJI-HeTWrJ0gtfMKdrwoJwA233iklZ_KGsmkJDpY71Ud3ngVIlwoVdFlFIxX6DtX6t9_-vRNhxbyZF-KU5FpOIsknLlVw_rZ52u7j9BBA4AVatjl3KFD_IYrjJ2ij5iL3cRk-ILUWKAF7CXwY_p2_6bgPXIfnFt0NqGemTbND91TildOhUg6YVvCkhhFItAhYZyLOYVeobbbwHpxOapeRM85OMYRPeE9agati9v2VN8zHF_lBSdFTjKc3LxBZPhW3uBID7qmmPRTolcbubz0XVL6CnFzIqs-R-" target="_blank" rel="noopener">Solving inverse problems using data-driven models</a>，不打算看了，174页，像是综述+写书</li><li>老师一作在CVPR2015上的<a href="https://openaccess.thecvf.com/content_cvpr_2015/html/Chen_On_Learning_Optimized_2015_CVPR_paper.html" target="_blank" rel="noopener">On Learning Optimized Reaction Diffusion Processes for Effective Image Restoration</a></li><li>Neural Computing and Applications 2018上的<a href="https://link.springer.com/article/10.1007/s00521-016-2623-y" target="_blank" rel="noopener">Learning sparse partial differential equations for vector-valued images</a></li><li>ICASSP 2019上的<a href="https://ieeexplore.ieee.org/abstract/document/8682944" target="_blank" rel="noopener">Learning Compact Partial Differential Equations for Color Images with Efficiency</a></li><li>刘日升老师的Valse课件<a href="http://valser.org/webinar/slide/slides/20141022/LPDE_RishengLiu.pdf" target="_blank" rel="noopener">Learning-Based PDE: A New Perspective for PDE Methods in Computer Vision</a></li><li>西交孙剑老师的Review，中国工业与应用数学学会，received on 22 April 2020；accepted on 16 June 2020，<a href="https://doc.global-sci.org/uploads/Issue/CSIAM-AM/v1n3/13_365.pdf?1603081030" target="_blank" rel="noopener">Model Meets Deep Learning in Image Inverse Problems</a></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Risheng Liu, Junjie Cao, Zhouchen Lin, and Shiguang Shan. Adaptive partial differential equation learning for visual saliency detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2014.</p><p>[2] Y. Chen and T. Pock. Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(6):1256–1272, 2017.</p><p>[3] Risheng Liu, Zhouchen Lin, Wei Zhang, Kewei Tang, and Zhixun Su. Toward designing intelligent pdes for computer vision: An optimal control approach. Image and Vision Computing, 31(1):43–56, 2013.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;截至2021/03/08，谷歌学术上引用林老师&lt;em&gt;Learning PDEs for Image Restoration via Optimal Control&lt;/em&gt;的有46篇，打算抽上几篇看看，目前只看了3篇（有笔记的）&lt;/p&gt;
&lt;p&gt;ps1：发现林老师此文引用量不高可能是因为没复现代码？&lt;/p&gt;
&lt;p&gt;ps2：这次写作的时候发现，如果断网，本地localhost预览博客可能会出现公式无法渲染的问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Machine Learning" scheme="http://maxliu245.github.io/tags/Machine-Learning/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读38】重读Learning PDEs for Image Restoration via Optimal Control</title>
    <link href="http://maxliu245.github.io/2021/03/07/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB38%E3%80%91%E9%87%8D%E8%AF%BBLearning-PDEs-for-Image-Restoration-via-Optimal-Control/"/>
    <id>http://maxliu245.github.io/2021/03/07/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB38%E3%80%91%E9%87%8D%E8%AF%BBLearning-PDEs-for-Image-Restoration-via-Optimal-Control/</id>
    <published>2021-03-07T14:44:12.000Z</published>
    <updated>2021-03-07T15:36:44.569Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>近日重读<em>Learning PDEs for Image Restoration via Optimal Control</em>，确认下本文的目标和做法</p><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2> <img src="/2021/03/07/【论文阅读38】重读Learning-PDEs-for-Image-Restoration-via-Optimal-Control/1.png" title="林老师的文章"><p>本文<em>Learning PDEs for Image Restoration via Optimal Control</em>是林宙辰老师等人在ECCV2010的文章，引用量没有查，应该不低，毕竟很经典</p><p>文献参考链接地址：</p><ul><li><p><a href="http://www.cvpapers.com/eccv2010.html" target="_blank" rel="noopener">http://www.cvpapers.com/eccv2010.html</a></p></li><li><p>官方博客：<a href="https://zero-lab-pku.github.io/publication/limingjie/eccv10_learning_pdes_for_imge_restoration_via_optimal_control/" target="_blank" rel="noopener">https://zero-lab-pku.github.io/publication/limingjie/eccv10_learning_pdes_for_imge_restoration_via_optimal_control/</a></p></li><li>陆一平的推荐：<a href="https://zhuanlan.zhihu.com/p/51514687" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51514687</a></li></ul><h2 id="文献内容"><a href="#文献内容" class="headerlink" title="文献内容"></a>文献内容</h2><p>本文学习PDE的基本目标（和我想得差不多），为图像相关任务自动设计合理的PDE</p><p>背景方法有2类，<strong>变分方法</strong>和<strong>直接设计</strong>PDE。变分方法的思路是用能量泛函学习图像的先验知识，一般是正则或其它先验模型；直接设计很暴力麻烦，对PDE中算子类型有所要求。两者应该（我的解读）都要保证图像的<strong>全局几何性质</strong>，对应PDE中的<strong>正则先验模型</strong>；然后保持一些变换下的<strong>不变性</strong>，对应各种<strong>微分不变量</strong>的线性组合</p><p>由此，本文的模型，称为<strong>可学习PDE</strong>（L-PDE），基本的形式如文中$(1)$式：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dfrac{\partial u}{\partial t} &= L(u,a) = \kappa(u)+F(u,a),\ (x,y,t)\in Q \\ u &= 0,\ (x,y,t)\in \Gamma \\ u|_{t=0} &= f,\ (x,y)\in \Omega \end{aligned} \right. \tag{1}</script><p><strong>本文要学习的目标</strong>和我想的是一样的，是正常PDE<strong>右边的方程</strong>，本文把它的形式设置为如上所示的正则先验项和数据驱动的几何不变量项。PDE的边界条件就是图像边界像素（假定填充为0）。式子中前者用的似乎是（我没看过）经典的TV-正则；后者其实很简单，如文中表$(2)$，几何不变量设置了5个，原始图像、输出图像、光滑程度等等。知道是这样做的即可，表格列在这里，细节不多</p> <img src="/2021/03/07/【论文阅读38】重读Learning-PDEs-for-Image-Restoration-via-Optimal-Control/2.png" title="图像在简单变换下的不变量"><p>学习过程就是学习几何不变量的系数，有个目标函数，优化方法是<strong>伴随方法+对能量泛函求G导数</strong>。。。当场🈚了，这部分<strong>还没研究透</strong>。。。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：</p><ul><li><p>L-PDE的形式可以概括本文之前的很多PDE模型</p></li><li><p>框架不错，模型假设和思路清晰</p></li></ul><p>缺点：</p><ul><li><p>个人疑问这几个几何不变量够么？？</p></li><li><p>代码当时未公布，<a href="https://zero-lab-pku.github.io/publication/limingjie/eccv10_learning_pdes_for_imge_restoration_via_optimal_control/" target="_blank" rel="noopener">官方博客</a>没给，现在似乎也搜不到。。</p></li></ul><h2 id="和PDE-Net共通之处"><a href="#和PDE-Net共通之处" class="headerlink" title="和PDE-Net共通之处"></a>和PDE-Net共通之处</h2><p>本来想和PDE-Net，结果发现以前的博客没有更。。。所以草草记录一下，手头上只有这个笔记：</p><p>PDE-Net 的motivation是pde轨线的拟合预测以及微分算子的估计，为此先估计导数再拟合轨线；2.0 的改进是修改了拟合轨线的网络，使用的是各阶导数组成的多项式的形式</p><p>这样看应该都是在学习PDE右边的式子</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日重读&lt;em&gt;Learning PDEs for Image Restoration via Optimal Control&lt;/em&gt;，确认下本文的目标和做法&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Computer Vision" scheme="http://maxliu245.github.io/tags/Computer-Vision/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读37】Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</title>
    <link href="http://maxliu245.github.io/2021/03/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB37%E3%80%91Very-Deep-VAEs-Generalize-Autoregressive-Models-and-Can-Outperform-Them-on-Images/"/>
    <id>http://maxliu245.github.io/2021/03/03/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB37%E3%80%91Very-Deep-VAEs-Generalize-Autoregressive-Models-and-Can-Outperform-Them-on-Images/</id>
    <published>2021-03-03T01:04:03.000Z</published>
    <updated>2021-03-03T01:19:44.533Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>阅读文献<em>Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</em></p><a id="more"></a><h2 id="文献信息"><a href="#文献信息" class="headerlink" title="文献信息"></a>文献信息</h2><p>标题<em>Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images</em>，发表于ICLR2021的<strong>spotlight</strong></p><p>文献链接</p><ul><li><a href="https://openreview.net/forum?id=RLRXCV6DbEJ" target="_blank" rel="noopener">https://openreview.net/forum?id=RLRXCV6DbEJ</a> （审稿意见先不看了）</li><li><a href="https://arxiv.org/abs/2011.10650" target="_blank" rel="noopener">https://arxiv.org/abs/2011.10650</a></li><li><a href="https://github.com/yaminibansal/vdvae" target="_blank" rel="noopener">https://github.com/yaminibansal/vdvae</a></li><li><a href="https://github.com/openai/vdvae" target="_blank" rel="noopener">https://github.com/openai/vdvae</a></li></ul><h2 id="文献总结"><a href="#文献总结" class="headerlink" title="文献总结"></a>文献总结</h2><p>本文基于下列动机/idea：</p><ol><li><p>自回归的归纳偏置不好，暴力找变量相关性；而VAE生成过程更明朗，二者关联性存在</p></li><li><p>由1，VAE可以弄成自回归模型，深度的可进一步完成其它生成模型</p><p>这里面有个idea是自回归模型约等于分层VAE+强先验，由此VAE弄成自回归</p></li><li><p>背景是一系列生成模型，如自回归、VAE、可逆流，这些模型都很好</p></li></ol><p>针对VAE、流模型相关的表示学习改进问题，通过设计深度VAE，调整其结构和优化技巧，成功把VAE拓展为有效的生成模型，效果绝佳</p><blockquote><p>PS：这里自回归忘了是啥了，大概是生成过程的强先验，所以此拓展合</p></blockquote><p>本文使用的深度VAE其实就是加深VAE，但是通过网络的设计和优化技巧使之能有效地加深</p><p>网络的设计大概就是使用top-down假设；只用高斯随机层、卷积层和非线性层；有不太明白为什么work的scaling和nearest-neighbor upsampling技巧。优化技巧就是解决VAE优化难的方式，本文用的是高梯度略掉（阈值），称为GRADIENT SKIPPING，但是我很好奇不管它越来越大咋办，估计本文的理论附录有什么证明吧</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>本文的优点：</p><ol><li>写作清晰，摘要一看就nb，性能优异吸引人，深度VAE干了什么也介绍了七七八八；后续模型来龙去脉也很清楚，层层推进</li><li>动机合理</li><li>后续对深度VAE有分析，对生成过程可视化</li><li>文章第6节末尾给了大量模型的对比</li><li>在CIFAR-10、ImageNe、FFHQ上实验的结果（对数似然、参数量、生成速度1000倍）优于PixelCNN</li><li>深度VAE可进一步完成其它生成模型</li><li>藉VAE可生成高分辨图像，原因应该是VAE有效的分层表示学习</li><li>文章第1节末尾前两个优点</li></ol><p>缺点想不出来。。大概是top-down的结构有无操作空间？好像没有。。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>一些实验的细节显示</p><ul><li>总层数相同，深度增加时，参数量不变，泛化误差减小</li><li>网络结构不变时，初始图像分辨率（大小）增加时，泛化误差减小</li><li>实验过程中先生成全局特征，再学习局部特征，图像变为高分辨</li><li>实验主要是验证生成过程的有效性，合理性，并且检验了哪些因素（如分辨率）对模型的影响</li></ul><h2 id="部分感悟"><a href="#部分感悟" class="headerlink" title="部分感悟"></a>部分感悟</h2><p>我参考的地方</p><ul><li><p>对大量模型的比较方式</p></li><li><p>文章第2节开头对VAE的表述</p></li><li><p>文章第2节先修知识表示，VAE相关方法本身效率相对有些问题，可能有两个原因：</p><ul><li>观测之间要相互独立✔</li><li>不要完全分解分布，可以假定生成过程，本文用的是分层VAE，就是隐变量是top-down的模式，方式应该是使用随机层。这是合理的，有这样的明确意义，从底层特征过渡到高层特征，且隐变量的生成有随机性，带来自由性</li></ul></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Rewon Child. Very deep VAEs generalize autoregressive models and can outperform them on images. In International Conference on Learning Representations, 2021.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;阅读文献&lt;em&gt;Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images&lt;/em&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读36】Dissecting NODEs</title>
    <link href="http://maxliu245.github.io/2021/03/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB36%E3%80%91Dissecting-NODEs/"/>
    <id>http://maxliu245.github.io/2021/03/01/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB36%E3%80%91Dissecting-NODEs/</id>
    <published>2021-03-01T07:16:24.000Z</published>
    <updated>2021-03-02T07:19:09.516Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>读了好久，不少地方困住了</p><p><em>Dissecting Neural ODEs</em></p></blockquote><a id="more"></a><p>这篇文章大概20年上半年就在<a href="https://arxiv.org/abs/2002.08071" target="_blank" rel="noopener">arXiv</a>上挂出来了，后来才知道中了<a href="https://proceedings.neurips.cc/" target="_blank" rel="noopener">NeurIPS</a>2020，作者日韩，文献地址：<a href="https://proceedings.neurips.cc/paper/2020/hash/293835c2cc75b585649498ee74b395f5-Abstract.html" target="_blank" rel="noopener"><em>Dissecting Neural ODEs</em></a></p><p>如题，本文试图解剖NODE，确实从很多角度给出了一个general的增广NODE框架，总结了一系列的相关模型！</p><h2 id="内容大纲"><a href="#内容大纲" class="headerlink" title="内容大纲"></a>内容大纲</h2><p>这篇文章的主要目的是分（解）析（剖）一下NODE，给出了一个general的NODE框架，叫<strong>general system-theoretic Neural ODE formulation</strong></p><p>文献的背景/idea：</p><ul><li>最近两年来比较有意思的连续深度学习模型NODE解剖分析的需求，需要简明解释NODE结构</li></ul><p>整体的框架是$(1)$式</p> <img src="/2021/03/01/【论文阅读36】Dissecting-NODEs/DNODEs-1.png" title="general system-theoretic Neural ODE formulation"><p>进一步分析这个框架是如何general的。具体分了三大块：</p><ul><li>Depth-Variance<ul><li>基本的idea是NODE不能作为无限近似的连续模型，为什么？当结论看着吧，不过确实参数化更rich</li></ul></li><li>增广策略<ul><li>基于ANODE的增广策略，可以退化为ANODE</li><li>在框架下，分为：<ul><li>对输入层增广</li><li>高阶信息增广</li></ul></li></ul></li><li>增广之外<ul><li>动机是对$\varphi(x)=-x$或者同心环问题，不一定需要增广，由此提出了2种模型：<ul><li>data control</li><li>adaptive depth</li></ul></li></ul></li></ul><h2 id="基于NODE的连续系统"><a href="#基于NODE的连续系统" class="headerlink" title="基于NODE的连续系统"></a>基于NODE的连续系统</h2><p>标题即文中<strong>Continuous–Depth Models</strong>部分，这算是框架的一个背景模型，其实就是回顾NODE。只不过这里的说法指的是general形式的NODE，即添加了输入层$h_x$和输出层$h_y$</p><p>主要回顾了general的连续ODE系统、适定性即解的存在唯一性、训练方法Adjoint</p><h2 id="Depth-Variance"><a href="#Depth-Variance" class="headerlink" title="Depth-Variance"></a>Depth-Variance</h2><p>Depth-Variance指的是啥没读懂，depth和variance应该分别指每个深度（层）和其参数不同，后者应该不是方差的意思</p><p>它的动机是最原始的NODE，虽然说是连续系统模拟，但是即使网络足够深<strong>也不能说</strong>是ResNet的极限，注意这个说法。一个简单的理解是ResNet的每一层的残差模块都应该有自己的参数，记为$\theta_s$，$s$在这里特指为层数，或者说<strong>depth</strong>。这样的话，general的深度ResNet应该至少是$\dot{z}=f_{\theta_s}(s,z(s))$的形式，包括了所有层的变化规律</p><blockquote><p>注：文中表示试图达到ResNet的deep极限的最初尝试就是hypernetwork，日后请浏览！</p></blockquote><p>本文表示直接参数化的做法，在理论上存在弱点。本文藉此考虑<strong>泛函空间中的梯度下降</strong>，直接视$\theta_s$函数存在于一（较）般（大）的函数空间中，这样的空间又往往是无穷维的，所以函数空间中的梯度下降就要算<strong>G导数</strong>，然后拓展使用Adjoint方法的过程中发现无穷维的时候不会算这个导数。</p><p>因此需要进行有限维空间中的近似，具体的做法给了两种，一种是采用有限多个正交基展开$\theta_s$；另一种是暴力地让$\theta_s$分多段常值。这两种方法分别叫<em>Spectral discretization: Galërkin Neural ODEs</em>和<em>Depth discretization: Stacked Neural ODEs</em>。它们从不同的角度参数化了网络模型的参数，增强了表达的能力，对，应该是这样</p><h2 id="增广策略"><a href="#增广策略" class="headerlink" title="增广策略"></a>增广策略</h2><p>本文对NODE相关的增广研究都基于ANODE，要强调的一点是ANODE只是单纯增广了维度，这种增广称为<strong>0-增广</strong>。如果细化一点增广的是什么，可能能得到general的增广策略</p><h3 id="输入层增广"><a href="#输入层增广" class="headerlink" title="输入层增广"></a>输入层增广</h3><p>注意general框架中的$z(0)=h_x(x)$，这就是输入层增广，称为<strong>IL-NODE</strong>，IL表示输入层</p><p>0-增广看成把输入$x$增广为$[x,0]$，然后转化为隐变量（顺序可看成反过来），其中$x$和$0$都是向量；那么输入层增广就是把输入$x$增广为$h_x(x)$，$h_x$取普通网络即可，再在框架中和$s,x$合并为正式输入</p><p>这样的话0-增广就是IL-NODE的一个特例，即$h_x(x)\overset{def}{=}[I,0]x$，维度省略，意思是明显的</p><p>进一步，我在增广策略开头提到<code>细化一点增广的是什么</code>，举个例子，如果让$x$的前多少维度反映重要信息，比如$x$本身信息，后面的维度增广为高阶信息，那增广就能引入微分方程中的高阶导数信息</p><h3 id="高阶信息增广"><a href="#高阶信息增广" class="headerlink" title="高阶信息增广"></a>高阶信息增广</h3><p>高阶信息增广指的是<strong>Higher–order</strong> Neural ODEs，这样增广的<strong>动机</strong>是提高参数效率</p><p>本来只有隐变量$z_1=z_q$，用网络从$z_1$生成$z_2=z_p$，作为$\dot{z}_1$，然后加一个二阶信息（方程）$\dot{z}_2=\ddot{z}_1$，即文章中的$(6)$式，$(7)$式是高阶信息增广合并到一起的写法：</p><script type="math/tex; mode=display">\displaystyle \left\{ \begin{aligned} \dot{z}_1 &= z_2(s) \\ \dot{z}_2 &= f_{\theta (s)}(s,z_1(s),z_2(s)) \end{aligned} \right.,\ where\ z(s)=[z_1(s),z_2(s)]. \tag{6}</script><script type="math/tex; mode=display">\displaystyle \dfrac{d^nz^1}{ds^n}=f_{\theta (s)}\left(s,z,\dfrac{dz^1}{ds},\cdots,\dfrac{d^{n-1}z^1}{ds^{n-1}} \right),\ where\ z=[z^1,z^2,\cdots,z^n],\ z^i\in\mathbb{R}^{\frac{n_z}{n}}. \tag{7}</script><p>为什么这样合并的形式提高了参数效率呢？此时注意$(7)$式中关键的函数$f_{\theta (s)}$的输出只需要是原来的$\frac{1}{n}$即可，这就是原因了</p><p>进一步推广不太好弄，一直加高阶信息的话需要增加的维度也很多，而且意义也不大了。一个做法是选择出重要的维度来存储信息</p><h3 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h3><p>文中给出了一些实验，表明了这些增广模型都是有效的，一定程度上提高了计算效率</p><p>用了两个<strong>评价指标</strong>，分别是NFE（number of function evaluations），越小越好；和参数量</p><h2 id="增广之外"><a href="#增广之外" class="headerlink" title="增广之外"></a>增广之外</h2><p>这一部分看似有点奇怪，但动机良好，对$\varphi(x)=-x$（称为<strong>reflection</strong>）或者同心环问题，不一定需要增广策略，由此提出了2种模型，<strong>data control</strong> NODE和<strong>adaptive depth</strong> NODE</p><p>对于data control，文章先举了一个例子，对于reflection，控制$z(0)=x$，然后去学习$z(1)$，让$z(1)$随初值的变化而变化，这样学出了$-x$这个函数。这个例子是在框架下的</p><p>然后举了一个data control的归一化流的例子，没看懂。。。但是我觉得这个data control的思路是让初值变化，其实就是一种输入层增广，这样对多个初值能学习到很多条流，这些流被data control，学习到目标函数。这个时候不需要在意轨线可能相交的原因应该是<strong>哪里避免了流在同一时刻达到交点</strong>，这个精妙的地方没有读懂。。</p><p>第2种模型是adaptive depth，字面意思是控制网络深度。差不多，它控制的是积分的上下限，如文中$(5.2)$节的积分上限$g(w)$，把要积到什么时候用网络来参数化，同样<strong>避免了流在同一时刻达到交点</strong>，它能做到的原因应该是学习了一系列的流，但是各自的积分时长其实都是自适应学习的，时刻也有所变化🤔</p><hr><p>最后，文章提了一个东西，叫<strong>Mind your input networks</strong>，意思是说对输入层增广之后可能已经得到了一些重要信息，导致后面再积分的过程冗余，所以输入的处理要小心</p><h2 id="审稿意见"><a href="#审稿意见" class="headerlink" title="审稿意见"></a>审稿意见</h2><p><a href="https://proceedings.neurips.cc/paper/2020/file/293835c2cc75b585649498ee74b395f5-Review.html" target="_blank" rel="noopener">https://proceedings.neurips.cc/paper/2020/file/293835c2cc75b585649498ee74b395f5-Review.html</a></p><p>看得真累，叭看了</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Massaroli, S., Poli, M., Park, J., Yamashita, A., &amp; Asma, H. (2020). Dissecting Neural ODEs. 34th Conference on Neural Information Processing Systems, NeurIPS 2020.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;读了好久，不少地方困住了&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Dissecting Neural ODEs&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读33-35】染色体分割相关</title>
    <link href="http://maxliu245.github.io/2021/02/22/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB33-35%E3%80%91%E6%9F%93%E8%89%B2%E4%BD%93%E5%88%86%E5%89%B2%E7%9B%B8%E5%85%B3/"/>
    <id>http://maxliu245.github.io/2021/02/22/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB33-35%E3%80%91%E6%9F%93%E8%89%B2%E4%BD%93%E5%88%86%E5%89%B2%E7%9B%B8%E5%85%B3/</id>
    <published>2021-02-22T15:20:54.000Z</published>
    <updated>2021-02-22T15:47:17.225Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>读了点染色体分割的小文章，有点平衡不好暴力美学和解释性方法了</p></blockquote><a id="more"></a><h2 id="第一篇"><a href="#第一篇" class="headerlink" title="第一篇"></a>第一篇</h2><p>第一篇文章是专利：<a href="https://www.zhangqiaokeyan.com/patent-detail/06120101534115.html" target="_blank" rel="noopener">一种染色体核型图像切割方法</a></p><p>申请公布日19/12/03，公司写的专利</p><p>粗看了一遍流程，方法是<strong>基础，合理，工程</strong>的</p><p>好多方法都用了，形态学算子、MaskRCNN等等，大概思路就是</p><ol><li>不知道有没有预处理，好像不需要</li><li>连通域提取染色体区域</li><li>重叠染色体进一步提取，方式是阈值判断与置信选择</li><li>进一步提取骨架，找中心点，骨架其实就是染色体条像素宽度1</li><li>后面就是无趣的深度学习工程式套模型，数据增强等等，有多少方法套多少方法</li></ol><h2 id="第二篇"><a href="#第二篇" class="headerlink" title="第二篇"></a>第二篇</h2><p>第二篇文章<a href="https://ieeexplore.ieee.org/document/7163174" target="_blank" rel="noopener">A Geometric Approach To Fully Automatic Chromosome Segmentation</a></p><p>这个文章是2014 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)的</p><p>感觉讲得很结实实在，就是讲染色体图像自动分割，方法就是<code>a geometric method for segmentation of the touching and partially overlapping chromosomes</code></p><p>基本方法：</p><ol><li>去噪（预处理）</li><li>分离重叠或者touching的染色体（key）</li><li>正式分离</li></ol><p>本文的出发点（idea）是基于几何进行自动分割，主要贡献在于检测分离2中的情形。本文强调几何方法的优点（section I最后有三条优点）是不用考虑图片类型，通用。本文的数据也不多，database containing 62 touching and  partially overlapping chromosomes，要考虑减小过拟合。</p><p>上述的2有两大步骤</p><ol><li>第1是把所有染色体簇识别出来，方式是三种几何方法适当组合，虽然每个方法都有偏颇，但组合之后确实可能更有效分别是计算凸包像素比例、外接椭圆长短轴比、骨架端点数</li><li>第2就是把染色体簇分成单个的，方式是找出分割点，有VAMD和SDTP两个准则，都是几何判断，细节不考虑了</li><li>ps：如果有多条染色体成簇，就重复算法，每次分出来一条</li></ol><h2 id="第三篇"><a href="#第三篇" class="headerlink" title="第三篇"></a>第三篇</h2><p>第三篇文章很早之前看过，这次整理一下</p><p><a href="https://ieeexplore.ieee.org/document/8014843" target="_blank" rel="noopener">Crowdsourcing for Chromosome Segmentation and Deep Classification</a>是<a href="https://ieeexplore.ieee.org/xpl/conhome/8014302/proceeding" target="_blank" rel="noopener">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</a>的</p><p>原来是个workshop，怪不得觉得差味道</p><p>这个讲一整套流程，中期（ metaphase ）染色体分析，分割与分类，众包流程。</p><p>众包是人工注释边界。。然后伸直矫正+长度归一化。。再网络分类。。</p><p>哈哈这个文章也提到了染色体分割的难处，叽里呱啦介绍了一堆别人方法，然后表示我们还是深度吧。。</p><p>扫了一遍内容没啥，我觉得就是强调了一遍染色体分类应用落地的流程。整个流程十分工程：</p><ol><li>众包分割单个染色体图像</li><li>众包过程中有细节提高分割效率</li><li>单个染色体有诸如剪切、拼接、扭直、归一化长度的操作</li><li>普通的网络进行分类</li><li>交互式应用界面</li></ol><p>最后，它的数据集不大，准确率泛化性存疑</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>平衡不好暴力美学和解释性方法了</p><p>要是一点点地设计模型，效果是存疑的，但是可解释性会比较优美，所以希望分类的方法能直观，能看出来实际意义，同时保持准确性（安全性）</p><p>要是暴力工程处理，实在不美，效果泛化未必就好，这样来看还是处理general图像的方法好，预处理尽可能忽略图像类型的影响</p><p>大晚上的迷糊了，ヾ(•ω•`)o</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 宋宁, 池浩塬, 秦玉磊, 韩云鹏, 马伟旗, 沈晓明, 晏青, 吴朝玉, and 杨洁. “一种染色体核型图像切割方法.” 2019.</p><p>[2] Minaee, S., M. Fotouhi, and B. H. Khalaj. “A Geometric Approach to Fully Automatic Chromosome Segmentation.” Paper presented at the 2014 IEEE Signal Processing in Medicine and Biology Symposium (SPMB), 13-13 Dec. 2014 2014.</p><p>[3] Sharma, M., O. Saha, A. Sriraman, R. Hebbalaguppe, L. Vig, and S. Karande. “Crowdsourcing for Chromosome Segmentation and Deep Classification.” Paper presented at the 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 21-26 July 2017 2017.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;读了点染色体分割的小文章，有点平衡不好暴力美学和解释性方法了&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Medical Images" scheme="http://maxliu245.github.io/tags/Medical-Images/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读32】NF小综述</title>
    <link href="http://maxliu245.github.io/2021/01/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB32%E3%80%91NF%E5%B0%8F%E7%BB%BC%E8%BF%B0/"/>
    <id>http://maxliu245.github.io/2021/01/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB32%E3%80%91NF%E5%B0%8F%E7%BB%BC%E8%BF%B0/</id>
    <published>2021-01-28T15:09:17.000Z</published>
    <updated>2021-01-28T15:13:05.276Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读归一化流小综述</p><p><em>Normalizing Flows: An Introduction and Review of Current Methods</em></p></blockquote><a id="more"></a> <img src="/2021/01/28/【论文阅读32】NF小综述/lzgnyq.jpg" title="小拳拳出击"><p>他喵的读文章读了好几天，日常很烦躁。</p><p>这篇文章是关于流模型的一个小综述，发在TPAMI(Early Access)上我是想不到的，截至2021/01/28影响因子17.8。去年5月刊出，现在有2次被引</p><p><a href="https://ieeexplore.ieee.org/document/9089305" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/9089305</a></p><h2 id="NF概述"><a href="#NF概述" class="headerlink" title="NF概述"></a>NF概述</h2><p>总结就是流这个东西属于生成模型建模的一部分，现在的<code>Normalizing流</code>在保证<strong>生成效果</strong>的同时要求<strong>生成过程可逆</strong>，也就是可以来回变。这个变来变去的过程一般包括采样，所以还需保证<strong>采样效率</strong>良好，这三个其实就是目前主要的<strong>模型改进方向</strong></p><p> <code>Normalizing流</code>没有正式翻译，我姑且称为归一化流。本来是<strong>从简单初始分布一步步到复杂数据分布的过程</strong>嘛，要求<strong>可逆可微</strong>（后者应该可以退化成连续）。那么<strong>流有两个方向</strong>，简单到复杂就是<strong>生成方向</strong>；反之称为<strong>normalizing方向</strong>，意思是复杂分布统统归一化为简单分布，就是这个意思</p><p>它的应用方向似乎不少，但是比较专，和生成模型相关的都可以，数据生成什么的也沾边</p><h2 id="NF基础理解"><a href="#NF基础理解" class="headerlink" title="NF基础理解"></a>NF基础理解</h2><p>基础的流理论，主要是概率分布之间的变化，那么自然有Jacobi的引入，后续针对它的结构、行列式计算也有很多改进。另外是基础理论，这个真的觉得难度一下子就上去了，涉及测度论</p><p>注意一个区别，微分同胚和双射不同！微分同胚是更强的，双射比较弱，原文是这么说的。自己感觉的话，微分同胚连续可微，双射不一定连续</p><p>流理论的两种主要应用，密度估计和变分推断，涉及流的两个方向的使用。正向即生成方向是直接计算复杂分布的概率密度的，因此这个过程要计算Jacobi。所以在密度估计问题中，由于这个密度指的是已知数据条件下，从复杂分布推导前面简单分布的概率密度，如果建模生成方向的话，则要计算其Jacobi的逆，这样复杂了，所以对密度估计一般建模归一化方向可能方便一点。</p><p>至于变分推断，就是一般的推断过程，需要重参数化技巧。不过我自己还没有见过有关这方面的流模型文章</p><h2 id="NF方法分类"><a href="#NF方法分类" class="headerlink" title="NF方法分类"></a>NF方法分类</h2><p>一图胜千言系列，文章也是按这个顺序介绍的，而且对应的方法相对前一种多有针对性的改进</p><img src="/2021/01/28/【论文阅读32】NF小综述/NF-1.png" title="方法分类"><ul><li><p>逐点流，其实是逐维度的流，维度分开。显然表达能力比较欠缺，维度之间没有相关性</p></li><li><p>线性流，线性指线性变换。在逐点流的基础上维度之间线性组合，即进行线性变换，不妨设形式$Ax+b$。具体又分<strong>$A$对角，上下三角，置换，正交，$A$矩阵分解，$A$取卷积阵</strong>等，这些都算线性流！</p><p>其中的<strong>Periodic Convolutions可能和XQ师兄提到的变换基的卷积有所关系</strong>！</p><p>线性流的缺点还是表达能力，毕竟是线性（如果直接引入非线性特征变换，线性套非线性变换的话会很奇怪，为什么不直接非线性变换）</p></li><li><p>平面流&amp;径向流，试图突破线性流，取非线性变换</p><ul><li>平面流加了方向，见文中$(10)$式$x+uh(w^Tx+b)$，观察知，有一点残差的味道，前面弄出来个$x$好像是有利于Jacobi行列式估计的；另外，后面的$h$非线性，先线性再非线性，前面还有个所谓的方向$u$，这大概是平面流名称的由来</li><li>径向流用的是那种中心点的形式，有点像核函数的那种形式，见文中$(14)$式</li></ul></li><li><p>耦合（coupling）流，<strong>有技巧的非线性变换</strong>，<strong>耦合函数也叫conditioner</strong>。一般的操作是维度拆开，一部分id，一部分用耦合函数作用，以前看的NICE就是这个套路，还取了名字叫加性耦合函数。</p><ul><li>问题一：哪一部分变量取耦合作用，这些可能涉及到顺序的问题。常用的套路是每次非线性变换一部分变量，到后面，<strong>还能id的变量维度是减少的</strong>，因为先前非线性变换的信息已经够多</li><li>问题二：回去即归一化的方向，在问题一的假设中，此方向id的维度依次增多，语义信息保留，指的是高阶信息逐渐变成id，且还能<strong>在归一化的过程中保留</strong></li></ul><p>针对问题一，耦合往往使用分割维度的方式，其顺序可以随机置换，也有mask方式和选择Jacobi对角值更高的维度（信息更多吧）</p></li></ul><p>中间插一段<strong>各种耦合函数</strong>的介绍：</p><ol><li>直接仿射变换</li><li>非线性的二次变换</li><li>连续的混合密度</li><li>样条（插值？），又包括分段线性，分段二次，三次样条，etc</li><li>神经网络建模的自回归耦合方式，应该是依次套层</li><li>多项式平方和</li><li>分段双射耦合</li></ol><ul><li><p>自回归流，其实就是上述耦合函数<strong>作用对象变化</strong>，依次作用在先前所有的输入上</p><p>这样做的一个缺点是逆不好算；且由于是顺序的，难以并行计算</p><img src="/2021/01/28/【论文阅读32】NF小综述/NF-2.png" title="自回归流的一般结构"></li><li><p>以残差网络为代表的流，正逆向建模的都有</p><ul><li><p>正向是自然理解，用了耦合coupling的手段，维度分开，用残差加性处理加性和前面说的还不是太一样，对每次的输出也有耦合作用，见$(30)$式</p></li><li><p>逆向需要所谓re-arrange，这个记不清了，暂时不太明白</p></li></ul><p>缺点是Jacobi难算，一个方案是采用det估计，由Lipschitz控制把det转换为计算迹，其中还有采样近似估计的trick。估计的方式不少，有偏无偏都有</p><p>对于这一类流，一个理解是ODE系统，这类网络可设计为可逆，有文中命题7保证，要求残差block被常数1，Lipschitz控制。但不好控制，一般需要控制网络的结构，由此又衍生出一些模型</p></li><li><p>连续流，字面上指离散得足够精细，也可依据上面ODE理解，中间状态足够精细就逼近连续系统。但是直接加深ResNet深度太SB了。基于此，这个分两类，ODE-based和SDE-based</p><ul><li><p>前者即熟知的NODE+adjoint方法</p><p>相关改进有陈天琦参与的FFJORD，估计迹，降低计算和存储（连续流）复杂度，还有个思路是正则限制</p><p>ODE方法类也有缺点，<strong>一条path上Jacobi行列式不变号</strong>，解决方式是维度增广ANODE，以前读ANODE的时候一直对这个path不交叉有点迷惑，现在又多了一个解释！</p><p>我看的DDNF他们也介绍了，路径由许多微分同胚构成</p></li><li><p>SDE-based没怎么看过（Langevin flows）：大概就是ODE与时间相关了，有随机项，也有固定的偏移项之类的东西</p></li></ul></li></ul><h2 id="NF常用数据"><a href="#NF常用数据" class="headerlink" title="NF常用数据"></a>NF常用数据</h2><p>实验数据方面比较固定。除了人工数据，参考文中表2、4即可。分别是UCI和常用实际数据</p><p>似乎UCI的数据都连续化了de-quantized，方式是对离散数据加均匀噪声，看成连续数据</p><h2 id="NF挑战"><a href="#NF挑战" class="headerlink" title="NF挑战"></a>NF挑战</h2><p>这个文章提的挑战不多，感觉很多核心的东西没有明说，我也没看出来太多</p><ol><li><p>从基础理论开始，自然是测度论太难做了，基测度，即初始分布的选取可以看成一种先验，也就是大家说取简单的好采样的就完事了。有生成的复杂度和效果之间的权衡？</p></li><li><p>另外，微分同胚的建模也很重要，上一篇看的<a href="https://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/">DNNF</a>就是</p></li><li><p>还有一点是损失函数的选取，现在普遍KL，也有其它距离介导的损失</p></li><li><p>再提一个理论上的东西，从欧氏空间到非欧空间哈哈。黎曼来袭，怎么把欧式转为黎曼。计算上必然复杂。这其中涉及到黎曼几何课上学习的东西，哈哈什么测地完备则测地线可以无限延伸，即空间中处处可以转换，也有切空间近似方式，亦或是考虑特定的黎曼空间，李群结构什么的😄</p></li><li><p>最后至于不连续流，个人觉得是特定应用场景下再使用就算了，而且一般也就是离散流de-quantized近似为连续流</p></li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Kobyzev, I., Prince, S., &amp; Brubaker, M. (2020). Normalizing Flows: An Introduction and Review of Current Methods. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1-1. <a href="https://doi.org/10.1109/TPAMI.2020.2992934" target="_blank" rel="noopener">https://doi.org/10.1109/TPAMI.2020.2992934</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读归一化流小综述&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Normalizing Flows: An Introduction and Review of Current Methods&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【Windows技巧3】奇怪的网页广告统统走开</title>
    <link href="http://maxliu245.github.io/2021/01/26/%E3%80%90Windows%E6%8A%80%E5%B7%A73%E3%80%91%E5%A5%87%E6%80%AA%E7%9A%84%E7%BD%91%E9%A1%B5%E5%B9%BF%E5%91%8A%E7%BB%9F%E7%BB%9F%E8%B5%B0%E5%BC%80/"/>
    <id>http://maxliu245.github.io/2021/01/26/%E3%80%90Windows%E6%8A%80%E5%B7%A73%E3%80%91%E5%A5%87%E6%80%AA%E7%9A%84%E7%BD%91%E9%A1%B5%E5%B9%BF%E5%91%8A%E7%BB%9F%E7%BB%9F%E8%B5%B0%E5%BC%80/</id>
    <published>2021-01-26T08:58:53.000Z</published>
    <updated>2021-01-26T09:14:19.632Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>大家吼！给大家安利去网页广告神器ADBlock！</p></blockquote><a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>凡安利必有因，本来打算用学校的vpn下波文献，研究研究《傅雷家书》的版权问题。毕竟傅雷早已过世，为什么傅雷家书还不算公版书呢？</p><p>以下文献讲得还可以，我感觉我明白了，《傅雷家书》是傅聪整理的，而且有所创新，其<strong>著作权现在归属傅聪</strong>。get</p><blockquote><p><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2017&amp;filename=FBZX201726164&amp;v=xscXH%25mmd2F5%25mmd2BzQVsz6bvAycyaGFAlQY3yZkHtJAdqbO7AuEXwv3Jgdg0xh2Bec06j25V" target="_blank" rel="noopener">浅论公版图书的版权问题——以《傅雷家书》版权案为例</a></p><p>许姗. (2017). 浅论公版图书的版权问题——以《傅雷家书》版权案为例. 法制博览(26), 252. </p></blockquote><h2 id="哈哈哈哪里都有奇怪的广告"><a href="#哈哈哈哪里都有奇怪的广告" class="headerlink" title="哈哈哈哪里都有奇怪的广告"></a>哈哈哈哪里都有奇怪的广告</h2><p>但是这波上了学校vpn之后出现的奇怪的广告，导致我<strong>点击不了文献</strong>，包括大半个网页屏幕区域</p><img src="/2021/01/26/【Windows技巧3】奇怪的网页广告统统走开/Webvpn-1.png" title="请问是Webvpn的锅么"><p>刚开始尝试开发者工具删除element，但是直接找看不出来哪个是这个广告</p><p>突然惊醒，👴有<strong>去广告神器ADBlock</strong>嘻嘻🤭</p><img src="/2021/01/26/【Windows技巧3】奇怪的网页广告统统走开/Webvpn-2.png" title="懂我意思吧hxd"><p>🆗</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>最后<strong>怒喷</strong>一波，学校这个服务还带广告的？？？这波是算合理外快还是又什么操作？？？搜文献的时候点击不了很毁人心情的</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;大家吼！给大家安利去网页广告神器ADBlock！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Windows" scheme="http://maxliu245.github.io/tags/Windows/"/>
    
  </entry>
  
  <entry>
    <title>【Hexo4】公式渲染出错更正——渲染位置失效问题</title>
    <link href="http://maxliu245.github.io/2021/01/13/%E3%80%90Hexo4%E3%80%91%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E5%87%BA%E9%94%99%E6%9B%B4%E6%AD%A3%E2%80%94%E2%80%94%E6%B8%B2%E6%9F%93%E4%BD%8D%E7%BD%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/"/>
    <id>http://maxliu245.github.io/2021/01/13/%E3%80%90Hexo4%E3%80%91%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93%E5%87%BA%E9%94%99%E6%9B%B4%E6%AD%A3%E2%80%94%E2%80%94%E6%B8%B2%E6%9F%93%E4%BD%8D%E7%BD%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/</id>
    <published>2021-01-13T06:12:41.000Z</published>
    <updated>2021-01-13T06:39:20.755Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>记录一下长久以来困扰我的公式渲染问题</p></blockquote><a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>很早就有这个问题了，<code>hexo</code>对公式的渲染莫名其妙会出现问题，自己在本地<code>Typora</code>编辑器中渲染得都非常漂亮，但是一旦发布或者在本地服务器上预览就会出问题，本来的<strong>应该被渲染的公式可能没有被渲染或者被渲染到了别的地方</strong>。这次好好写的笔记又炸了，如下图所示：</p><img src="/2021/01/13/【Hexo4】公式渲染出错更正——渲染位置失效问题/error.jpg" title="MathJax Error"><p>主要的问题在于：</p><ol><li><p>用来生成$\{\}$的代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\&#123;\&#125;</span><br></pre></td></tr></table></figure><p>中花括号的转义字符<code>\</code>会消失导致渲染失败</p></li><li><p>下标转义字符<code>_</code>会偶尔消失，主要是行内公式</p></li><li><p>由以上问题导致非公式文本会被渲染</p></li></ol><p>太难看了，这次从网上找了解决方案，聊记于此，原因是<strong>原来的渲染包<code>hexo-renderer-marked</code>不太行</strong>。。。我先自己更新了一下，发现问题没有改观，然后卸载之并安装<code>hexo-renderer-kramed</code>，问题仍未改观。最后按照解决方案修改<code>js</code>规则，总算🆗啦！</p><h2 id="试错顺序"><a href="#试错顺序" class="headerlink" title="试错顺序"></a>试错顺序</h2><p>第一步观察是不是工具包未升级的问题：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g npm</span><br></pre></td></tr></table></figure><p>第二步观察是不是新的工具包就好了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><p>第三步按链接找到<code>../node_modules/kramed/lib/rules/inline.js</code>中第11行和第20行并修改转义规则：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span></span><br><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([`*\[\]()#$+\-.!_&gt;])/</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span></span><br><span class="line">em: <span class="regexp">/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span>,</span><br></pre></td></tr></table></figure><p>再重新渲染就🆗啦！</p><h2 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h2><p><a href="https://home.cnblogs.com/u/Ai-heng/" target="_blank" rel="noopener">VitaHeng</a>的博客<a href="https://www.cnblogs.com/Ai-heng/p/7282110.html" target="_blank" rel="noopener">hexo博客MathJax公式渲染问题</a>，顺便发现这位大兄弟的主页了，前两年还有两篇文章，加油！</p><p>自己确实试了错，加了自己的探索过程，除了代码，我觉得不算转载。如果的确需要授权，请联系我商议解决~</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;记录一下长久以来困扰我的公式渲染问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Hexo" scheme="http://maxliu245.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>【论文阅读31】DDNF——深度微分同胚的Normalizing Flow</title>
    <link href="http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/"/>
    <id>http://maxliu245.github.io/2021/01/13/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB31%E3%80%91DDNF%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6%E5%BE%AE%E5%88%86%E5%90%8C%E8%83%9A%E7%9A%84Normalizing-Flow/</id>
    <published>2021-01-13T03:45:18.000Z</published>
    <updated>2021-01-13T03:58:21.384Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读文章<em>Deep Diffeomorphic Normalizing Flows</em></p><p>感觉写得不错，但是引用量很少，我觉得是代码没有开源的缘故</p></blockquote><a id="more"></a><h2 id="Deep-Diffeomorphic-Normalizing-Flows"><a href="#Deep-Diffeomorphic-Normalizing-Flows" class="headerlink" title="Deep Diffeomorphic Normalizing Flows"></a>Deep Diffeomorphic Normalizing Flows</h2><h2 id="心路历程"><a href="#心路历程" class="headerlink" title="心路历程"></a>心路历程</h2><p>很长时间没有看过流模型了，这次也看到了许多之前没有接触过的概念，包括很多细节，本来打算这些细节将在文末实验部分单独一一列出，但是太累了不写了，需要的时候自己看看吧</p><p>另外文章中介绍了不少以往的模型，这些也不介绍了，以后见到慢慢补充</p><h2 id="文献简介"><a href="#文献简介" class="headerlink" title="文献简介"></a>文献简介</h2><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-1.png" title="DDNF"><ul><li><p>作者信息</p><p>一作是微软的工程师Hadi Salman，看了看他的<a href="https://www.microsoft.com/en-us/research/people/hasalman/" target="_blank" rel="noopener">个人主页</a>和<a href="https://scholar.google.com/citations?user=Kr8JjF0AAAAJ&amp;hl=en&amp;oi=sra" target="_blank" rel="noopener">学术主页</a>，这个人主要是做对抗攻防的，带一点稳健动力系统。其余作者来自弗吉尼亚大学和匹兹堡大学</p></li><li><p>文献信息</p><p>文献链接：<a href="https://arxiv.org/abs/1810.03256" target="_blank" rel="noopener">https://arxiv.org/abs/1810.03256</a></p><p>这篇文章18年挂出来，截至2021/01/12谷歌学术上的引用量是11</p></li><li><p>文献简述</p><p>这个文章有些意思，它提出了一种新的对流模型的建模<strong><em>DDNF</em></strong>，主要的思想是借用ODE中每个state可以看成流模型中隐变量的多次映射过程，即 $z_0\rightarrow z_1\rightarrow\cdots\rightarrow z_n$，那么隐变量的每一步更新看成ODE的积分过程，这个过程可以进一步反应在抽象出来的流形上，如下图所示：</p><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-2.png" title="隐变量如何多次映射"></li></ul><p>我想把它对于流模型的建模步骤归纳为：</p><pre class="mermaid">graph LRA(DDNF<br>Deep Diffeomorphic Normalizing Flows) -->B(Idea<br>介绍微分同胚和ODE之间的关联)A -->C(DDNF的结构<br>主要是建模过程,模型设置)A -->D(Jacobi计算<br>泰勒展开以及行列式的迹估计)A -->E(正则引入<br>有两种方法改善模型效果,分别是测地正则和逆一致正则)</pre><h2 id="基本任务——对归纳偏执建模"><a href="#基本任务——对归纳偏执建模" class="headerlink" title="基本任务——对归纳偏执建模"></a>基本任务——对归纳偏执建模</h2><p>写总结的时候发现还是要写像target一样的东西放在前面</p><p>对流的建模基本不变，即数据 $X=\{x_1,\cdots,x_N\}$，引入生成模型及其隐变量 $z$，目标是最大似然</p><script type="math/tex; mode=display">\begin{align} \displaystyle \log p_{\theta}(X)&=\sum_{i=1}^N \log p_{\theta}x_i \tag{1}\\ &\overset{p_{\theta}(x)=\int p_{\theta}(z,x)dz}{\geq} \mathbb{E}_{q_{\lambda}(z|x)}[\log p_{\theta}(x|z)-KL(q_{\lambda}(z|x)|p(z))]. \tag{2}\end{align}</script><p>现在给出归纳偏置，由于主要是<strong>建模隐变量</strong> $z$，试图近似它的后验分布，那么本文假设的是<strong>最终的隐变量 $z$ 由一系列可逆变换 $\phi_k$ 作用在初始分布 $q_0$ 上得到</strong>，即</p><script type="math/tex; mode=display">\displaystyle final\ latent\ variable\ z_K = \phi_K\circ\cdots\circ\phi_2\circ\phi_1(z_0) \tag{3}</script><p>之后要写出对应的变分目标，具体的过程就是 $(3)$ 式<strong>概率密度函数分解</strong>，由</p><script type="math/tex; mode=display">\begin{align} \displaystyle q_{k+1}(z_{k+1})&=q_k(z_k)\bigg|det\dfrac{\partial \phi_{k+1}(z_k)}{\partial z_k}\bigg|^{-1} \tag{4}\\ &=q_k(\phi_{k+1}^{-1}(z_{k+1}))\bigg|det\dfrac{\partial \phi_{k+1}^{-1}(z_{k+1})}{\partial z_{k+1}}\bigg| \tag{5}\end{align}</script><p>可得分解后的变分目标（其实不难，就是要写半天。。。）为</p><script type="math/tex; mode=display">\begin{align} \displaystyle \mathcal{F}(\theta,\lambda)&=\mathbb{E}_{q_{\lambda}}[\log q_{\lambda}(z|x)-\log p_{\theta}(x,z)] \tag{6}\\ &=\mathbb{E}_{q_0}[\log q_0(z_0|x)-\log p_{\theta}(x,z_K)] - \mathbb{E}_{q_0}\left[\sum_{k=1}^K \log  \bigg|det\dfrac{\partial \phi_{k}(z_{k-1})}{\partial z_{k-1}}\bigg|\right] \tag{7}\end{align}</script><p>因此，DDNF的目标其实就是<strong>针对这一系列的可逆变换设计流模型</strong>，进一步引入微分同胚保持可逆和光滑性，而这恰好引入了ODE-Net的思想</p><h2 id="Idea——微分同胚如何引入"><a href="#Idea——微分同胚如何引入" class="headerlink" title="Idea——微分同胚如何引入"></a>Idea——微分同胚如何引入</h2><p>这要联系ODE中<strong>连续流</strong>的概念，并结合美妙的<strong>黎曼几何</strong>。如文首所述：</p><blockquote><p>主要的思想是借用ODE中每个state可以看成流模型中隐变量的<strong>多次映射</strong>过程，即 $z_0\rightarrow z_1\rightarrow\cdots\rightarrow z_n$，那么<strong>隐变量的每一步更新看成ODE的积分过程</strong>，这个过程可以进一步反应在抽象出来的流形上</p><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-2.png" title="隐变量如何多次映射"></blockquote><p>具体设置为（细节拜拜，反之就是Hilbert空间假设，然后随便推导），每个可逆变换 $\phi_k:\Omega\rightarrow\Omega$，其中 $\Omega\subset\mathbb{R}^d$，就是切向量之间的映射，设 $\Omega$ 的切丛（从这里看出它把 $\Omega$ 直接看成带有内积的流形了，不妨当成黎曼流形就好）的完备化空间为 $V\overset{def}{=}H^s(\mathcal{T}\Omega)$，$s$ 代表切向量的几阶导存在，且都默认二次可积。总之，完备化+黎曼流形就瞎推了</p><p>那么<strong>关键</strong>来了，之前说隐变量的前进过程看成ODE上的积分过程，这需要<strong>切向量在流形上的平行移动（其实就是积分）</strong>，所以先要模拟切向量，这里设其形式为一般的可随时间变化的切向量 $v(t,\cdot):[0,1]\rightarrow V$，应该是指流形上每一点处可以得到与时间相关的切向量。那么<strong>隐变量的每一步更新看成ODE的积分过程</strong>：</p><script type="math/tex; mode=display">\displaystyle \dfrac{d}{dt}\phi_k(t,z)=v(t,\phi_k(t,z)). \tag{8}</script><p>这样，如果能用像ResNet之类的网络模拟一阶导 $v$，那么ResNet输出的就相当于积分后的方程，输出的是 $\phi_k$；那么再配合上RNN之类的结构把这一系列变换 $\phi_k$ 串起来，那就是整个流的建模过程了</p><p>最后再声明，上述建模过程说得很轻巧，看起来也比较合理，那有没有理论保证，你这个就一定行呢？有的，参考原文第3页左下角部分，大概就是</p><ul><li>前人结论：<ul><li>若 $v$ 充分光滑，那 $\phi$ 就相当于微分同胚</li><li>这样的flow中的Jacobi行列式总是非负的（<strong>为0不就gg，估计有trick处理，阈值截断什么的</strong>）</li></ul></li><li>原作者总结的性质：<ul><li>一系列微分同胚 $\phi_k$ 保持代数运算，它们在代数群上✅</li><li>假定空间存在合适的内积，那就成为黎曼流形，进一步可以引入测地线概念，引入测地正则✅</li></ul></li></ul><h2 id="网络结构——RNN-ResNet-ODE-Net"><a href="#网络结构——RNN-ResNet-ODE-Net" class="headerlink" title="网络结构——RNN+ResNet(ODE-Net)"></a>网络结构——RNN+ResNet(ODE-Net)</h2><p>这个部分本来以为挺难，但是读完了发现文章中图2真是<strong>一图胜千言</strong>。我解读了三次此网络，前两次应该都错了！后一次就是总结出来的┭┮﹏┭┮</p><img src="/2021/01/13/【论文阅读31】DDNF——深度微分同胚的Normalizing-Flow/DDNF-3.png" title="网络设置"><p>首先，观察<strong>最下面的图</strong>，这就是<strong>整个流的建模过程</strong>，即通过 $K$ <strong>个可逆微分同胚变换</strong>，$\{\phi_{k}\}_k$ ，它把初始化的隐变量 $z_0$，逐步映射到最终目标隐变量 $z_K$。因此，最下面的图中每个block都是在流形上某点$z_k$处切空间中进行积分的过程。且注意到在每个切空间  $T_{z_k}\Omega$中，切向量都是不同的，因此每步变换中的切向量或者说速率不同！</p><p>其次，如上图<strong>中间的图</strong>表示，中间的图整个是<strong>一个积分过程，表示一步可逆变换</strong> $z_{k+1}=\phi_{k+1}(z_k)$。<strong>整体是RNN</strong>模型，其中有 $T$ 个block，指的是 $T$ 个ResNet block，$T$ 指的是从 $z_k$ 到 $z_{k+1}$ 的积分过程中离散近似的小区间数目，RNN就是把这离散的过程叠加循环起来。且为了方便，建模时考虑<strong>使用不随时间变化的stationary向量场</strong>，即每个block使用相同的向量场，图中记为 $v^k$ 是很合理的。此时，整个一步积分是自治方程 $(8)$ 的求解过程，，解出来其实是指映射 $\phi^{v_k}=exp(v^k(t,\cdot))=exp(v^k(\cdot))$，如果考虑实验中的近似手段 $T$ 个block的结果叠加，那就是 $\phi^{v_k}=exp(v^k(\cdot)/T)^T$</p><p>最后是<strong>最上面的模型</strong>，即具体<strong>一步积分中一个小区间的近似</strong>过程，为<strong>一个ResNet block</strong>，其中使用多少层，每层宽度多少是可以调整的。我记的没错的话，本文实验多使用的结构只有两层，每层只有两个神经元，目的是验证即使结构简单，其表达能力也很强，这将会验证基于ODE的微分同胚流的模型是优异的</p><hr><p>这样模型就讲完了，下面介绍为什么使用ResNet的结构，计算Jacobi会用到，但是这<strong>和以前我看的不一样</strong>，我记得以前看过哪篇文章，<strong>用ResNet的结构会使Jacobi呈现行列式为1的形式</strong>，进一步微调使之变化（好像是这样，忘了）。这里计算Jacobi不太一样</p><p>本文的思路是借用ResNet中恒等映射的存在<strong>作泰勒展开</strong>近似估计Jacobi行列式：</p><script type="math/tex; mode=display">\begin{align} \displaystyle \log det(\mathcal{J}\phi^v(\Delta t,\cdot))&\overset{RestNet}{=}\log det(I+\Delta t\mathcal{J}v(\cdot)) \tag{9}\\ &\overset{A\overset{def}{=}I+\Delta t\mathcal{J}v(\cdot)}{=}\log det(A) \tag{10}\\ &=\log \left(det(A^2)\right)^\frac{1}{2} \tag{11}\\ &= \dfrac{1}{2}\log \left(det(A^TA)\right) \tag{12}\\ &= \dfrac{1}{2}\log \left(det(I+\Delta t(\mathcal{J}v(\cdot)+\mathcal{J}v(\cdot)^T+\Delta t\mathcal{J}v(\cdot)^T\mathcal{J}v(\cdot)))\right) \tag{13}\\ &\overset{def}{=} \dfrac{1}{2}\log \left(det(I+\Delta tB)\right) \tag{14}\\ &\approx \dfrac{1}{2}\Delta tTr(\mathcal{J}v(\cdot)+\mathcal{J}v(\cdot)^T)-\dfrac{1}{2}(\Delta t)^2Tr(\mathcal{J}v(\cdot)^T\mathcal{J}v(\cdot)). \tag{15}\end{align}</script><p>其中最后一步我<strong>没有推出来</strong>，现在不推了，日后需要再搞。只知道是在 $B=0$ 处二阶泰勒展开，三次及三次以上都近似忽略掉，然后用迹估计的方法即可</p><p>所以使用ResNet的结构并引入泰勒展开，<strong>目的是降低Jacobi计算的复杂度</strong>，一般来说根据模型结构，有 $T$ 个Jacobi的行列式需要计算，所以计算复杂度可看成 $\mathcal{O}(Td^3)$，而转化为 $(15)$ 式后，除了矩阵 $\mathcal{J}v$ 的存储外，迹的计算复杂度只有 $\mathcal{O}(d)$，而近似方法中需要 $M$ 常数次采样，因此最终复杂度由 $\mathcal{O}(Td^3)$ 降低到 $\mathcal{O}(Md)$，的确是比较大的进步！</p><h2 id="微分同胚流的其它亮点"><a href="#微分同胚流的其它亮点" class="headerlink" title="微分同胚流的其它亮点"></a>微分同胚流的其它亮点</h2><h3 id="流的逆简易计算"><a href="#流的逆简易计算" class="headerlink" title="流的逆简易计算"></a>流的逆简易计算</h3><p>流的逆一般需要好求，这往往需要对网络的结构进行限制，本文表示，由于限定每一个可逆映射中的切向量是stationary的，所以求解出来直接就是指数映射，所以逆回去的时候也指数逆回去就好了，即 $\phi^{v_k}=exp(v^k(\cdot)/T)^T$ 逆为 $(\phi^{v_k})^{-1}=exp(-v^k(\cdot)/T)^T$</p><h3 id="两种正则有效"><a href="#两种正则有效" class="headerlink" title="两种正则有效"></a>两种正则有效</h3><p>在最后，本文指出可以引入正则增强模型的性能，有两种：</p><ul><li><p>测地正则，即 $v_0$ 和 $v_K$ 的测地距离尽可能小，原理大概就是测地线喵喵咪</p><script type="math/tex; mode=display">\mathcal{R}(v)=\langle v_0,v_K\rangle_V=\mathbb{E}_{q_0}[v_0^TGv_K] \tag{16}</script><p>其中 $G$ 是黎曼流形的度规矩阵，实际操作的时候用欧氏空间的单位阵即可</p></li><li><p>逆正则，即逆回去得到的 $\phi^{-1}(z_K)$ 与初始的变量 $z_0$ 要恢复好</p><script type="math/tex; mode=display">\mathcal{R}(v)=||z_0-\phi^{-1}(z_K)||_2 \tag{17}</script></li></ul><h2 id="实验简介"><a href="#实验简介" class="headerlink" title="实验简介"></a>实验简介</h2><p>文章的一个不错的地方是实验很充足，我都看了，但是不想写细节了，细节也忘了，需要的时候再回顾吧，写累死了。。。</p><p>有哪些有意思的实验：</p><ul><li>文中图7，模拟数据验证性能可以逼近分布</li><li>文中图4和图6，分别是toy和真实数据中变量分布的逼近，与其它几个模型对比，优势体现在不需要ResNet太多层等</li><li>文中图5和图8，两种正则的效果，看起来不错</li><li>文中表1，MNIST和Omniglot数据上的实验，大模型套的VAE，DDNF用来建模隐变量，似乎效果不错，只是说的好少？</li></ul><h2 id="优缺点简析"><a href="#优缺点简析" class="headerlink" title="优缺点简析"></a>优缺点简析</h2><p>模型优点（根据原文所述）：</p><ul><li>所提的微分同胚流 $f$ 保持了微分同胚的性质，$f$ 可逆，且 $f$ 与 $f^{-1}$ 都光滑</li><li>流的建模引入ODE的概念，流的部分变化过程由可与时间相关的向量场 $v(t,\cdot)$ 完成，此向量场由ResNet模拟</li><li>流的建模还引入了RNN来近似整个流的变化，结构使得似然推断还行，流的逆易求，隐变量的概率密度也好算</li><li>流的建模没有对网络结构有特殊设计</li><li>实验充足，据文章说competitive with SOTA</li><li>黎曼几何有更多的认识么？</li></ul><p>模型缺点：</p><ul><li>文章说代码将会开源，这都2021了我搜不到，迷惑</li><li>其实还是有很多估计，现在还能记起来的有，ODE积分的离散估计；stationary切向量的使用（但是不用这个就没有指数性质）；泰勒展开中只近似到2阶项；Jacobi计算时迹的估计</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Hadi Salman, Payman Yadollahpour, Tom Fletcher, and Kayhan Batmanghelich. Deep diffeomorphic normalizing flows. arXiv e-prints, page arXiv:1810.03256, 2018.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读文章&lt;em&gt;Deep Diffeomorphic Normalizing Flows&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;感觉写得不错，但是引用量很少，我觉得是代码没有开源的缘故&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="ODE" scheme="http://maxliu245.github.io/tags/ODE/"/>
    
      <category term="Flow Model" scheme="http://maxliu245.github.io/tags/Flow-Model/"/>
    
  </entry>
  
  <entry>
    <title>【论文略读30】AI Poincare</title>
    <link href="http://maxliu245.github.io/2021/01/11/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB30%E3%80%91AI-Poincare/"/>
    <id>http://maxliu245.github.io/2021/01/11/%E3%80%90%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB30%E3%80%91AI-Poincare/</id>
    <published>2021-01-11T01:12:26.000Z</published>
    <updated>2021-01-11T01:34:16.259Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>阅读文章<em>AI Poincaré: Machine Learning Conservation Laws from Trajectories</em></p><p>名字挺炫酷，不过看了一遍，觉得可以借鉴的地方不多，见正文方法部分最后一句</p></blockquote><a id="more"></a><h1 id="AI-Poincare"><a href="#AI-Poincare" class="headerlink" title="AI Poincaré"></a>AI Poincaré</h1><p>还是偏物理的，个人觉得不太算CS的文章，有的格式都不一样；只有5页，不过符号不算少，就是证明没有，难道是保密技术？纯粹是兴趣看一看，<strong>作者MIT学物理的</strong>，不是我，狗头👍。而且可以学习借鉴的地方不多</p><p>文献链接：<a href="https://arxiv.org/abs/2011.04698" target="_blank" rel="noopener">https://arxiv.org/abs/2011.04698</a></p><p>提出的方法叫做 $AI\ Poincar\acute{e}$，是只利用未知动力系统轨线数据自动寻找守恒律的学习算法</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>纯粹数据驱动，从轨线trajectories中学习守恒律</li><li>自动学习，不手动设计特征，且不加显式的偏置归纳</li><li>实验优点：哈密顿系统中发现了所有精确的守恒量，而且似乎有一定的解释性：发现了周期轨道，phase transitions和breakdown timescale</li></ul><h2 id="认为的缺点："><a href="#认为的缺点：" class="headerlink" title="认为的缺点："></a>认为的缺点：</h2><ul><li>方法在建模比赛中应该是非常有意思的，但是在学习领域，觉得不够味道</li><li>虽然走纯数据驱动的路子，但是可解释性不足，发现轨道等概念的解释性和我想的不一样</li><li>方法其实解释得不清楚，只是讲了一遍过程，合理性不足</li><li>实验结果似乎对不上？没看明白ERD图，难道不是中间有几条线下凸，低于阈值就是发现多少守恒律？文章表格和描述的似乎不一致，我很费解，可能是我菜。。。</li></ul><h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>文章自述一个宏伟的目标是<strong>智能学习物理系统中的规律，如符号回归得到的方程形式、守恒律、对称性，etc</strong>，我喜欢。本文的具体target是：<strong>从轨线trajectories中学习守恒律</strong>。</p><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><p>一般求守恒律可能要限制方程形式？所以以往方法可能是模型驱动。现在的idea就是表示只用轨线，对方程形式没有任何假设，就是要<strong>纯粹数据驱动</strong>试试。</p><p>具体的思想见建模的过程，本质是概念的对应，实现的方式比较基础</p><h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p>用于对比批判的方法：</p><ul><li>用AE、暹罗网络的正交方法（我自己未验证此方法），可以寻找对称性。缺点是要手动设计（对称性）特征</li><li>把守恒律作为偏执归纳先验，但这不是纯数据驱动</li></ul><p>重点参考的方法：</p><p>sampling manifolds方法和动力系统<strong>概念的对应</strong>（我一直在想这个问题但是想不通。。）看了这篇文章给的对应关系，也只是觉得可能有关系，但是还是没有说清楚概念之间的真正联系，可能<strong>还是要看更基础的文章</strong>！</p><img src="/2021/01/11/【论文略读30】AI-Poincare/AIPoin.png" title="概念对应关系"><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>看完方法觉得在机器学习的范畴内亮点不多。把方法流程大致过一遍。</p><p>首先是模型的基本假设，假定是<strong>带有守恒律</strong> $H_j(\mathbf{x})=h_j$ 的方程（真的是守恒律），每条守恒律都看作是一个高维空间（在可操作意义下都是 $\mathbb{R}^{l}$）中的超平面，满足一条守恒律就意味着有一个<strong>限制条件</strong>（凸分析学的好啊）。本文把所有可行轨线所在的空间看成与满足守恒律的空间一致，称之为可允许状态流形<code>permissible state manifold (PSM)</code> $\mathcal{M}$，且<strong>假设</strong>轨线数据集 $\mathcal{S}=\{\mathbf{x}(t)|t\geq 0\}$ 都分布在这个流形 $\mathcal{M}$ 上。它定义为</p><script type="math/tex; mode=display">\begin{equation} \mathcal{M} = \{\mathbf{x}\in\mathbb{R}^N|H_j(\mathbf{x})=h_j\} \tag{1}\end{equation}</script><p>那么每满足一条守恒律，此流形其实就有了一个的限制，相当于在 $\mathbb{R}^N$ 的基础上维度<strong>降低一维</strong>，如果观察到总维度（应该是提前已知）减去估计出的轨线数据集 $\mathcal{S}$ 的维度不为0，那就是找出了守恒律。</p><p>那么第二点是模型怎么算的。<strong>第1步是对轨线数据预处理</strong>，标准化，这样会有一个协方差矩阵，对角元对应特征值，有特征值就说明找到了重要的维度，初始时的非0特征值个数就应该是上一段说的总维度，然后一旦<strong>有特征值在迭代的过程中变得很小</strong>，那就是守恒律被发现了，这个维度就对应守恒律。第2步是对轨线数据加噪，干扰之，得到<strong>近似的流形</strong>（我认为是这样），再蒙特卡洛采样，学习恢复流形的函数，这一步的目的应该想把干扰后的轨线投影到切空间，如果守恒律存在，那么<strong>合适的干扰对守恒律会有较大的影响</strong>。那么第3步就是把投影后的轨线数据PCA降维处理得到最后的维度，如果降维的过程中发现<strong>维度变化很大</strong>，说明合适水平的噪声影响到了守恒律。这时根据<code>explained ratio diagram (ERD)</code>（我真不懂这个图怎么对应几条守恒律，因为好像和结果描述的不一致）可<strong>看出</strong>守恒律有几条。</p><p>思路就是这样，有点意思，意思在于<strong>干扰影响了守恒律</strong>，且合适水平的干扰可以最大影响守恒律；另外就是其实专门去寻找可能存在的守恒律，这一点与流形上有些概念似乎可以对应。私以为本文<strong>只有这两点可以借鉴</strong>。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>做了5种有守恒律的哈密顿方程的实验。但是私以为讲得不清楚，因为用ERD看出的守恒律数目和文章描述的似乎不一样😶。也可能是我菜看不出来🤡。。。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Ziming Liu and Max Tegmark. AI Poincaré: Machine Learning Conservation Laws from Trajectories. arXiv e-prints, page arXiv:2011.04698, November 2020.</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;阅读文章&lt;em&gt;AI Poincaré: Machine Learning Conservation Laws from Trajectories&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;名字挺炫酷，不过看了一遍，觉得可以借鉴的地方不多，见正文方法部分最后一句&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="Paper Reading" scheme="http://maxliu245.github.io/tags/Paper-Reading/"/>
    
      <category term="Manifold" scheme="http://maxliu245.github.io/tags/Manifold/"/>
    
      <category term="PDE" scheme="http://maxliu245.github.io/tags/PDE/"/>
    
  </entry>
  
</feed>
